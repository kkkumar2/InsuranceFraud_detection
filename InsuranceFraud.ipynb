{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InsuranceFraud.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "udjqkdGX9bSt"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import lightgbm as lgb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfECxdTK-6cT",
        "outputId": "4344c4ce-ca2f-43e5-8c74-39f94b7e20fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up the working directory\n",
        "os.chdir(\"/content/drive/MyDrive/Imarticus/Captsoneproject_ml\")\n",
        "os.getcwd()\n",
        "# importing the dataset\n",
        "data = pd.read_csv(\"insuranceFraud.csv\")"
      ],
      "metadata": {
        "id": "xbaz5MBT9ieS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features:\n",
        "\n",
        "1.\tmonths_as_customer: It denotes the number of months for which the customer is associated with the insurance company.\n",
        "2.\tage: continuous. It denotes the age of the person.\n",
        "3.\tpolicy_number: The policy number.\n",
        "4.\tpolicy_bind_date: Start date of the policy.\n",
        "5.\tpolicy_state: The state where the policy is registered.\n",
        "6.\tpolicy_csl-combined single limits. How much of the bodily injury will be covered from the total damage.\n",
        "https://www.berkshireinsuranceservices.com/arecombinedsinglelimitsbetter  \n",
        "7.\tpolicy_deductable: The amount paid out of pocket by the policy-holder before an insurance provider will pay any expenses.\n",
        "8.\tpolicy_annual_premium: The yearly premium for the policy.\n",
        "9.\tumbrella_limit: An umbrella insurance policy is extra liability insurance coverage that goes beyond the limits of the insured's homeowners, auto or watercraft insurance. It provides an additional layer of security to those who are at risk of being sued for damages to other people's property or injuries caused to others in an accident.\n",
        "10.\tinsured_zip: The zip code where the policy is registered.\n",
        "11.\tinsured_sex: It denotes the person's gender.\n",
        "12.\tinsured_education_level: The highest educational qualification of the policy-holder.\n",
        "13.\tinsured_occupation: The occupation of the policy-holder.\n",
        "14.\tinsured_hobbies: The hobbies of the policy-holder.\n",
        "15.\tinsured_relationship: Dependents on the policy-holder.\n",
        "16.\tcapital-gain: It denotes the monitory gains by the person.\n",
        "17.\tcapital-loss: It denotes the monitory loss by the person.\n",
        "18.\tincident_date: The date when the incident happened.\n",
        "19.\tincident_type: The type of the incident.\n",
        "20.\tcollision_type: The type of collision that took place.\n",
        "21.\tincident_severity: The severity of the incident.\n",
        "22.\tauthorities_contacted: Which authority was contacted.\n",
        "23.\tincident_state: The state in which the incident took place.\n",
        "24.\tincident_city: The city in which the incident took place. \n",
        "25.\tincident_location: The street in which the incident took place.\n",
        "26.\tincident_hour_of_the_day: The time of the day when the incident took place.\n",
        "27.\tproperty_damage: If any property damage was done.\n",
        "28.\tbodily_injuries: Number of bodily injuries.\n",
        "29.\tWitnesses: Number of witnesses present.\n",
        "30.\tpolice_report_available: Is the police report available.\n",
        "31.\ttotal_claim_amount: Total amount claimed by the customer.\n",
        "32.\tinjury_claim: Amount claimed for injury\n",
        "33.\tproperty_claim: Amount claimed for property damage.\n",
        "34.\tvehicle_claim: Amount claimed for vehicle damage.\n",
        "35.\tauto_make: The manufacturer of the vehicle\n",
        "36.\tauto_model: The model of the vehicle. \n",
        "37.\tauto_year: The year of manufacture of the vehicle. \n",
        "\n",
        "\n",
        "Target Label:\n",
        "Whether the claim is fraudulent or not.\n",
        "38.\tfraud_reported:  Y or N\n"
      ],
      "metadata": {
        "id": "JDg614zySdcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 : https://colab.research.google.com/drive/1i_qU7c_JAqFoE-GPqOu1P_mtx22_7nwQ#scrollTo=TygA6mzy9m7g&line=23&uniqifier=1\n",
        "\n",
        "Model 2 :\n",
        "Model 3 :"
      ],
      "metadata": {
        "id": "6tp3HjYxoPo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "okJFWIdA9lxu",
        "outputId": "254f5edb-60f5-48e7-f1db-0848bc1d98c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4fe9093b-b04d-4a07-9399-ea9abd918a0e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_as_customer</th>\n",
              "      <th>age</th>\n",
              "      <th>policy_number</th>\n",
              "      <th>policy_bind_date</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>policy_deductable</th>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <th>umbrella_limit</th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_date</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_location</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>injury_claim</th>\n",
              "      <th>property_claim</th>\n",
              "      <th>vehicle_claim</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_model</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>328</td>\n",
              "      <td>48</td>\n",
              "      <td>521585</td>\n",
              "      <td>10/17/2014</td>\n",
              "      <td>OH</td>\n",
              "      <td>250/500</td>\n",
              "      <td>1000</td>\n",
              "      <td>1406.91</td>\n",
              "      <td>0</td>\n",
              "      <td>466132</td>\n",
              "      <td>MALE</td>\n",
              "      <td>MD</td>\n",
              "      <td>craft-repair</td>\n",
              "      <td>sleeping</td>\n",
              "      <td>husband</td>\n",
              "      <td>53300</td>\n",
              "      <td>0</td>\n",
              "      <td>1/25/2015</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Side Collision</td>\n",
              "      <td>Major Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>SC</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>9935 4th Drive</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>YES</td>\n",
              "      <td>71610</td>\n",
              "      <td>6510</td>\n",
              "      <td>13020</td>\n",
              "      <td>52080</td>\n",
              "      <td>Saab</td>\n",
              "      <td>92x</td>\n",
              "      <td>2004</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>228</td>\n",
              "      <td>42</td>\n",
              "      <td>342868</td>\n",
              "      <td>6/27/2006</td>\n",
              "      <td>IN</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1197.22</td>\n",
              "      <td>5000000</td>\n",
              "      <td>468176</td>\n",
              "      <td>MALE</td>\n",
              "      <td>MD</td>\n",
              "      <td>machine-op-inspct</td>\n",
              "      <td>reading</td>\n",
              "      <td>other-relative</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1/21/2015</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>?</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>VA</td>\n",
              "      <td>Riverwood</td>\n",
              "      <td>6608 MLK Hwy</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>?</td>\n",
              "      <td>5070</td>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "      <td>3510</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>E400</td>\n",
              "      <td>2007</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>134</td>\n",
              "      <td>29</td>\n",
              "      <td>687698</td>\n",
              "      <td>9/6/2000</td>\n",
              "      <td>OH</td>\n",
              "      <td>100/300</td>\n",
              "      <td>2000</td>\n",
              "      <td>1413.14</td>\n",
              "      <td>5000000</td>\n",
              "      <td>430632</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>PhD</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>own-child</td>\n",
              "      <td>35100</td>\n",
              "      <td>0</td>\n",
              "      <td>2/22/2015</td>\n",
              "      <td>Multi-vehicle Collision</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>NY</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>7121 Francis Lane</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>NO</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NO</td>\n",
              "      <td>34650</td>\n",
              "      <td>7700</td>\n",
              "      <td>3850</td>\n",
              "      <td>23100</td>\n",
              "      <td>Dodge</td>\n",
              "      <td>RAM</td>\n",
              "      <td>2007</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>256</td>\n",
              "      <td>41</td>\n",
              "      <td>227811</td>\n",
              "      <td>5/25/1990</td>\n",
              "      <td>IL</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1415.74</td>\n",
              "      <td>6000000</td>\n",
              "      <td>608117</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>PhD</td>\n",
              "      <td>armed-forces</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>48900</td>\n",
              "      <td>-62400</td>\n",
              "      <td>1/10/2015</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Front Collision</td>\n",
              "      <td>Major Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>OH</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>6956 Maple Drive</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NO</td>\n",
              "      <td>63400</td>\n",
              "      <td>6340</td>\n",
              "      <td>6340</td>\n",
              "      <td>50720</td>\n",
              "      <td>Chevrolet</td>\n",
              "      <td>Tahoe</td>\n",
              "      <td>2014</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>228</td>\n",
              "      <td>44</td>\n",
              "      <td>367455</td>\n",
              "      <td>6/6/2014</td>\n",
              "      <td>IL</td>\n",
              "      <td>500/1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1583.91</td>\n",
              "      <td>6000000</td>\n",
              "      <td>610706</td>\n",
              "      <td>MALE</td>\n",
              "      <td>Associate</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>66000</td>\n",
              "      <td>-46000</td>\n",
              "      <td>2/17/2015</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>?</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>None</td>\n",
              "      <td>NY</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>3041 3rd Ave</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>6500</td>\n",
              "      <td>1300</td>\n",
              "      <td>650</td>\n",
              "      <td>4550</td>\n",
              "      <td>Accura</td>\n",
              "      <td>RSX</td>\n",
              "      <td>2009</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fe9093b-b04d-4a07-9399-ea9abd918a0e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4fe9093b-b04d-4a07-9399-ea9abd918a0e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4fe9093b-b04d-4a07-9399-ea9abd918a0e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   months_as_customer  age  policy_number  ... auto_model auto_year fraud_reported\n",
              "0                 328   48         521585  ...        92x      2004              Y\n",
              "1                 228   42         342868  ...       E400      2007              Y\n",
              "2                 134   29         687698  ...        RAM      2007              N\n",
              "3                 256   41         227811  ...      Tahoe      2014              Y\n",
              "4                 228   44         367455  ...        RSX      2009              N\n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeZTxJt89l0d",
        "outputId": "fffd8c56-70cb-4d62-c322-dd33f09c6697"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 39 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   months_as_customer           1000 non-null   int64  \n",
            " 1   age                          1000 non-null   int64  \n",
            " 2   policy_number                1000 non-null   int64  \n",
            " 3   policy_bind_date             1000 non-null   object \n",
            " 4   policy_state                 1000 non-null   object \n",
            " 5   policy_csl                   1000 non-null   object \n",
            " 6   policy_deductable            1000 non-null   int64  \n",
            " 7   policy_annual_premium        1000 non-null   float64\n",
            " 8   umbrella_limit               1000 non-null   int64  \n",
            " 9   insured_zip                  1000 non-null   int64  \n",
            " 10  insured_sex                  1000 non-null   object \n",
            " 11  insured_education_level      1000 non-null   object \n",
            " 12  insured_occupation           1000 non-null   object \n",
            " 13  insured_hobbies              1000 non-null   object \n",
            " 14  insured_relationship         1000 non-null   object \n",
            " 15  capital-gains                1000 non-null   int64  \n",
            " 16  capital-loss                 1000 non-null   int64  \n",
            " 17  incident_date                1000 non-null   object \n",
            " 18  incident_type                1000 non-null   object \n",
            " 19  collision_type               1000 non-null   object \n",
            " 20  incident_severity            1000 non-null   object \n",
            " 21  authorities_contacted        1000 non-null   object \n",
            " 22  incident_state               1000 non-null   object \n",
            " 23  incident_city                1000 non-null   object \n",
            " 24  incident_location            1000 non-null   object \n",
            " 25  incident_hour_of_the_day     1000 non-null   int64  \n",
            " 26  number_of_vehicles_involved  1000 non-null   int64  \n",
            " 27  property_damage              1000 non-null   object \n",
            " 28  bodily_injuries              1000 non-null   int64  \n",
            " 29  witnesses                    1000 non-null   int64  \n",
            " 30  police_report_available      1000 non-null   object \n",
            " 31  total_claim_amount           1000 non-null   int64  \n",
            " 32  injury_claim                 1000 non-null   int64  \n",
            " 33  property_claim               1000 non-null   int64  \n",
            " 34  vehicle_claim                1000 non-null   int64  \n",
            " 35  auto_make                    1000 non-null   object \n",
            " 36  auto_model                   1000 non-null   object \n",
            " 37  auto_year                    1000 non-null   int64  \n",
            " 38  fraud_reported               1000 non-null   object \n",
            "dtypes: float64(1), int64(17), object(21)\n",
            "memory usage: 304.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "qfcZCdr3FXqL",
        "outputId": "9b542188-4775-4fa8-8c19-ae0e80fb6370"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cded372f-845b-467c-b2ed-c573ed2cc029\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_as_customer</th>\n",
              "      <th>age</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>policy_deductable</th>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <th>umbrella_limit</th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>injury_claim</th>\n",
              "      <th>property_claim</th>\n",
              "      <th>vehicle_claim</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1.000000e+03</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>203.954000</td>\n",
              "      <td>38.948000</td>\n",
              "      <td>0.246760</td>\n",
              "      <td>0.248000</td>\n",
              "      <td>1136.000000</td>\n",
              "      <td>1256.406150</td>\n",
              "      <td>1.101000e+06</td>\n",
              "      <td>501214.488000</td>\n",
              "      <td>0.243890</td>\n",
              "      <td>3.883000</td>\n",
              "      <td>0.247490</td>\n",
              "      <td>0.247350</td>\n",
              "      <td>0.246390</td>\n",
              "      <td>25126.100000</td>\n",
              "      <td>-26793.700000</td>\n",
              "      <td>0.246860</td>\n",
              "      <td>0.248220</td>\n",
              "      <td>2.74600</td>\n",
              "      <td>0.248100</td>\n",
              "      <td>0.246010</td>\n",
              "      <td>0.245420</td>\n",
              "      <td>11.644000</td>\n",
              "      <td>1.83900</td>\n",
              "      <td>0.302000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>1.487000</td>\n",
              "      <td>0.314000</td>\n",
              "      <td>52761.94000</td>\n",
              "      <td>7433.420000</td>\n",
              "      <td>7399.570000</td>\n",
              "      <td>37928.950000</td>\n",
              "      <td>0.247130</td>\n",
              "      <td>2005.103000</td>\n",
              "      <td>0.247000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>115.113174</td>\n",
              "      <td>9.140287</td>\n",
              "      <td>0.012652</td>\n",
              "      <td>0.018339</td>\n",
              "      <td>611.864673</td>\n",
              "      <td>244.167395</td>\n",
              "      <td>2.297407e+06</td>\n",
              "      <td>71701.610941</td>\n",
              "      <td>0.014966</td>\n",
              "      <td>2.011805</td>\n",
              "      <td>0.057659</td>\n",
              "      <td>0.174296</td>\n",
              "      <td>0.030486</td>\n",
              "      <td>27872.187708</td>\n",
              "      <td>28104.096686</td>\n",
              "      <td>0.071443</td>\n",
              "      <td>0.020343</td>\n",
              "      <td>0.96458</td>\n",
              "      <td>0.069208</td>\n",
              "      <td>0.053666</td>\n",
              "      <td>0.023276</td>\n",
              "      <td>6.951373</td>\n",
              "      <td>1.01888</td>\n",
              "      <td>0.459355</td>\n",
              "      <td>0.820127</td>\n",
              "      <td>1.111335</td>\n",
              "      <td>0.464349</td>\n",
              "      <td>26401.53319</td>\n",
              "      <td>4880.951853</td>\n",
              "      <td>4824.726179</td>\n",
              "      <td>18886.252893</td>\n",
              "      <td>0.051466</td>\n",
              "      <td>6.015861</td>\n",
              "      <td>0.431483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>433.330000</td>\n",
              "      <td>-1.000000e+06</td>\n",
              "      <td>430104.000000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.210000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-111100.000000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.180000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>1995.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>115.750000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>1089.607500</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>448404.500000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.210000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-51500.000000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>0.210000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41812.50000</td>\n",
              "      <td>4295.000000</td>\n",
              "      <td>4445.000000</td>\n",
              "      <td>30292.500000</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>199.500000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1257.200000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>466445.500000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.210000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-23250.000000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>58055.00000</td>\n",
              "      <td>6775.000000</td>\n",
              "      <td>6750.000000</td>\n",
              "      <td>42100.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>2005.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>276.250000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>1415.695000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>603251.000000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>51025.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>70592.50000</td>\n",
              "      <td>11305.000000</td>\n",
              "      <td>10885.000000</td>\n",
              "      <td>50822.500000</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>479.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2047.590000</td>\n",
              "      <td>1.000000e+07</td>\n",
              "      <td>620962.000000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>100500.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>114920.00000</td>\n",
              "      <td>21450.000000</td>\n",
              "      <td>23670.000000</td>\n",
              "      <td>79560.000000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>2015.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cded372f-845b-467c-b2ed-c573ed2cc029')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cded372f-845b-467c-b2ed-c573ed2cc029 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cded372f-845b-467c-b2ed-c573ed2cc029');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       months_as_customer          age  ...    auto_year  fraud_reported\n",
              "count         1000.000000  1000.000000  ...  1000.000000     1000.000000\n",
              "mean           203.954000    38.948000  ...  2005.103000        0.247000\n",
              "std            115.113174     9.140287  ...     6.015861        0.431483\n",
              "min              0.000000    19.000000  ...  1995.000000        0.000000\n",
              "25%            115.750000    32.000000  ...  2000.000000        0.000000\n",
              "50%            199.500000    38.000000  ...  2005.000000        0.000000\n",
              "75%            276.250000    44.000000  ...  2010.000000        0.000000\n",
              "max            479.000000    64.000000  ...  2015.000000        1.000000\n",
              "\n",
              "[8 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe(include='object')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "A3c9L4YeFum0",
        "outputId": "ddb7a8e2-4209-4c1b-f279-c65f3c32231c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-db29877a-fe67-4cfd-8b12-103d73958bea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>policy_bind_date</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>incident_date</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_location</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_model</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>951</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>60</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>1/1/2006</td>\n",
              "      <td>OH</td>\n",
              "      <td>250/500</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>JD</td>\n",
              "      <td>machine-op-inspct</td>\n",
              "      <td>reading</td>\n",
              "      <td>own-child</td>\n",
              "      <td>2/2/2015</td>\n",
              "      <td>Multi-vehicle Collision</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>NY</td>\n",
              "      <td>Springfield</td>\n",
              "      <td>9935 4th Drive</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Saab</td>\n",
              "      <td>RAM</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>352</td>\n",
              "      <td>351</td>\n",
              "      <td>537</td>\n",
              "      <td>161</td>\n",
              "      <td>93</td>\n",
              "      <td>64</td>\n",
              "      <td>183</td>\n",
              "      <td>28</td>\n",
              "      <td>419</td>\n",
              "      <td>292</td>\n",
              "      <td>354</td>\n",
              "      <td>292</td>\n",
              "      <td>262</td>\n",
              "      <td>157</td>\n",
              "      <td>1</td>\n",
              "      <td>360</td>\n",
              "      <td>343</td>\n",
              "      <td>80</td>\n",
              "      <td>43</td>\n",
              "      <td>753</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db29877a-fe67-4cfd-8b12-103d73958bea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db29877a-fe67-4cfd-8b12-103d73958bea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db29877a-fe67-4cfd-8b12-103d73958bea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       policy_bind_date policy_state  ... auto_model fraud_reported\n",
              "count              1000         1000  ...       1000           1000\n",
              "unique              951            3  ...         39              2\n",
              "top            1/1/2006           OH  ...        RAM              N\n",
              "freq                  3          352  ...         43            753\n",
              "\n",
              "[4 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking missing values\n",
        "# Function to calculate missing values by column# Funct \n",
        "def missing_values_table(df):\n",
        "\n",
        "  Total = df.isnull().sum().sort_values(ascending = False)          \n",
        "  Percent = (df.isnull().sum()*100/df.isnull().count()).sort_values(ascending = False)   \n",
        "  missing_data = pd.concat([Total, Percent], axis = 1, keys = ['Total', 'Percentage of Missing Values'])\n",
        "        \n",
        "        # Return the dataframe with missing information\n",
        "  return missing_data"
      ],
      "metadata": {
        "id": "VE82SaB89l3N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values statistics\n",
        "missing_values = missing_values_table(data)\n",
        "missing_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ymbVPDC9l59",
        "outputId": "9dac0503-d2c9-4b12-d71c-85cb9ea3c839"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bd8b2354-7f2d-4492-a8d9-c0054c36840f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percentage of Missing Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>months_as_customer</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>witnesses</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_state</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_city</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_location</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property_damage</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodily_injuries</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>police_report_available</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_severity</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_claim_amount</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>injury_claim</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property_claim</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vehicle_claim</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auto_make</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auto_model</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auto_year</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>authorities_contacted</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>collision_type</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_zip</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_number</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_bind_date</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_state</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_csl</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_deductable</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>umbrella_limit</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_sex</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_type</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_education_level</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_occupation</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_hobbies</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_relationship</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gains</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_date</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraud_reported</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd8b2354-7f2d-4492-a8d9-c0054c36840f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd8b2354-7f2d-4492-a8d9-c0054c36840f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd8b2354-7f2d-4492-a8d9-c0054c36840f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             Total  Percentage of Missing Values\n",
              "months_as_customer               0                           0.0\n",
              "witnesses                        0                           0.0\n",
              "incident_state                   0                           0.0\n",
              "incident_city                    0                           0.0\n",
              "incident_location                0                           0.0\n",
              "incident_hour_of_the_day         0                           0.0\n",
              "number_of_vehicles_involved      0                           0.0\n",
              "property_damage                  0                           0.0\n",
              "bodily_injuries                  0                           0.0\n",
              "police_report_available          0                           0.0\n",
              "incident_severity                0                           0.0\n",
              "total_claim_amount               0                           0.0\n",
              "injury_claim                     0                           0.0\n",
              "property_claim                   0                           0.0\n",
              "vehicle_claim                    0                           0.0\n",
              "auto_make                        0                           0.0\n",
              "auto_model                       0                           0.0\n",
              "auto_year                        0                           0.0\n",
              "authorities_contacted            0                           0.0\n",
              "collision_type                   0                           0.0\n",
              "age                              0                           0.0\n",
              "insured_zip                      0                           0.0\n",
              "policy_number                    0                           0.0\n",
              "policy_bind_date                 0                           0.0\n",
              "policy_state                     0                           0.0\n",
              "policy_csl                       0                           0.0\n",
              "policy_deductable                0                           0.0\n",
              "policy_annual_premium            0                           0.0\n",
              "umbrella_limit                   0                           0.0\n",
              "insured_sex                      0                           0.0\n",
              "incident_type                    0                           0.0\n",
              "insured_education_level          0                           0.0\n",
              "insured_occupation               0                           0.0\n",
              "insured_hobbies                  0                           0.0\n",
              "insured_relationship             0                           0.0\n",
              "capital-gains                    0                           0.0\n",
              "capital-loss                     0                           0.0\n",
              "incident_date                    0                           0.0\n",
              "fraud_reported                   0                           0.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "HpaTsyIVioS2",
        "outputId": "14e491f4-6c11-4d61-8bb9-8721932b29bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e2b9140a-ebdf-40bc-aa7a-3cfd15328181\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_as_customer</th>\n",
              "      <th>age</th>\n",
              "      <th>policy_number</th>\n",
              "      <th>policy_bind_date</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>policy_deductable</th>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <th>umbrella_limit</th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_date</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_location</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>injury_claim</th>\n",
              "      <th>property_claim</th>\n",
              "      <th>vehicle_claim</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_model</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>328</td>\n",
              "      <td>48</td>\n",
              "      <td>521585</td>\n",
              "      <td>10/17/2014</td>\n",
              "      <td>OH</td>\n",
              "      <td>250/500</td>\n",
              "      <td>1000</td>\n",
              "      <td>1406.91</td>\n",
              "      <td>0</td>\n",
              "      <td>466132</td>\n",
              "      <td>MALE</td>\n",
              "      <td>MD</td>\n",
              "      <td>craft-repair</td>\n",
              "      <td>sleeping</td>\n",
              "      <td>husband</td>\n",
              "      <td>53300</td>\n",
              "      <td>0</td>\n",
              "      <td>1/25/2015</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Side Collision</td>\n",
              "      <td>Major Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>SC</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>9935 4th Drive</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>YES</td>\n",
              "      <td>71610</td>\n",
              "      <td>6510</td>\n",
              "      <td>13020</td>\n",
              "      <td>52080</td>\n",
              "      <td>Saab</td>\n",
              "      <td>92x</td>\n",
              "      <td>2004</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>228</td>\n",
              "      <td>42</td>\n",
              "      <td>342868</td>\n",
              "      <td>6/27/2006</td>\n",
              "      <td>IN</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1197.22</td>\n",
              "      <td>5000000</td>\n",
              "      <td>468176</td>\n",
              "      <td>MALE</td>\n",
              "      <td>MD</td>\n",
              "      <td>machine-op-inspct</td>\n",
              "      <td>reading</td>\n",
              "      <td>other-relative</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1/21/2015</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>?</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>VA</td>\n",
              "      <td>Riverwood</td>\n",
              "      <td>6608 MLK Hwy</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>?</td>\n",
              "      <td>5070</td>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "      <td>3510</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>E400</td>\n",
              "      <td>2007</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>134</td>\n",
              "      <td>29</td>\n",
              "      <td>687698</td>\n",
              "      <td>9/6/2000</td>\n",
              "      <td>OH</td>\n",
              "      <td>100/300</td>\n",
              "      <td>2000</td>\n",
              "      <td>1413.14</td>\n",
              "      <td>5000000</td>\n",
              "      <td>430632</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>PhD</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>own-child</td>\n",
              "      <td>35100</td>\n",
              "      <td>0</td>\n",
              "      <td>2/22/2015</td>\n",
              "      <td>Multi-vehicle Collision</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>NY</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>7121 Francis Lane</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>NO</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NO</td>\n",
              "      <td>34650</td>\n",
              "      <td>7700</td>\n",
              "      <td>3850</td>\n",
              "      <td>23100</td>\n",
              "      <td>Dodge</td>\n",
              "      <td>RAM</td>\n",
              "      <td>2007</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>256</td>\n",
              "      <td>41</td>\n",
              "      <td>227811</td>\n",
              "      <td>5/25/1990</td>\n",
              "      <td>IL</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1415.74</td>\n",
              "      <td>6000000</td>\n",
              "      <td>608117</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>PhD</td>\n",
              "      <td>armed-forces</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>48900</td>\n",
              "      <td>-62400</td>\n",
              "      <td>1/10/2015</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Front Collision</td>\n",
              "      <td>Major Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>OH</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>6956 Maple Drive</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NO</td>\n",
              "      <td>63400</td>\n",
              "      <td>6340</td>\n",
              "      <td>6340</td>\n",
              "      <td>50720</td>\n",
              "      <td>Chevrolet</td>\n",
              "      <td>Tahoe</td>\n",
              "      <td>2014</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>228</td>\n",
              "      <td>44</td>\n",
              "      <td>367455</td>\n",
              "      <td>6/6/2014</td>\n",
              "      <td>IL</td>\n",
              "      <td>500/1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1583.91</td>\n",
              "      <td>6000000</td>\n",
              "      <td>610706</td>\n",
              "      <td>MALE</td>\n",
              "      <td>Associate</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>66000</td>\n",
              "      <td>-46000</td>\n",
              "      <td>2/17/2015</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>?</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>None</td>\n",
              "      <td>NY</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>3041 3rd Ave</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>6500</td>\n",
              "      <td>1300</td>\n",
              "      <td>650</td>\n",
              "      <td>4550</td>\n",
              "      <td>Accura</td>\n",
              "      <td>RSX</td>\n",
              "      <td>2009</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2b9140a-ebdf-40bc-aa7a-3cfd15328181')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2b9140a-ebdf-40bc-aa7a-3cfd15328181 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2b9140a-ebdf-40bc-aa7a-3cfd15328181');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   months_as_customer  age  policy_number  ... auto_model auto_year fraud_reported\n",
              "0                 328   48         521585  ...        92x      2004              Y\n",
              "1                 228   42         342868  ...       E400      2007              Y\n",
              "2                 134   29         687698  ...        RAM      2007              N\n",
              "3                 256   41         227811  ...      Tahoe      2014              Y\n",
              "4                 228   44         367455  ...        RSX      2009              N\n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this dataset missing values have been denoted by '?'\n",
        "# we are replacing ? with NaN for them to be imputed down the line.\n",
        "data=data.replace('?',np.nan)"
      ],
      "metadata": {
        "id": "U-GVrPSh9l8g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values statistics\n",
        "missing_values = missing_values_table(data)\n",
        "missing_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C0Hb0i9x9l_L",
        "outputId": "2d91b9c5-7546-42db-8a75-54182024319f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1b1ea834-d6c4-4472-8545-a63754062173\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percentage of Missing Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>property_damage</th>\n",
              "      <td>360</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>police_report_available</th>\n",
              "      <td>343</td>\n",
              "      <td>34.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>collision_type</th>\n",
              "      <td>178</td>\n",
              "      <td>17.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auto_model</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auto_make</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vehicle_claim</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property_claim</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>injury_claim</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_claim_amount</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_severity</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>witnesses</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodily_injuries</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auto_year</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_location</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_city</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_state</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>authorities_contacted</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>months_as_customer</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_zip</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_number</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_bind_date</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_state</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_csl</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_deductable</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>umbrella_limit</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_sex</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_type</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_education_level</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_occupation</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_hobbies</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_relationship</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gains</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_date</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraud_reported</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b1ea834-d6c4-4472-8545-a63754062173')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b1ea834-d6c4-4472-8545-a63754062173 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b1ea834-d6c4-4472-8545-a63754062173');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             Total  Percentage of Missing Values\n",
              "property_damage                360                          36.0\n",
              "police_report_available        343                          34.3\n",
              "collision_type                 178                          17.8\n",
              "auto_model                       0                           0.0\n",
              "auto_make                        0                           0.0\n",
              "vehicle_claim                    0                           0.0\n",
              "property_claim                   0                           0.0\n",
              "injury_claim                     0                           0.0\n",
              "total_claim_amount               0                           0.0\n",
              "incident_severity                0                           0.0\n",
              "witnesses                        0                           0.0\n",
              "bodily_injuries                  0                           0.0\n",
              "auto_year                        0                           0.0\n",
              "number_of_vehicles_involved      0                           0.0\n",
              "incident_hour_of_the_day         0                           0.0\n",
              "incident_location                0                           0.0\n",
              "incident_city                    0                           0.0\n",
              "incident_state                   0                           0.0\n",
              "authorities_contacted            0                           0.0\n",
              "months_as_customer               0                           0.0\n",
              "age                              0                           0.0\n",
              "insured_zip                      0                           0.0\n",
              "policy_number                    0                           0.0\n",
              "policy_bind_date                 0                           0.0\n",
              "policy_state                     0                           0.0\n",
              "policy_csl                       0                           0.0\n",
              "policy_deductable                0                           0.0\n",
              "policy_annual_premium            0                           0.0\n",
              "umbrella_limit                   0                           0.0\n",
              "insured_sex                      0                           0.0\n",
              "incident_type                    0                           0.0\n",
              "insured_education_level          0                           0.0\n",
              "insured_occupation               0                           0.0\n",
              "insured_hobbies                  0                           0.0\n",
              "insured_relationship             0                           0.0\n",
              "capital-gains                    0                           0.0\n",
              "capital-loss                     0                           0.0\n",
              "incident_date                    0                           0.0\n",
              "fraud_reported                   0                           0.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe(include='object')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "-J2wGbJ79mBn",
        "outputId": "838b3d80-447c-406c-f40a-3290172cee4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-27eb241b-5fbd-4222-89c5-7c7213ef9020\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>policy_bind_date</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>incident_date</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_location</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_model</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>822</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>640</td>\n",
              "      <td>657</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>951</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>60</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>1/1/2006</td>\n",
              "      <td>OH</td>\n",
              "      <td>250/500</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>JD</td>\n",
              "      <td>machine-op-inspct</td>\n",
              "      <td>reading</td>\n",
              "      <td>own-child</td>\n",
              "      <td>2/2/2015</td>\n",
              "      <td>Multi-vehicle Collision</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>NY</td>\n",
              "      <td>Springfield</td>\n",
              "      <td>9935 4th Drive</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>Saab</td>\n",
              "      <td>RAM</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>352</td>\n",
              "      <td>351</td>\n",
              "      <td>537</td>\n",
              "      <td>161</td>\n",
              "      <td>93</td>\n",
              "      <td>64</td>\n",
              "      <td>183</td>\n",
              "      <td>28</td>\n",
              "      <td>419</td>\n",
              "      <td>292</td>\n",
              "      <td>354</td>\n",
              "      <td>292</td>\n",
              "      <td>262</td>\n",
              "      <td>157</td>\n",
              "      <td>1</td>\n",
              "      <td>338</td>\n",
              "      <td>343</td>\n",
              "      <td>80</td>\n",
              "      <td>43</td>\n",
              "      <td>753</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27eb241b-5fbd-4222-89c5-7c7213ef9020')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27eb241b-5fbd-4222-89c5-7c7213ef9020 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27eb241b-5fbd-4222-89c5-7c7213ef9020');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       policy_bind_date policy_state  ... auto_model fraud_reported\n",
              "count              1000         1000  ...       1000           1000\n",
              "unique              951            3  ...         39              2\n",
              "top            1/1/2006           OH  ...        RAM              N\n",
              "freq                  3          352  ...         43            753\n",
              "\n",
              "[4 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_counter(data):\n",
        "\n",
        "  colum_name =[]\n",
        "  unique_value=[]\n",
        "  # Iterate through the columns\n",
        "  for col in data:\n",
        "      if data[col].dtype == 'object':\n",
        "          # If 2 or fewer unique categories\n",
        "          colum_name.append(str(col)) \n",
        "          unique_value.append(data[col].nunique())\n",
        "  table= pd.DataFrame()\n",
        "  table['Col_name'] = colum_name\n",
        "  table['Value']= unique_value\n",
        "              \n",
        "  table=table.sort_values('Value',ascending=False)\n",
        "  return table"
      ],
      "metadata": {
        "id": "3eAD0pme9mEK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_counter(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "IzknYuuN9mGp",
        "outputId": "a48a02df-c720-4eca-df1a-206c8e37b717"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d876dcf1-d352-43c8-adb1-8bd7af011df7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Col_name</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>incident_location</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>policy_bind_date</td>\n",
              "      <td>951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>incident_date</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>auto_model</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>insured_hobbies</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>auto_make</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>insured_occupation</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>incident_city</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>insured_education_level</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>incident_state</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>insured_relationship</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>authorities_contacted</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>incident_type</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>incident_severity</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>collision_type</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>policy_state</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>policy_csl</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>property_damage</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>police_report_available</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>insured_sex</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>fraud_reported</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d876dcf1-d352-43c8-adb1-8bd7af011df7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d876dcf1-d352-43c8-adb1-8bd7af011df7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d876dcf1-d352-43c8-adb1-8bd7af011df7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   Col_name  Value\n",
              "15        incident_location   1000\n",
              "0          policy_bind_date    951\n",
              "8             incident_date     60\n",
              "19               auto_model     39\n",
              "6           insured_hobbies     20\n",
              "18                auto_make     14\n",
              "5        insured_occupation     14\n",
              "14            incident_city      7\n",
              "4   insured_education_level      7\n",
              "13           incident_state      7\n",
              "7      insured_relationship      6\n",
              "12    authorities_contacted      5\n",
              "9             incident_type      4\n",
              "11        incident_severity      4\n",
              "10           collision_type      3\n",
              "1              policy_state      3\n",
              "2                policy_csl      3\n",
              "16          property_damage      2\n",
              "17  police_report_available      2\n",
              "3               insured_sex      2\n",
              "20           fraud_reported      2"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "aaHbIELO9mLZ",
        "outputId": "fcb02a3a-534c-4b17-90ee-3ace5eb616dc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e1cba51e-554a-4409-9174-6fd3a8b00e8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_as_customer</th>\n",
              "      <th>age</th>\n",
              "      <th>policy_number</th>\n",
              "      <th>policy_deductable</th>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <th>umbrella_limit</th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>injury_claim</th>\n",
              "      <th>property_claim</th>\n",
              "      <th>vehicle_claim</th>\n",
              "      <th>auto_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>months_as_customer</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.922098</td>\n",
              "      <td>0.057555</td>\n",
              "      <td>0.026807</td>\n",
              "      <td>0.005018</td>\n",
              "      <td>0.015498</td>\n",
              "      <td>0.017895</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.020209</td>\n",
              "      <td>0.070639</td>\n",
              "      <td>0.014736</td>\n",
              "      <td>-0.010162</td>\n",
              "      <td>0.058383</td>\n",
              "      <td>0.062108</td>\n",
              "      <td>0.065329</td>\n",
              "      <td>0.034940</td>\n",
              "      <td>0.061013</td>\n",
              "      <td>-0.000292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0.922098</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.059413</td>\n",
              "      <td>0.029188</td>\n",
              "      <td>0.014404</td>\n",
              "      <td>0.018126</td>\n",
              "      <td>0.025604</td>\n",
              "      <td>-0.007075</td>\n",
              "      <td>0.007368</td>\n",
              "      <td>0.087161</td>\n",
              "      <td>0.022102</td>\n",
              "      <td>-0.015679</td>\n",
              "      <td>0.052359</td>\n",
              "      <td>0.069863</td>\n",
              "      <td>0.075522</td>\n",
              "      <td>0.060898</td>\n",
              "      <td>0.062588</td>\n",
              "      <td>0.001354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_number</th>\n",
              "      <td>0.057555</td>\n",
              "      <td>0.059413</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.006738</td>\n",
              "      <td>0.022566</td>\n",
              "      <td>0.008968</td>\n",
              "      <td>0.007083</td>\n",
              "      <td>0.009802</td>\n",
              "      <td>-0.005669</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.013432</td>\n",
              "      <td>-0.004558</td>\n",
              "      <td>-0.012661</td>\n",
              "      <td>-0.018009</td>\n",
              "      <td>-0.008762</td>\n",
              "      <td>-0.010678</td>\n",
              "      <td>-0.020184</td>\n",
              "      <td>-0.000183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_deductable</th>\n",
              "      <td>0.026807</td>\n",
              "      <td>0.029188</td>\n",
              "      <td>-0.006738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003245</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.004545</td>\n",
              "      <td>0.035212</td>\n",
              "      <td>-0.023544</td>\n",
              "      <td>0.060935</td>\n",
              "      <td>0.051214</td>\n",
              "      <td>-0.022765</td>\n",
              "      <td>0.066639</td>\n",
              "      <td>0.022839</td>\n",
              "      <td>0.039107</td>\n",
              "      <td>0.064792</td>\n",
              "      <td>0.005269</td>\n",
              "      <td>0.026105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <td>0.005018</td>\n",
              "      <td>0.014404</td>\n",
              "      <td>0.022566</td>\n",
              "      <td>-0.003245</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.006247</td>\n",
              "      <td>0.032354</td>\n",
              "      <td>-0.013738</td>\n",
              "      <td>0.023547</td>\n",
              "      <td>-0.001578</td>\n",
              "      <td>-0.045991</td>\n",
              "      <td>0.026780</td>\n",
              "      <td>0.002332</td>\n",
              "      <td>0.009094</td>\n",
              "      <td>-0.017633</td>\n",
              "      <td>-0.011654</td>\n",
              "      <td>0.020246</td>\n",
              "      <td>-0.049226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>umbrella_limit</th>\n",
              "      <td>0.015498</td>\n",
              "      <td>0.018126</td>\n",
              "      <td>0.008968</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>-0.006247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.019671</td>\n",
              "      <td>-0.047268</td>\n",
              "      <td>-0.024056</td>\n",
              "      <td>-0.023257</td>\n",
              "      <td>-0.021270</td>\n",
              "      <td>0.022743</td>\n",
              "      <td>-0.006738</td>\n",
              "      <td>-0.040344</td>\n",
              "      <td>-0.045412</td>\n",
              "      <td>-0.023790</td>\n",
              "      <td>-0.038584</td>\n",
              "      <td>0.009893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insured_zip</th>\n",
              "      <td>0.017895</td>\n",
              "      <td>0.025604</td>\n",
              "      <td>0.007083</td>\n",
              "      <td>0.004545</td>\n",
              "      <td>0.032354</td>\n",
              "      <td>0.019671</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006303</td>\n",
              "      <td>0.049372</td>\n",
              "      <td>0.008274</td>\n",
              "      <td>0.027448</td>\n",
              "      <td>0.028695</td>\n",
              "      <td>0.019805</td>\n",
              "      <td>-0.033873</td>\n",
              "      <td>-0.017495</td>\n",
              "      <td>-0.006841</td>\n",
              "      <td>-0.041083</td>\n",
              "      <td>-0.032736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gains</th>\n",
              "      <td>0.006399</td>\n",
              "      <td>-0.007075</td>\n",
              "      <td>0.009802</td>\n",
              "      <td>0.035212</td>\n",
              "      <td>-0.013738</td>\n",
              "      <td>-0.047268</td>\n",
              "      <td>0.006303</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.046904</td>\n",
              "      <td>-0.016406</td>\n",
              "      <td>0.061643</td>\n",
              "      <td>0.055829</td>\n",
              "      <td>-0.017651</td>\n",
              "      <td>0.015980</td>\n",
              "      <td>0.025934</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>0.015836</td>\n",
              "      <td>0.031398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0.020209</td>\n",
              "      <td>0.007368</td>\n",
              "      <td>-0.005669</td>\n",
              "      <td>-0.023544</td>\n",
              "      <td>0.023547</td>\n",
              "      <td>-0.024056</td>\n",
              "      <td>0.049372</td>\n",
              "      <td>-0.046904</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.025054</td>\n",
              "      <td>-0.014895</td>\n",
              "      <td>-0.024418</td>\n",
              "      <td>-0.041330</td>\n",
              "      <td>-0.036060</td>\n",
              "      <td>-0.046060</td>\n",
              "      <td>-0.022863</td>\n",
              "      <td>-0.032665</td>\n",
              "      <td>-0.056615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <td>0.070639</td>\n",
              "      <td>0.087161</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.060935</td>\n",
              "      <td>-0.001578</td>\n",
              "      <td>-0.023257</td>\n",
              "      <td>0.008274</td>\n",
              "      <td>-0.016406</td>\n",
              "      <td>-0.025054</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.120794</td>\n",
              "      <td>-0.034563</td>\n",
              "      <td>0.006527</td>\n",
              "      <td>0.217702</td>\n",
              "      <td>0.165768</td>\n",
              "      <td>0.179536</td>\n",
              "      <td>0.215626</td>\n",
              "      <td>0.021368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <td>0.014736</td>\n",
              "      <td>0.022102</td>\n",
              "      <td>0.013432</td>\n",
              "      <td>0.051214</td>\n",
              "      <td>-0.045991</td>\n",
              "      <td>-0.021270</td>\n",
              "      <td>0.027448</td>\n",
              "      <td>0.061643</td>\n",
              "      <td>-0.014895</td>\n",
              "      <td>0.120794</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014030</td>\n",
              "      <td>-0.014669</td>\n",
              "      <td>0.274278</td>\n",
              "      <td>0.224650</td>\n",
              "      <td>0.219084</td>\n",
              "      <td>0.269393</td>\n",
              "      <td>0.034554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodily_injuries</th>\n",
              "      <td>-0.010162</td>\n",
              "      <td>-0.015679</td>\n",
              "      <td>-0.004558</td>\n",
              "      <td>-0.022765</td>\n",
              "      <td>0.026780</td>\n",
              "      <td>0.022743</td>\n",
              "      <td>0.028695</td>\n",
              "      <td>0.055829</td>\n",
              "      <td>-0.024418</td>\n",
              "      <td>-0.034563</td>\n",
              "      <td>0.014030</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005606</td>\n",
              "      <td>0.047093</td>\n",
              "      <td>0.047319</td>\n",
              "      <td>0.039749</td>\n",
              "      <td>0.043449</td>\n",
              "      <td>-0.020527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>witnesses</th>\n",
              "      <td>0.058383</td>\n",
              "      <td>0.052359</td>\n",
              "      <td>-0.012661</td>\n",
              "      <td>0.066639</td>\n",
              "      <td>0.002332</td>\n",
              "      <td>-0.006738</td>\n",
              "      <td>0.019805</td>\n",
              "      <td>-0.017651</td>\n",
              "      <td>-0.041330</td>\n",
              "      <td>0.006527</td>\n",
              "      <td>-0.014669</td>\n",
              "      <td>-0.005606</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.011114</td>\n",
              "      <td>-0.024843</td>\n",
              "      <td>0.052640</td>\n",
              "      <td>-0.022564</td>\n",
              "      <td>0.045791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_claim_amount</th>\n",
              "      <td>0.062108</td>\n",
              "      <td>0.069863</td>\n",
              "      <td>-0.018009</td>\n",
              "      <td>0.022839</td>\n",
              "      <td>0.009094</td>\n",
              "      <td>-0.040344</td>\n",
              "      <td>-0.033873</td>\n",
              "      <td>0.015980</td>\n",
              "      <td>-0.036060</td>\n",
              "      <td>0.217702</td>\n",
              "      <td>0.274278</td>\n",
              "      <td>0.047093</td>\n",
              "      <td>-0.011114</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.805025</td>\n",
              "      <td>0.810686</td>\n",
              "      <td>0.982773</td>\n",
              "      <td>-0.035781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>injury_claim</th>\n",
              "      <td>0.065329</td>\n",
              "      <td>0.075522</td>\n",
              "      <td>-0.008762</td>\n",
              "      <td>0.039107</td>\n",
              "      <td>-0.017633</td>\n",
              "      <td>-0.045412</td>\n",
              "      <td>-0.017495</td>\n",
              "      <td>0.025934</td>\n",
              "      <td>-0.046060</td>\n",
              "      <td>0.165768</td>\n",
              "      <td>0.224650</td>\n",
              "      <td>0.047319</td>\n",
              "      <td>-0.024843</td>\n",
              "      <td>0.805025</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.563866</td>\n",
              "      <td>0.722878</td>\n",
              "      <td>-0.013718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property_claim</th>\n",
              "      <td>0.034940</td>\n",
              "      <td>0.060898</td>\n",
              "      <td>-0.010678</td>\n",
              "      <td>0.064792</td>\n",
              "      <td>-0.011654</td>\n",
              "      <td>-0.023790</td>\n",
              "      <td>-0.006841</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>-0.022863</td>\n",
              "      <td>0.179536</td>\n",
              "      <td>0.219084</td>\n",
              "      <td>0.039749</td>\n",
              "      <td>0.052640</td>\n",
              "      <td>0.810686</td>\n",
              "      <td>0.563866</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.732090</td>\n",
              "      <td>-0.014508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vehicle_claim</th>\n",
              "      <td>0.061013</td>\n",
              "      <td>0.062588</td>\n",
              "      <td>-0.020184</td>\n",
              "      <td>0.005269</td>\n",
              "      <td>0.020246</td>\n",
              "      <td>-0.038584</td>\n",
              "      <td>-0.041083</td>\n",
              "      <td>0.015836</td>\n",
              "      <td>-0.032665</td>\n",
              "      <td>0.215626</td>\n",
              "      <td>0.269393</td>\n",
              "      <td>0.043449</td>\n",
              "      <td>-0.022564</td>\n",
              "      <td>0.982773</td>\n",
              "      <td>0.722878</td>\n",
              "      <td>0.732090</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.042768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auto_year</th>\n",
              "      <td>-0.000292</td>\n",
              "      <td>0.001354</td>\n",
              "      <td>-0.000183</td>\n",
              "      <td>0.026105</td>\n",
              "      <td>-0.049226</td>\n",
              "      <td>0.009893</td>\n",
              "      <td>-0.032736</td>\n",
              "      <td>0.031398</td>\n",
              "      <td>-0.056615</td>\n",
              "      <td>0.021368</td>\n",
              "      <td>0.034554</td>\n",
              "      <td>-0.020527</td>\n",
              "      <td>0.045791</td>\n",
              "      <td>-0.035781</td>\n",
              "      <td>-0.013718</td>\n",
              "      <td>-0.014508</td>\n",
              "      <td>-0.042768</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1cba51e-554a-4409-9174-6fd3a8b00e8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1cba51e-554a-4409-9174-6fd3a8b00e8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1cba51e-554a-4409-9174-6fd3a8b00e8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             months_as_customer  ...  auto_year\n",
              "months_as_customer                     1.000000  ...  -0.000292\n",
              "age                                    0.922098  ...   0.001354\n",
              "policy_number                          0.057555  ...  -0.000183\n",
              "policy_deductable                      0.026807  ...   0.026105\n",
              "policy_annual_premium                  0.005018  ...  -0.049226\n",
              "umbrella_limit                         0.015498  ...   0.009893\n",
              "insured_zip                            0.017895  ...  -0.032736\n",
              "capital-gains                          0.006399  ...   0.031398\n",
              "capital-loss                           0.020209  ...  -0.056615\n",
              "incident_hour_of_the_day               0.070639  ...   0.021368\n",
              "number_of_vehicles_involved            0.014736  ...   0.034554\n",
              "bodily_injuries                       -0.010162  ...  -0.020527\n",
              "witnesses                              0.058383  ...   0.045791\n",
              "total_claim_amount                     0.062108  ...  -0.035781\n",
              "injury_claim                           0.065329  ...  -0.013718\n",
              "property_claim                         0.034940  ...  -0.014508\n",
              "vehicle_claim                          0.061013  ...  -0.042768\n",
              "auto_year                             -0.000292  ...   1.000000\n",
              "\n",
              "[18 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list of columns not necessary for prediction\n",
        "## dropping these columns because it doesn't serve any purpose to the prediction\n",
        "\n",
        "cols_to_drop=['policy_number','policy_bind_date','incident_location','incident_date','auto_model']"
      ],
      "metadata": {
        "id": "YvkeTdcT9mN2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the unnecessary columns\n",
        "data.drop(columns=cols_to_drop,inplace=True)"
      ],
      "metadata": {
        "id": "L9MmBLrf9mQX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data after dropping the columns\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "DqcYRhYw9mS3",
        "outputId": "d379f5b7-d51e-41f3-f7d5-8e899bc98665"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1685e585-a64b-4e22-ba4d-5b4f18c34fb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_as_customer</th>\n",
              "      <th>age</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>policy_deductable</th>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <th>umbrella_limit</th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>injury_claim</th>\n",
              "      <th>property_claim</th>\n",
              "      <th>vehicle_claim</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>328</td>\n",
              "      <td>48</td>\n",
              "      <td>OH</td>\n",
              "      <td>250/500</td>\n",
              "      <td>1000</td>\n",
              "      <td>1406.91</td>\n",
              "      <td>0</td>\n",
              "      <td>466132</td>\n",
              "      <td>MALE</td>\n",
              "      <td>MD</td>\n",
              "      <td>craft-repair</td>\n",
              "      <td>sleeping</td>\n",
              "      <td>husband</td>\n",
              "      <td>53300</td>\n",
              "      <td>0</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Side Collision</td>\n",
              "      <td>Major Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>SC</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>YES</td>\n",
              "      <td>71610</td>\n",
              "      <td>6510</td>\n",
              "      <td>13020</td>\n",
              "      <td>52080</td>\n",
              "      <td>Saab</td>\n",
              "      <td>2004</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>228</td>\n",
              "      <td>42</td>\n",
              "      <td>IN</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1197.22</td>\n",
              "      <td>5000000</td>\n",
              "      <td>468176</td>\n",
              "      <td>MALE</td>\n",
              "      <td>MD</td>\n",
              "      <td>machine-op-inspct</td>\n",
              "      <td>reading</td>\n",
              "      <td>other-relative</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>VA</td>\n",
              "      <td>Riverwood</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5070</td>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "      <td>3510</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>2007</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>134</td>\n",
              "      <td>29</td>\n",
              "      <td>OH</td>\n",
              "      <td>100/300</td>\n",
              "      <td>2000</td>\n",
              "      <td>1413.14</td>\n",
              "      <td>5000000</td>\n",
              "      <td>430632</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>PhD</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>own-child</td>\n",
              "      <td>35100</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-vehicle Collision</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>NY</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>NO</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NO</td>\n",
              "      <td>34650</td>\n",
              "      <td>7700</td>\n",
              "      <td>3850</td>\n",
              "      <td>23100</td>\n",
              "      <td>Dodge</td>\n",
              "      <td>2007</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>256</td>\n",
              "      <td>41</td>\n",
              "      <td>IL</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1415.74</td>\n",
              "      <td>6000000</td>\n",
              "      <td>608117</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>PhD</td>\n",
              "      <td>armed-forces</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>48900</td>\n",
              "      <td>-62400</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Front Collision</td>\n",
              "      <td>Major Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>OH</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NO</td>\n",
              "      <td>63400</td>\n",
              "      <td>6340</td>\n",
              "      <td>6340</td>\n",
              "      <td>50720</td>\n",
              "      <td>Chevrolet</td>\n",
              "      <td>2014</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>228</td>\n",
              "      <td>44</td>\n",
              "      <td>IL</td>\n",
              "      <td>500/1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1583.91</td>\n",
              "      <td>6000000</td>\n",
              "      <td>610706</td>\n",
              "      <td>MALE</td>\n",
              "      <td>Associate</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>66000</td>\n",
              "      <td>-46000</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>None</td>\n",
              "      <td>NY</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>6500</td>\n",
              "      <td>1300</td>\n",
              "      <td>650</td>\n",
              "      <td>4550</td>\n",
              "      <td>Accura</td>\n",
              "      <td>2009</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1685e585-a64b-4e22-ba4d-5b4f18c34fb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1685e585-a64b-4e22-ba4d-5b4f18c34fb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1685e585-a64b-4e22-ba4d-5b4f18c34fb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   months_as_customer  age policy_state  ...  auto_make  auto_year  fraud_reported\n",
              "0                 328   48           OH  ...       Saab       2004               Y\n",
              "1                 228   42           IN  ...   Mercedes       2007               Y\n",
              "2                 134   29           OH  ...      Dodge       2007               N\n",
              "3                 256   41           IL  ...  Chevrolet       2014               Y\n",
              "4                 228   44           IL  ...     Accura       2009               N\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbeF3z6b9mVh",
        "outputId": "0286d2dc-2059-4a56-ff87-7bb0ee88f4c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "months_as_customer               0\n",
              "age                              0\n",
              "policy_state                     0\n",
              "policy_csl                       0\n",
              "policy_deductable                0\n",
              "policy_annual_premium            0\n",
              "umbrella_limit                   0\n",
              "insured_zip                      0\n",
              "insured_sex                      0\n",
              "insured_education_level          0\n",
              "insured_occupation               0\n",
              "insured_hobbies                  0\n",
              "insured_relationship             0\n",
              "capital-gains                    0\n",
              "capital-loss                     0\n",
              "incident_type                    0\n",
              "collision_type                 178\n",
              "incident_severity                0\n",
              "authorities_contacted            0\n",
              "incident_state                   0\n",
              "incident_city                    0\n",
              "incident_hour_of_the_day         0\n",
              "number_of_vehicles_involved      0\n",
              "property_damage                360\n",
              "bodily_injuries                  0\n",
              "witnesses                        0\n",
              "police_report_available        343\n",
              "total_claim_amount               0\n",
              "injury_claim                     0\n",
              "property_claim                   0\n",
              "vehicle_claim                    0\n",
              "auto_make                        0\n",
              "auto_year                        0\n",
              "fraud_reported                   0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## The CategoricalImputer() replaces missing data in categorical variables with the string 'Missing' or by the most frequent category. \n",
        "## It works only with categorical variables. A list of variables can be indicated, or the imputer will automatically select all categorical variables in the train set.\n",
        "\n",
        "# As the columns which have missing values, they are only categorical, we'll use the categorical imputer\n",
        "# Importing the categorical imputer\n",
        "from sklearn_pandas import CategoricalImputer\n",
        "imputer = CategoricalImputer()"
      ],
      "metadata": {
        "id": "93t1mmwM9mYM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imputing the missing values from the column\n",
        "\n",
        "data['collision_type']=imputer.fit_transform(data['collision_type'])\n",
        "data['property_damage']=imputer.fit_transform(data['property_damage'])\n",
        "data['police_report_available']=imputer.fit_transform(data['police_report_available'])"
      ],
      "metadata": {
        "id": "dOLUpuuO9mbF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "HOqZkZM_9md7",
        "outputId": "e4106a0f-a3fd-403d-daff-b9a1062d6f77"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff23ae29-5ff0-48df-81c6-fc9989b6d4d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_as_customer</th>\n",
              "      <th>age</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>policy_deductable</th>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <th>umbrella_limit</th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>injury_claim</th>\n",
              "      <th>property_claim</th>\n",
              "      <th>vehicle_claim</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>328</td>\n",
              "      <td>48</td>\n",
              "      <td>OH</td>\n",
              "      <td>250/500</td>\n",
              "      <td>1000</td>\n",
              "      <td>1406.91</td>\n",
              "      <td>0</td>\n",
              "      <td>466132</td>\n",
              "      <td>MALE</td>\n",
              "      <td>MD</td>\n",
              "      <td>craft-repair</td>\n",
              "      <td>sleeping</td>\n",
              "      <td>husband</td>\n",
              "      <td>53300</td>\n",
              "      <td>0</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Side Collision</td>\n",
              "      <td>Major Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>SC</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>YES</td>\n",
              "      <td>71610</td>\n",
              "      <td>6510</td>\n",
              "      <td>13020</td>\n",
              "      <td>52080</td>\n",
              "      <td>Saab</td>\n",
              "      <td>2004</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>228</td>\n",
              "      <td>42</td>\n",
              "      <td>IN</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1197.22</td>\n",
              "      <td>5000000</td>\n",
              "      <td>468176</td>\n",
              "      <td>MALE</td>\n",
              "      <td>MD</td>\n",
              "      <td>machine-op-inspct</td>\n",
              "      <td>reading</td>\n",
              "      <td>other-relative</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>VA</td>\n",
              "      <td>Riverwood</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "      <td>5070</td>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "      <td>3510</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>2007</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>134</td>\n",
              "      <td>29</td>\n",
              "      <td>OH</td>\n",
              "      <td>100/300</td>\n",
              "      <td>2000</td>\n",
              "      <td>1413.14</td>\n",
              "      <td>5000000</td>\n",
              "      <td>430632</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>PhD</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>own-child</td>\n",
              "      <td>35100</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-vehicle Collision</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>NY</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>NO</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NO</td>\n",
              "      <td>34650</td>\n",
              "      <td>7700</td>\n",
              "      <td>3850</td>\n",
              "      <td>23100</td>\n",
              "      <td>Dodge</td>\n",
              "      <td>2007</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>256</td>\n",
              "      <td>41</td>\n",
              "      <td>IL</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1415.74</td>\n",
              "      <td>6000000</td>\n",
              "      <td>608117</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>PhD</td>\n",
              "      <td>armed-forces</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>48900</td>\n",
              "      <td>-62400</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Front Collision</td>\n",
              "      <td>Major Damage</td>\n",
              "      <td>Police</td>\n",
              "      <td>OH</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NO</td>\n",
              "      <td>63400</td>\n",
              "      <td>6340</td>\n",
              "      <td>6340</td>\n",
              "      <td>50720</td>\n",
              "      <td>Chevrolet</td>\n",
              "      <td>2014</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>228</td>\n",
              "      <td>44</td>\n",
              "      <td>IL</td>\n",
              "      <td>500/1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1583.91</td>\n",
              "      <td>6000000</td>\n",
              "      <td>610706</td>\n",
              "      <td>MALE</td>\n",
              "      <td>Associate</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>66000</td>\n",
              "      <td>-46000</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>Minor Damage</td>\n",
              "      <td>None</td>\n",
              "      <td>NY</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "      <td>6500</td>\n",
              "      <td>1300</td>\n",
              "      <td>650</td>\n",
              "      <td>4550</td>\n",
              "      <td>Accura</td>\n",
              "      <td>2009</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff23ae29-5ff0-48df-81c6-fc9989b6d4d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff23ae29-5ff0-48df-81c6-fc9989b6d4d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff23ae29-5ff0-48df-81c6-fc9989b6d4d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   months_as_customer  age policy_state  ...  auto_make  auto_year  fraud_reported\n",
              "0                 328   48           OH  ...       Saab       2004               Y\n",
              "1                 228   42           IN  ...   Mercedes       2007               Y\n",
              "2                 134   29           OH  ...      Dodge       2007               N\n",
              "3                 256   41           IL  ...  Chevrolet       2014               Y\n",
              "4                 228   44           IL  ...     Accura       2009               N\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_counter(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "YA8UqSUA9mgH",
        "outputId": "7473735c-5773-460c-aca1-4724039cb05c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-11f7ebde-51c9-4f47-9d4e-fbff195a5e83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Col_name</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>insured_hobbies</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>auto_make</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>insured_occupation</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>incident_state</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>insured_education_level</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>incident_city</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>insured_relationship</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>authorities_contacted</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>incident_type</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>incident_severity</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>policy_state</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>collision_type</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>policy_csl</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>property_damage</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>police_report_available</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>insured_sex</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>fraud_reported</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11f7ebde-51c9-4f47-9d4e-fbff195a5e83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11f7ebde-51c9-4f47-9d4e-fbff195a5e83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11f7ebde-51c9-4f47-9d4e-fbff195a5e83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   Col_name  Value\n",
              "5           insured_hobbies     20\n",
              "15                auto_make     14\n",
              "4        insured_occupation     14\n",
              "11           incident_state      7\n",
              "3   insured_education_level      7\n",
              "12            incident_city      7\n",
              "6      insured_relationship      6\n",
              "10    authorities_contacted      5\n",
              "7             incident_type      4\n",
              "9         incident_severity      4\n",
              "0              policy_state      3\n",
              "8            collision_type      3\n",
              "1                policy_csl      3\n",
              "13          property_damage      2\n",
              "14  police_report_available      2\n",
              "2               insured_sex      2\n",
              "16           fraud_reported      2"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Label encoding of data\n",
        "###  custom mapping for encoding\n",
        "\n",
        "data['insured_education_level'] = data['insured_education_level'].map({'JD' : 1, 'High School' : 2,'College':3,'Masters':4,'Associate':5,'MD':6,'PhD':7})\n",
        "data['incident_severity'] = data['incident_severity'].map({'Trivial Damage' : 1, 'Minor Damage' : 2,'Major Damage':3,'Total Loss':4})\n",
        "data['insured_sex'] = data['insured_sex'].map({'FEMALE' : 0, 'MALE' : 1})\n",
        "data['property_damage'] = data['property_damage'].map({'NO' : 0, 'YES' : 1})\n",
        "data['police_report_available'] = data['police_report_available'].map({'NO' : 0, 'YES' : 1})\n",
        "data['fraud_reported'] = data['fraud_reported'].map({'N' : 0, 'Y' : 1})"
      ],
      "metadata": {
        "id": "B3awFAuXaYd8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "NJQ0dMvNi-s2",
        "outputId": "e5464878-bfc4-4282-ead6-2698db964100"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1a9edece-edd9-401a-959f-033be6f036f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_as_customer</th>\n",
              "      <th>age</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>policy_deductable</th>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <th>umbrella_limit</th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>injury_claim</th>\n",
              "      <th>property_claim</th>\n",
              "      <th>vehicle_claim</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>328</td>\n",
              "      <td>48</td>\n",
              "      <td>OH</td>\n",
              "      <td>250/500</td>\n",
              "      <td>1000</td>\n",
              "      <td>1406.91</td>\n",
              "      <td>0</td>\n",
              "      <td>466132</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>craft-repair</td>\n",
              "      <td>sleeping</td>\n",
              "      <td>husband</td>\n",
              "      <td>53300</td>\n",
              "      <td>0</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Side Collision</td>\n",
              "      <td>3</td>\n",
              "      <td>Police</td>\n",
              "      <td>SC</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>71610</td>\n",
              "      <td>6510</td>\n",
              "      <td>13020</td>\n",
              "      <td>52080</td>\n",
              "      <td>Saab</td>\n",
              "      <td>2004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>228</td>\n",
              "      <td>42</td>\n",
              "      <td>IN</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1197.22</td>\n",
              "      <td>5000000</td>\n",
              "      <td>468176</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>machine-op-inspct</td>\n",
              "      <td>reading</td>\n",
              "      <td>other-relative</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>2</td>\n",
              "      <td>Police</td>\n",
              "      <td>VA</td>\n",
              "      <td>Riverwood</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5070</td>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "      <td>3510</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>2007</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>134</td>\n",
              "      <td>29</td>\n",
              "      <td>OH</td>\n",
              "      <td>100/300</td>\n",
              "      <td>2000</td>\n",
              "      <td>1413.14</td>\n",
              "      <td>5000000</td>\n",
              "      <td>430632</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>own-child</td>\n",
              "      <td>35100</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-vehicle Collision</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>2</td>\n",
              "      <td>Police</td>\n",
              "      <td>NY</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>34650</td>\n",
              "      <td>7700</td>\n",
              "      <td>3850</td>\n",
              "      <td>23100</td>\n",
              "      <td>Dodge</td>\n",
              "      <td>2007</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>256</td>\n",
              "      <td>41</td>\n",
              "      <td>IL</td>\n",
              "      <td>250/500</td>\n",
              "      <td>2000</td>\n",
              "      <td>1415.74</td>\n",
              "      <td>6000000</td>\n",
              "      <td>608117</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>armed-forces</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>48900</td>\n",
              "      <td>-62400</td>\n",
              "      <td>Single Vehicle Collision</td>\n",
              "      <td>Front Collision</td>\n",
              "      <td>3</td>\n",
              "      <td>Police</td>\n",
              "      <td>OH</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>63400</td>\n",
              "      <td>6340</td>\n",
              "      <td>6340</td>\n",
              "      <td>50720</td>\n",
              "      <td>Chevrolet</td>\n",
              "      <td>2014</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>228</td>\n",
              "      <td>44</td>\n",
              "      <td>IL</td>\n",
              "      <td>500/1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1583.91</td>\n",
              "      <td>6000000</td>\n",
              "      <td>610706</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>sales</td>\n",
              "      <td>board-games</td>\n",
              "      <td>unmarried</td>\n",
              "      <td>66000</td>\n",
              "      <td>-46000</td>\n",
              "      <td>Vehicle Theft</td>\n",
              "      <td>Rear Collision</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>NY</td>\n",
              "      <td>Arlington</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6500</td>\n",
              "      <td>1300</td>\n",
              "      <td>650</td>\n",
              "      <td>4550</td>\n",
              "      <td>Accura</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a9edece-edd9-401a-959f-033be6f036f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a9edece-edd9-401a-959f-033be6f036f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a9edece-edd9-401a-959f-033be6f036f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   months_as_customer  age policy_state  ...  auto_make  auto_year  fraud_reported\n",
              "0                 328   48           OH  ...       Saab       2004               1\n",
              "1                 228   42           IN  ...   Mercedes       2007               1\n",
              "2                 134   29           OH  ...      Dodge       2007               0\n",
              "3                 256   41           IL  ...  Chevrolet       2014               1\n",
              "4                 228   44           IL  ...     Accura       2009               0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Function to encode the categorical columns based on their weightage with respect to Target variable\n",
        "### Why this encoding is done ? it is done to make sure the weightage of data is passed to the model instead of just imputing some whole value or doing one hot encoding or label encoding\n",
        "\n",
        "def custom_encoder(col_list,data):\n",
        "  for i in col_list:\n",
        "    groupby = data[[i, 'fraud_reported']].groupby([i], as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
        "    data[i] = data[i].replace(tuple(groupby[i]), tuple(round(groupby['fraud_reported'],2)))\n"
      ],
      "metadata": {
        "id": "mzTxvPcE9mln"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_data1 = data.copy(deep=True)\n",
        "col_list = ['auto_make', 'incident_city', 'incident_state',\n",
        "'authorities_contacted', 'collision_type', 'incident_type', 'insured_relationship', 'insured_hobbies', 'insured_occupation', 'insured_sex', 'policy_csl', 'policy_state']\n",
        "custom_encoder(col_list,data)"
      ],
      "metadata": {
        "id": "JNJMw_5v9moV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "pqGbww3X9mrP",
        "outputId": "f0978626-96aa-4fed-e408-6530a550bc48"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-be4a0993-ec5c-47d2-bc7a-a02841e7ba22\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_as_customer</th>\n",
              "      <th>age</th>\n",
              "      <th>policy_state</th>\n",
              "      <th>policy_csl</th>\n",
              "      <th>policy_deductable</th>\n",
              "      <th>policy_annual_premium</th>\n",
              "      <th>umbrella_limit</th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>insured_sex</th>\n",
              "      <th>insured_education_level</th>\n",
              "      <th>insured_occupation</th>\n",
              "      <th>insured_hobbies</th>\n",
              "      <th>insured_relationship</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_type</th>\n",
              "      <th>collision_type</th>\n",
              "      <th>incident_severity</th>\n",
              "      <th>authorities_contacted</th>\n",
              "      <th>incident_state</th>\n",
              "      <th>incident_city</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>property_damage</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>police_report_available</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>injury_claim</th>\n",
              "      <th>property_claim</th>\n",
              "      <th>vehicle_claim</th>\n",
              "      <th>auto_make</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>328</td>\n",
              "      <td>48</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1000</td>\n",
              "      <td>1406.91</td>\n",
              "      <td>0</td>\n",
              "      <td>466132</td>\n",
              "      <td>0.26</td>\n",
              "      <td>6</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.21</td>\n",
              "      <td>53300</td>\n",
              "      <td>0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.26</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>71610</td>\n",
              "      <td>6510</td>\n",
              "      <td>13020</td>\n",
              "      <td>52080</td>\n",
              "      <td>0.22</td>\n",
              "      <td>2004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>228</td>\n",
              "      <td>42</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2000</td>\n",
              "      <td>1197.22</td>\n",
              "      <td>5000000</td>\n",
              "      <td>468176</td>\n",
              "      <td>0.26</td>\n",
              "      <td>6</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.23</td>\n",
              "      <td>2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.22</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5070</td>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "      <td>3510</td>\n",
              "      <td>0.34</td>\n",
              "      <td>2007</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>134</td>\n",
              "      <td>29</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2000</td>\n",
              "      <td>1413.14</td>\n",
              "      <td>5000000</td>\n",
              "      <td>430632</td>\n",
              "      <td>0.23</td>\n",
              "      <td>7</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.21</td>\n",
              "      <td>35100</td>\n",
              "      <td>0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.23</td>\n",
              "      <td>2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.26</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>34650</td>\n",
              "      <td>7700</td>\n",
              "      <td>3850</td>\n",
              "      <td>23100</td>\n",
              "      <td>0.25</td>\n",
              "      <td>2007</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>256</td>\n",
              "      <td>41</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2000</td>\n",
              "      <td>1415.74</td>\n",
              "      <td>6000000</td>\n",
              "      <td>608117</td>\n",
              "      <td>0.23</td>\n",
              "      <td>7</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.24</td>\n",
              "      <td>48900</td>\n",
              "      <td>-62400</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.29</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>63400</td>\n",
              "      <td>6340</td>\n",
              "      <td>6340</td>\n",
              "      <td>50720</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2014</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>228</td>\n",
              "      <td>44</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1000</td>\n",
              "      <td>1583.91</td>\n",
              "      <td>6000000</td>\n",
              "      <td>610706</td>\n",
              "      <td>0.26</td>\n",
              "      <td>5</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.24</td>\n",
              "      <td>66000</td>\n",
              "      <td>-46000</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.23</td>\n",
              "      <td>2</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.29</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6500</td>\n",
              "      <td>1300</td>\n",
              "      <td>650</td>\n",
              "      <td>4550</td>\n",
              "      <td>0.19</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be4a0993-ec5c-47d2-bc7a-a02841e7ba22')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be4a0993-ec5c-47d2-bc7a-a02841e7ba22 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be4a0993-ec5c-47d2-bc7a-a02841e7ba22');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   months_as_customer  age  policy_state  ...  auto_make  auto_year  fraud_reported\n",
              "0                 328   48          0.26  ...       0.22       2004               1\n",
              "1                 228   42          0.25  ...       0.34       2007               1\n",
              "2                 134   29          0.26  ...       0.25       2007               0\n",
              "3                 256   41          0.23  ...       0.28       2014               1\n",
              "4                 228   44          0.23  ...       0.19       2009               0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the feature and target columns\n",
        "x=data.drop('fraud_reported',axis=1)\n",
        "y=data['fraud_reported']\n",
        "print(\"Shape of x :\", x.shape)\n",
        "print(\"Shape of y :\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceWdIOAD9mzY",
        "outputId": "09f3561b-db01-4e59-9ff4-f4045579f84d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x : (1000, 33)\n",
            "Shape of y : (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's split the dataset into train and test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "print(\"Shape of x_train :\", x_train.shape)\n",
        "print(\"Shape of x_test :\", x_test.shape)\n",
        "print(\"Shape of y_train :\", y_train.shape)\n",
        "print(\"Shape of y_test :\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NA-iH8M9m42",
        "outputId": "8d8e902c-6cab-4a70-9504-8e4f01c1c508"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train : (800, 33)\n",
            "Shape of x_test : (200, 33)\n",
            "Shape of y_train : (800,)\n",
            "Shape of y_test : (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the numeric values in the dataset\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "x_train=scaler.fit_transform(x_train)\n",
        "x_test=scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "9KXOb-8Xo9fa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape,x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vCjGK2VpmAJ",
        "outputId": "a028affc-cb6e-48d6-fa76-4256405b2f6d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800, 33), (200, 33))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to plot the ROC curve and print the ROC-AUC score\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn import metrics\n",
        "\n",
        "def plot_roc(model):\n",
        "    \n",
        "    # the roc_curve() returns the values for false positive rate, true positive rate and threshold\n",
        "    # pass the actual target values and predicted probabilities to the function\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "\n",
        "    # plot the ROC curve\n",
        "    plt.plot(fpr, tpr)\n",
        "\n",
        "    # set limits for x and y axes\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.0])\n",
        "\n",
        "    # plot the straight line showing worst prediction for the model\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "\n",
        "    # add plot and axes labels\n",
        "    # set text size using 'fontsize'\n",
        "    plt.title('ROC Curve for Insurance fraud detection Classifier', fontsize = 15)\n",
        "    plt.xlabel('False positive rate (1-Specificity)', fontsize = 15)\n",
        "    plt.ylabel('True positive rate (Sensitivity)', fontsize = 15)\n",
        "\n",
        "    # add the AUC score to the plot\n",
        "    # 'x' and 'y' gives position of the text\n",
        "    # 's' is the text \n",
        "    # use round() to round-off the AUC score upto 4 digits\n",
        "    plt.text(x = 0.02, y = 0.9, s = ('AUC Score:',round(roc_auc_score(y_test, y_pred_prob),4)))\n",
        "\n",
        "    # plot the grid\n",
        "    plt.grid(True)"
      ],
      "metadata": {
        "id": "DfKIXAQWBKBF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "                 \n",
        "\n",
        "model = BalancedRandomForestClassifier(n_estimators = 100, random_state = 0)\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "y_pred_rf = model.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy: \", model.score(x_train, y_train))\n",
        "print('Testing Accuarcy: ', model.score(x_test, y_test))\n",
        "\n",
        "# making a classification report\n",
        "cr = classification_report(y_test,  y_pred_rf)\n",
        "print(cr)\n",
        "\n",
        "# making a confusion matrix\n",
        "plt.rcParams['figure.figsize'] = (5, 5)\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "print(cm)\n",
        "y_pred_prob = model.predict_proba(x_test)[:,1]\n",
        "\n",
        "# call the function 'plot_roc' to plot the ROC curve\n",
        "# pass the decision tree model to the function\n",
        "plot_roc(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "TygA6mzy9m7g",
        "outputId": "ae98896e-72ac-4f3f-dc44-d86be2734045"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9375\n",
            "Testing Accuarcy:  0.82\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.83      0.87       143\n",
            "           1       0.65      0.79      0.71        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.78      0.81      0.79       200\n",
            "weighted avg       0.84      0.82      0.82       200\n",
            "\n",
            "[[119  24]\n",
            " [ 12  45]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "!pip install lightgbm\n",
        "!pip install catboost\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "compare={\"KNN\":KNeighborsClassifier(),\"DTC\":DecisionTreeClassifier(),\"RFC\":RandomForestClassifier(),\"Adaboost\":AdaBoostClassifier(),\"xgboost\":XGBClassifier(),\n",
        "         \"Gradientboost\":GradientBoostingClassifier(),\"lgbm\":LGBMClassifier(),\"cboost\":CatBoostClassifier(),\"svc\":SVC()}\n",
        "results_score={}\n",
        "\n",
        "for model_name,model in compare.items():\n",
        "  model.fit(x_train,y_train)\n",
        "  results_score[model_name]=model.score(x_test,y_test)\n",
        "for i in results_score.items():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9hVvSuQ9m-2",
        "outputId": "9374d520-976d-4363-b7b1-bb7e81840e31"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n",
            "Learning rate set to 0.009366\n",
            "0:\tlearn: 0.6830806\ttotal: 54.7ms\tremaining: 54.6s\n",
            "1:\tlearn: 0.6732109\ttotal: 62ms\tremaining: 30.9s\n",
            "2:\tlearn: 0.6639240\ttotal: 78.7ms\tremaining: 26.1s\n",
            "3:\tlearn: 0.6545625\ttotal: 92.2ms\tremaining: 23s\n",
            "4:\tlearn: 0.6501301\ttotal: 113ms\tremaining: 22.5s\n",
            "5:\tlearn: 0.6404855\ttotal: 127ms\tremaining: 21.1s\n",
            "6:\tlearn: 0.6350564\ttotal: 136ms\tremaining: 19.4s\n",
            "7:\tlearn: 0.6309115\ttotal: 147ms\tremaining: 18.2s\n",
            "8:\tlearn: 0.6223497\ttotal: 161ms\tremaining: 17.7s\n",
            "9:\tlearn: 0.6139760\ttotal: 178ms\tremaining: 17.6s\n",
            "10:\tlearn: 0.6102736\ttotal: 191ms\tremaining: 17.2s\n",
            "11:\tlearn: 0.6024358\ttotal: 214ms\tremaining: 17.6s\n",
            "12:\tlearn: 0.5975806\ttotal: 228ms\tremaining: 17.3s\n",
            "13:\tlearn: 0.5927393\ttotal: 244ms\tremaining: 17.1s\n",
            "14:\tlearn: 0.5851279\ttotal: 259ms\tremaining: 17s\n",
            "15:\tlearn: 0.5782499\ttotal: 271ms\tremaining: 16.6s\n",
            "16:\tlearn: 0.5752336\ttotal: 285ms\tremaining: 16.5s\n",
            "17:\tlearn: 0.5679150\ttotal: 299ms\tremaining: 16.3s\n",
            "18:\tlearn: 0.5640055\ttotal: 309ms\tremaining: 16s\n",
            "19:\tlearn: 0.5606120\ttotal: 330ms\tremaining: 16.2s\n",
            "20:\tlearn: 0.5566078\ttotal: 345ms\tremaining: 16.1s\n",
            "21:\tlearn: 0.5525375\ttotal: 361ms\tremaining: 16s\n",
            "22:\tlearn: 0.5458957\ttotal: 376ms\tremaining: 16s\n",
            "23:\tlearn: 0.5401973\ttotal: 389ms\tremaining: 15.8s\n",
            "24:\tlearn: 0.5371761\ttotal: 405ms\tremaining: 15.8s\n",
            "25:\tlearn: 0.5345841\ttotal: 418ms\tremaining: 15.7s\n",
            "26:\tlearn: 0.5316606\ttotal: 431ms\tremaining: 15.5s\n",
            "27:\tlearn: 0.5258159\ttotal: 446ms\tremaining: 15.5s\n",
            "28:\tlearn: 0.5195922\ttotal: 454ms\tremaining: 15.2s\n",
            "29:\tlearn: 0.5169647\ttotal: 467ms\tremaining: 15.1s\n",
            "30:\tlearn: 0.5126992\ttotal: 470ms\tremaining: 14.7s\n",
            "31:\tlearn: 0.5086077\ttotal: 475ms\tremaining: 14.4s\n",
            "32:\tlearn: 0.5032494\ttotal: 485ms\tremaining: 14.2s\n",
            "33:\tlearn: 0.4998170\ttotal: 495ms\tremaining: 14.1s\n",
            "34:\tlearn: 0.4977755\ttotal: 500ms\tremaining: 13.8s\n",
            "35:\tlearn: 0.4954989\ttotal: 509ms\tremaining: 13.6s\n",
            "36:\tlearn: 0.4899339\ttotal: 529ms\tremaining: 13.8s\n",
            "37:\tlearn: 0.4849650\ttotal: 539ms\tremaining: 13.7s\n",
            "38:\tlearn: 0.4799612\ttotal: 550ms\tremaining: 13.5s\n",
            "39:\tlearn: 0.4750829\ttotal: 565ms\tremaining: 13.6s\n",
            "40:\tlearn: 0.4734470\ttotal: 581ms\tremaining: 13.6s\n",
            "41:\tlearn: 0.4686071\ttotal: 598ms\tremaining: 13.6s\n",
            "42:\tlearn: 0.4667859\ttotal: 619ms\tremaining: 13.8s\n",
            "43:\tlearn: 0.4622906\ttotal: 627ms\tremaining: 13.6s\n",
            "44:\tlearn: 0.4584328\ttotal: 645ms\tremaining: 13.7s\n",
            "45:\tlearn: 0.4540689\ttotal: 673ms\tremaining: 14s\n",
            "46:\tlearn: 0.4521632\ttotal: 692ms\tremaining: 14s\n",
            "47:\tlearn: 0.4477080\ttotal: 704ms\tremaining: 14s\n",
            "48:\tlearn: 0.4434594\ttotal: 714ms\tremaining: 13.9s\n",
            "49:\tlearn: 0.4406952\ttotal: 722ms\tremaining: 13.7s\n",
            "50:\tlearn: 0.4389159\ttotal: 737ms\tremaining: 13.7s\n",
            "51:\tlearn: 0.4360651\ttotal: 745ms\tremaining: 13.6s\n",
            "52:\tlearn: 0.4343195\ttotal: 751ms\tremaining: 13.4s\n",
            "53:\tlearn: 0.4315471\ttotal: 767ms\tremaining: 13.4s\n",
            "54:\tlearn: 0.4292401\ttotal: 773ms\tremaining: 13.3s\n",
            "55:\tlearn: 0.4275027\ttotal: 782ms\tremaining: 13.2s\n",
            "56:\tlearn: 0.4262717\ttotal: 791ms\tremaining: 13.1s\n",
            "57:\tlearn: 0.4225115\ttotal: 800ms\tremaining: 13s\n",
            "58:\tlearn: 0.4189248\ttotal: 809ms\tremaining: 12.9s\n",
            "59:\tlearn: 0.4157253\ttotal: 820ms\tremaining: 12.8s\n",
            "60:\tlearn: 0.4138404\ttotal: 825ms\tremaining: 12.7s\n",
            "61:\tlearn: 0.4125491\ttotal: 834ms\tremaining: 12.6s\n",
            "62:\tlearn: 0.4094881\ttotal: 843ms\tremaining: 12.5s\n",
            "63:\tlearn: 0.4082145\ttotal: 852ms\tremaining: 12.5s\n",
            "64:\tlearn: 0.4074840\ttotal: 858ms\tremaining: 12.3s\n",
            "65:\tlearn: 0.4062198\ttotal: 870ms\tremaining: 12.3s\n",
            "66:\tlearn: 0.4028046\ttotal: 875ms\tremaining: 12.2s\n",
            "67:\tlearn: 0.4017368\ttotal: 884ms\tremaining: 12.1s\n",
            "68:\tlearn: 0.3988058\ttotal: 899ms\tremaining: 12.1s\n",
            "69:\tlearn: 0.3972389\ttotal: 906ms\tremaining: 12s\n",
            "70:\tlearn: 0.3956480\ttotal: 916ms\tremaining: 12s\n",
            "71:\tlearn: 0.3927813\ttotal: 925ms\tremaining: 11.9s\n",
            "72:\tlearn: 0.3921291\ttotal: 943ms\tremaining: 12s\n",
            "73:\tlearn: 0.3912689\ttotal: 961ms\tremaining: 12s\n",
            "74:\tlearn: 0.3903185\ttotal: 971ms\tremaining: 12s\n",
            "75:\tlearn: 0.3887766\ttotal: 979ms\tremaining: 11.9s\n",
            "76:\tlearn: 0.3876265\ttotal: 989ms\tremaining: 11.9s\n",
            "77:\tlearn: 0.3867333\ttotal: 999ms\tremaining: 11.8s\n",
            "78:\tlearn: 0.3839510\ttotal: 1.01s\tremaining: 11.8s\n",
            "79:\tlearn: 0.3819701\ttotal: 1.02s\tremaining: 11.7s\n",
            "80:\tlearn: 0.3809967\ttotal: 1.02s\tremaining: 11.6s\n",
            "81:\tlearn: 0.3797070\ttotal: 1.04s\tremaining: 11.6s\n",
            "82:\tlearn: 0.3770541\ttotal: 1.06s\tremaining: 11.7s\n",
            "83:\tlearn: 0.3758341\ttotal: 1.07s\tremaining: 11.7s\n",
            "84:\tlearn: 0.3733730\ttotal: 1.09s\tremaining: 11.8s\n",
            "85:\tlearn: 0.3722454\ttotal: 1.1s\tremaining: 11.7s\n",
            "86:\tlearn: 0.3697750\ttotal: 1.12s\tremaining: 11.7s\n",
            "87:\tlearn: 0.3687350\ttotal: 1.12s\tremaining: 11.6s\n",
            "88:\tlearn: 0.3678785\ttotal: 1.13s\tremaining: 11.5s\n",
            "89:\tlearn: 0.3666884\ttotal: 1.13s\tremaining: 11.4s\n",
            "90:\tlearn: 0.3640292\ttotal: 1.14s\tremaining: 11.4s\n",
            "91:\tlearn: 0.3620119\ttotal: 1.16s\tremaining: 11.4s\n",
            "92:\tlearn: 0.3598599\ttotal: 1.16s\tremaining: 11.3s\n",
            "93:\tlearn: 0.3590434\ttotal: 1.16s\tremaining: 11.2s\n",
            "94:\tlearn: 0.3570055\ttotal: 1.17s\tremaining: 11.1s\n",
            "95:\tlearn: 0.3565295\ttotal: 1.18s\tremaining: 11.1s\n",
            "96:\tlearn: 0.3546672\ttotal: 1.19s\tremaining: 11s\n",
            "97:\tlearn: 0.3531243\ttotal: 1.2s\tremaining: 11s\n",
            "98:\tlearn: 0.3512407\ttotal: 1.2s\tremaining: 10.9s\n",
            "99:\tlearn: 0.3502132\ttotal: 1.21s\tremaining: 10.9s\n",
            "100:\tlearn: 0.3482700\ttotal: 1.21s\tremaining: 10.8s\n",
            "101:\tlearn: 0.3474651\ttotal: 1.22s\tremaining: 10.7s\n",
            "102:\tlearn: 0.3455795\ttotal: 1.22s\tremaining: 10.6s\n",
            "103:\tlearn: 0.3444234\ttotal: 1.22s\tremaining: 10.5s\n",
            "104:\tlearn: 0.3437029\ttotal: 1.23s\tremaining: 10.5s\n",
            "105:\tlearn: 0.3428926\ttotal: 1.23s\tremaining: 10.4s\n",
            "106:\tlearn: 0.3409356\ttotal: 1.24s\tremaining: 10.3s\n",
            "107:\tlearn: 0.3402028\ttotal: 1.24s\tremaining: 10.2s\n",
            "108:\tlearn: 0.3393893\ttotal: 1.24s\tremaining: 10.2s\n",
            "109:\tlearn: 0.3385345\ttotal: 1.25s\tremaining: 10.1s\n",
            "110:\tlearn: 0.3369444\ttotal: 1.25s\tremaining: 10s\n",
            "111:\tlearn: 0.3353477\ttotal: 1.25s\tremaining: 9.94s\n",
            "112:\tlearn: 0.3344714\ttotal: 1.26s\tremaining: 9.87s\n",
            "113:\tlearn: 0.3329729\ttotal: 1.26s\tremaining: 9.8s\n",
            "114:\tlearn: 0.3322084\ttotal: 1.26s\tremaining: 9.73s\n",
            "115:\tlearn: 0.3311800\ttotal: 1.27s\tremaining: 9.67s\n",
            "116:\tlearn: 0.3297281\ttotal: 1.28s\tremaining: 9.64s\n",
            "117:\tlearn: 0.3286175\ttotal: 1.28s\tremaining: 9.61s\n",
            "118:\tlearn: 0.3277173\ttotal: 1.29s\tremaining: 9.54s\n",
            "119:\tlearn: 0.3262335\ttotal: 1.29s\tremaining: 9.49s\n",
            "120:\tlearn: 0.3246197\ttotal: 1.3s\tremaining: 9.44s\n",
            "121:\tlearn: 0.3239019\ttotal: 1.31s\tremaining: 9.42s\n",
            "122:\tlearn: 0.3232390\ttotal: 1.32s\tremaining: 9.41s\n",
            "123:\tlearn: 0.3225090\ttotal: 1.33s\tremaining: 9.37s\n",
            "124:\tlearn: 0.3217358\ttotal: 1.34s\tremaining: 9.39s\n",
            "125:\tlearn: 0.3211464\ttotal: 1.35s\tremaining: 9.36s\n",
            "126:\tlearn: 0.3207420\ttotal: 1.36s\tremaining: 9.38s\n",
            "127:\tlearn: 0.3201958\ttotal: 1.37s\tremaining: 9.36s\n",
            "128:\tlearn: 0.3193479\ttotal: 1.38s\tremaining: 9.35s\n",
            "129:\tlearn: 0.3186672\ttotal: 1.39s\tremaining: 9.3s\n",
            "130:\tlearn: 0.3181689\ttotal: 1.4s\tremaining: 9.29s\n",
            "131:\tlearn: 0.3173991\ttotal: 1.41s\tremaining: 9.28s\n",
            "132:\tlearn: 0.3168822\ttotal: 1.42s\tremaining: 9.23s\n",
            "133:\tlearn: 0.3163233\ttotal: 1.45s\tremaining: 9.39s\n",
            "134:\tlearn: 0.3155714\ttotal: 1.47s\tremaining: 9.4s\n",
            "135:\tlearn: 0.3150352\ttotal: 1.49s\tremaining: 9.47s\n",
            "136:\tlearn: 0.3144418\ttotal: 1.51s\tremaining: 9.49s\n",
            "137:\tlearn: 0.3136005\ttotal: 1.51s\tremaining: 9.47s\n",
            "138:\tlearn: 0.3127364\ttotal: 1.52s\tremaining: 9.45s\n",
            "139:\tlearn: 0.3121020\ttotal: 1.54s\tremaining: 9.44s\n",
            "140:\tlearn: 0.3115152\ttotal: 1.55s\tremaining: 9.46s\n",
            "141:\tlearn: 0.3103179\ttotal: 1.57s\tremaining: 9.48s\n",
            "142:\tlearn: 0.3096205\ttotal: 1.58s\tremaining: 9.46s\n",
            "143:\tlearn: 0.3089291\ttotal: 1.59s\tremaining: 9.46s\n",
            "144:\tlearn: 0.3077028\ttotal: 1.6s\tremaining: 9.45s\n",
            "145:\tlearn: 0.3069940\ttotal: 1.61s\tremaining: 9.43s\n",
            "146:\tlearn: 0.3065035\ttotal: 1.62s\tremaining: 9.41s\n",
            "147:\tlearn: 0.3053456\ttotal: 1.63s\tremaining: 9.41s\n",
            "148:\tlearn: 0.3044682\ttotal: 1.64s\tremaining: 9.37s\n",
            "149:\tlearn: 0.3038993\ttotal: 1.65s\tremaining: 9.35s\n",
            "150:\tlearn: 0.3033790\ttotal: 1.66s\tremaining: 9.36s\n",
            "151:\tlearn: 0.3028157\ttotal: 1.68s\tremaining: 9.36s\n",
            "152:\tlearn: 0.3021674\ttotal: 1.69s\tremaining: 9.35s\n",
            "153:\tlearn: 0.3007920\ttotal: 1.7s\tremaining: 9.36s\n",
            "154:\tlearn: 0.2996305\ttotal: 1.71s\tremaining: 9.33s\n",
            "155:\tlearn: 0.2987189\ttotal: 1.73s\tremaining: 9.34s\n",
            "156:\tlearn: 0.2979611\ttotal: 1.73s\tremaining: 9.31s\n",
            "157:\tlearn: 0.2975164\ttotal: 1.74s\tremaining: 9.28s\n",
            "158:\tlearn: 0.2970323\ttotal: 1.75s\tremaining: 9.27s\n",
            "159:\tlearn: 0.2962526\ttotal: 1.76s\tremaining: 9.25s\n",
            "160:\tlearn: 0.2953378\ttotal: 1.77s\tremaining: 9.21s\n",
            "161:\tlearn: 0.2948570\ttotal: 1.77s\tremaining: 9.17s\n",
            "162:\tlearn: 0.2937816\ttotal: 1.78s\tremaining: 9.12s\n",
            "163:\tlearn: 0.2929138\ttotal: 1.78s\tremaining: 9.07s\n",
            "164:\tlearn: 0.2926036\ttotal: 1.78s\tremaining: 9.03s\n",
            "165:\tlearn: 0.2919865\ttotal: 1.79s\tremaining: 8.98s\n",
            "166:\tlearn: 0.2915567\ttotal: 1.79s\tremaining: 8.94s\n",
            "167:\tlearn: 0.2911736\ttotal: 1.8s\tremaining: 8.89s\n",
            "168:\tlearn: 0.2907129\ttotal: 1.8s\tremaining: 8.86s\n",
            "169:\tlearn: 0.2902124\ttotal: 1.81s\tremaining: 8.82s\n",
            "170:\tlearn: 0.2895412\ttotal: 1.81s\tremaining: 8.78s\n",
            "171:\tlearn: 0.2891996\ttotal: 1.81s\tremaining: 8.74s\n",
            "172:\tlearn: 0.2888391\ttotal: 1.82s\tremaining: 8.7s\n",
            "173:\tlearn: 0.2881253\ttotal: 1.82s\tremaining: 8.66s\n",
            "174:\tlearn: 0.2873753\ttotal: 1.83s\tremaining: 8.63s\n",
            "175:\tlearn: 0.2869509\ttotal: 1.83s\tremaining: 8.59s\n",
            "176:\tlearn: 0.2859565\ttotal: 1.84s\tremaining: 8.55s\n",
            "177:\tlearn: 0.2854938\ttotal: 1.84s\tremaining: 8.51s\n",
            "178:\tlearn: 0.2852321\ttotal: 1.85s\tremaining: 8.5s\n",
            "179:\tlearn: 0.2848092\ttotal: 1.86s\tremaining: 8.46s\n",
            "180:\tlearn: 0.2845174\ttotal: 1.86s\tremaining: 8.43s\n",
            "181:\tlearn: 0.2835338\ttotal: 1.87s\tremaining: 8.39s\n",
            "182:\tlearn: 0.2826151\ttotal: 1.87s\tremaining: 8.35s\n",
            "183:\tlearn: 0.2821716\ttotal: 1.87s\tremaining: 8.31s\n",
            "184:\tlearn: 0.2816434\ttotal: 1.88s\tremaining: 8.28s\n",
            "185:\tlearn: 0.2810931\ttotal: 1.89s\tremaining: 8.28s\n",
            "186:\tlearn: 0.2808466\ttotal: 1.9s\tremaining: 8.24s\n",
            "187:\tlearn: 0.2802950\ttotal: 1.9s\tremaining: 8.21s\n",
            "188:\tlearn: 0.2799591\ttotal: 1.9s\tremaining: 8.17s\n",
            "189:\tlearn: 0.2790250\ttotal: 1.91s\tremaining: 8.13s\n",
            "190:\tlearn: 0.2784556\ttotal: 1.92s\tremaining: 8.14s\n",
            "191:\tlearn: 0.2777308\ttotal: 1.93s\tremaining: 8.13s\n",
            "192:\tlearn: 0.2770515\ttotal: 1.94s\tremaining: 8.11s\n",
            "193:\tlearn: 0.2764570\ttotal: 1.94s\tremaining: 8.07s\n",
            "194:\tlearn: 0.2757153\ttotal: 1.95s\tremaining: 8.04s\n",
            "195:\tlearn: 0.2752711\ttotal: 1.95s\tremaining: 8.01s\n",
            "196:\tlearn: 0.2749888\ttotal: 1.96s\tremaining: 7.97s\n",
            "197:\tlearn: 0.2746454\ttotal: 1.96s\tremaining: 7.94s\n",
            "198:\tlearn: 0.2740861\ttotal: 1.97s\tremaining: 7.91s\n",
            "199:\tlearn: 0.2735919\ttotal: 1.97s\tremaining: 7.88s\n",
            "200:\tlearn: 0.2727046\ttotal: 1.98s\tremaining: 7.85s\n",
            "201:\tlearn: 0.2720985\ttotal: 1.98s\tremaining: 7.82s\n",
            "202:\tlearn: 0.2716560\ttotal: 1.98s\tremaining: 7.79s\n",
            "203:\tlearn: 0.2711467\ttotal: 1.99s\tremaining: 7.75s\n",
            "204:\tlearn: 0.2705336\ttotal: 1.99s\tremaining: 7.72s\n",
            "205:\tlearn: 0.2698917\ttotal: 2s\tremaining: 7.69s\n",
            "206:\tlearn: 0.2691058\ttotal: 2s\tremaining: 7.66s\n",
            "207:\tlearn: 0.2684425\ttotal: 2s\tremaining: 7.63s\n",
            "208:\tlearn: 0.2677209\ttotal: 2.01s\tremaining: 7.6s\n",
            "209:\tlearn: 0.2669321\ttotal: 2.01s\tremaining: 7.57s\n",
            "210:\tlearn: 0.2665695\ttotal: 2.02s\tremaining: 7.54s\n",
            "211:\tlearn: 0.2660028\ttotal: 2.02s\tremaining: 7.52s\n",
            "212:\tlearn: 0.2654487\ttotal: 2.03s\tremaining: 7.51s\n",
            "213:\tlearn: 0.2648544\ttotal: 2.04s\tremaining: 7.49s\n",
            "214:\tlearn: 0.2641055\ttotal: 2.05s\tremaining: 7.48s\n",
            "215:\tlearn: 0.2636882\ttotal: 2.05s\tremaining: 7.45s\n",
            "216:\tlearn: 0.2633418\ttotal: 2.06s\tremaining: 7.42s\n",
            "217:\tlearn: 0.2630775\ttotal: 2.06s\tremaining: 7.39s\n",
            "218:\tlearn: 0.2627172\ttotal: 2.06s\tremaining: 7.36s\n",
            "219:\tlearn: 0.2622063\ttotal: 2.07s\tremaining: 7.35s\n",
            "220:\tlearn: 0.2618016\ttotal: 2.08s\tremaining: 7.33s\n",
            "221:\tlearn: 0.2613054\ttotal: 2.08s\tremaining: 7.29s\n",
            "222:\tlearn: 0.2607802\ttotal: 2.08s\tremaining: 7.27s\n",
            "223:\tlearn: 0.2599834\ttotal: 2.09s\tremaining: 7.24s\n",
            "224:\tlearn: 0.2592445\ttotal: 2.09s\tremaining: 7.21s\n",
            "225:\tlearn: 0.2588893\ttotal: 2.1s\tremaining: 7.18s\n",
            "226:\tlearn: 0.2581091\ttotal: 2.1s\tremaining: 7.16s\n",
            "227:\tlearn: 0.2577464\ttotal: 2.1s\tremaining: 7.13s\n",
            "228:\tlearn: 0.2572974\ttotal: 2.11s\tremaining: 7.1s\n",
            "229:\tlearn: 0.2565055\ttotal: 2.11s\tremaining: 7.07s\n",
            "230:\tlearn: 0.2560658\ttotal: 2.12s\tremaining: 7.06s\n",
            "231:\tlearn: 0.2554877\ttotal: 2.12s\tremaining: 7.03s\n",
            "232:\tlearn: 0.2551838\ttotal: 2.13s\tremaining: 7s\n",
            "233:\tlearn: 0.2547216\ttotal: 2.13s\tremaining: 6.98s\n",
            "234:\tlearn: 0.2542881\ttotal: 2.14s\tremaining: 6.95s\n",
            "235:\tlearn: 0.2539312\ttotal: 2.14s\tremaining: 6.93s\n",
            "236:\tlearn: 0.2534377\ttotal: 2.14s\tremaining: 6.91s\n",
            "237:\tlearn: 0.2530678\ttotal: 2.15s\tremaining: 6.89s\n",
            "238:\tlearn: 0.2528980\ttotal: 2.16s\tremaining: 6.87s\n",
            "239:\tlearn: 0.2521716\ttotal: 2.16s\tremaining: 6.85s\n",
            "240:\tlearn: 0.2517061\ttotal: 2.17s\tremaining: 6.82s\n",
            "241:\tlearn: 0.2511260\ttotal: 2.17s\tremaining: 6.8s\n",
            "242:\tlearn: 0.2507405\ttotal: 2.17s\tremaining: 6.77s\n",
            "243:\tlearn: 0.2504314\ttotal: 2.18s\tremaining: 6.75s\n",
            "244:\tlearn: 0.2499596\ttotal: 2.18s\tremaining: 6.73s\n",
            "245:\tlearn: 0.2494370\ttotal: 2.19s\tremaining: 6.71s\n",
            "246:\tlearn: 0.2492324\ttotal: 2.19s\tremaining: 6.69s\n",
            "247:\tlearn: 0.2485575\ttotal: 2.2s\tremaining: 6.67s\n",
            "248:\tlearn: 0.2481590\ttotal: 2.2s\tremaining: 6.64s\n",
            "249:\tlearn: 0.2477910\ttotal: 2.21s\tremaining: 6.62s\n",
            "250:\tlearn: 0.2470880\ttotal: 2.21s\tremaining: 6.6s\n",
            "251:\tlearn: 0.2466518\ttotal: 2.22s\tremaining: 6.58s\n",
            "252:\tlearn: 0.2462531\ttotal: 2.22s\tremaining: 6.56s\n",
            "253:\tlearn: 0.2459437\ttotal: 2.23s\tremaining: 6.54s\n",
            "254:\tlearn: 0.2456439\ttotal: 2.23s\tremaining: 6.51s\n",
            "255:\tlearn: 0.2453359\ttotal: 2.23s\tremaining: 6.49s\n",
            "256:\tlearn: 0.2449279\ttotal: 2.24s\tremaining: 6.48s\n",
            "257:\tlearn: 0.2446179\ttotal: 2.25s\tremaining: 6.48s\n",
            "258:\tlearn: 0.2442984\ttotal: 2.26s\tremaining: 6.47s\n",
            "259:\tlearn: 0.2439635\ttotal: 2.28s\tremaining: 6.48s\n",
            "260:\tlearn: 0.2434447\ttotal: 2.29s\tremaining: 6.49s\n",
            "261:\tlearn: 0.2430495\ttotal: 2.3s\tremaining: 6.48s\n",
            "262:\tlearn: 0.2427617\ttotal: 2.31s\tremaining: 6.48s\n",
            "263:\tlearn: 0.2420154\ttotal: 2.33s\tremaining: 6.49s\n",
            "264:\tlearn: 0.2413961\ttotal: 2.34s\tremaining: 6.5s\n",
            "265:\tlearn: 0.2409927\ttotal: 2.35s\tremaining: 6.49s\n",
            "266:\tlearn: 0.2404867\ttotal: 2.36s\tremaining: 6.48s\n",
            "267:\tlearn: 0.2401658\ttotal: 2.38s\tremaining: 6.49s\n",
            "268:\tlearn: 0.2398830\ttotal: 2.39s\tremaining: 6.49s\n",
            "269:\tlearn: 0.2396375\ttotal: 2.39s\tremaining: 6.47s\n",
            "270:\tlearn: 0.2392532\ttotal: 2.4s\tremaining: 6.46s\n",
            "271:\tlearn: 0.2388104\ttotal: 2.41s\tremaining: 6.45s\n",
            "272:\tlearn: 0.2385253\ttotal: 2.42s\tremaining: 6.44s\n",
            "273:\tlearn: 0.2381162\ttotal: 2.43s\tremaining: 6.45s\n",
            "274:\tlearn: 0.2376578\ttotal: 2.44s\tremaining: 6.45s\n",
            "275:\tlearn: 0.2373761\ttotal: 2.47s\tremaining: 6.47s\n",
            "276:\tlearn: 0.2368416\ttotal: 2.47s\tremaining: 6.46s\n",
            "277:\tlearn: 0.2364683\ttotal: 2.48s\tremaining: 6.45s\n",
            "278:\tlearn: 0.2361279\ttotal: 2.49s\tremaining: 6.44s\n",
            "279:\tlearn: 0.2357993\ttotal: 2.5s\tremaining: 6.42s\n",
            "280:\tlearn: 0.2353200\ttotal: 2.51s\tremaining: 6.43s\n",
            "281:\tlearn: 0.2350071\ttotal: 2.52s\tremaining: 6.42s\n",
            "282:\tlearn: 0.2347183\ttotal: 2.53s\tremaining: 6.41s\n",
            "283:\tlearn: 0.2341497\ttotal: 2.54s\tremaining: 6.41s\n",
            "284:\tlearn: 0.2339813\ttotal: 2.56s\tremaining: 6.41s\n",
            "285:\tlearn: 0.2333589\ttotal: 2.57s\tremaining: 6.41s\n",
            "286:\tlearn: 0.2330833\ttotal: 2.58s\tremaining: 6.4s\n",
            "287:\tlearn: 0.2323833\ttotal: 2.59s\tremaining: 6.39s\n",
            "288:\tlearn: 0.2320639\ttotal: 2.6s\tremaining: 6.39s\n",
            "289:\tlearn: 0.2316765\ttotal: 2.6s\tremaining: 6.38s\n",
            "290:\tlearn: 0.2312023\ttotal: 2.61s\tremaining: 6.37s\n",
            "291:\tlearn: 0.2306771\ttotal: 2.63s\tremaining: 6.37s\n",
            "292:\tlearn: 0.2303559\ttotal: 2.63s\tremaining: 6.36s\n",
            "293:\tlearn: 0.2297596\ttotal: 2.64s\tremaining: 6.34s\n",
            "294:\tlearn: 0.2294576\ttotal: 2.65s\tremaining: 6.34s\n",
            "295:\tlearn: 0.2289230\ttotal: 2.66s\tremaining: 6.33s\n",
            "296:\tlearn: 0.2286139\ttotal: 2.67s\tremaining: 6.32s\n",
            "297:\tlearn: 0.2283012\ttotal: 2.68s\tremaining: 6.31s\n",
            "298:\tlearn: 0.2278407\ttotal: 2.69s\tremaining: 6.31s\n",
            "299:\tlearn: 0.2274974\ttotal: 2.7s\tremaining: 6.29s\n",
            "300:\tlearn: 0.2270039\ttotal: 2.71s\tremaining: 6.29s\n",
            "301:\tlearn: 0.2267416\ttotal: 2.72s\tremaining: 6.28s\n",
            "302:\tlearn: 0.2262601\ttotal: 2.73s\tremaining: 6.27s\n",
            "303:\tlearn: 0.2261270\ttotal: 2.74s\tremaining: 6.28s\n",
            "304:\tlearn: 0.2256614\ttotal: 2.75s\tremaining: 6.28s\n",
            "305:\tlearn: 0.2253030\ttotal: 2.76s\tremaining: 6.26s\n",
            "306:\tlearn: 0.2251033\ttotal: 2.77s\tremaining: 6.26s\n",
            "307:\tlearn: 0.2248294\ttotal: 2.78s\tremaining: 6.25s\n",
            "308:\tlearn: 0.2242538\ttotal: 2.8s\tremaining: 6.25s\n",
            "309:\tlearn: 0.2240749\ttotal: 2.8s\tremaining: 6.23s\n",
            "310:\tlearn: 0.2236728\ttotal: 2.8s\tremaining: 6.21s\n",
            "311:\tlearn: 0.2234265\ttotal: 2.81s\tremaining: 6.2s\n",
            "312:\tlearn: 0.2230226\ttotal: 2.83s\tremaining: 6.2s\n",
            "313:\tlearn: 0.2227725\ttotal: 2.83s\tremaining: 6.2s\n",
            "314:\tlearn: 0.2224429\ttotal: 2.85s\tremaining: 6.19s\n",
            "315:\tlearn: 0.2221701\ttotal: 2.85s\tremaining: 6.18s\n",
            "316:\tlearn: 0.2218624\ttotal: 2.87s\tremaining: 6.17s\n",
            "317:\tlearn: 0.2212814\ttotal: 2.87s\tremaining: 6.16s\n",
            "318:\tlearn: 0.2208953\ttotal: 2.88s\tremaining: 6.15s\n",
            "319:\tlearn: 0.2206400\ttotal: 2.88s\tremaining: 6.13s\n",
            "320:\tlearn: 0.2202812\ttotal: 2.89s\tremaining: 6.11s\n",
            "321:\tlearn: 0.2201291\ttotal: 2.89s\tremaining: 6.09s\n",
            "322:\tlearn: 0.2196284\ttotal: 2.89s\tremaining: 6.07s\n",
            "323:\tlearn: 0.2193950\ttotal: 2.9s\tremaining: 6.05s\n",
            "324:\tlearn: 0.2190775\ttotal: 2.9s\tremaining: 6.03s\n",
            "325:\tlearn: 0.2188858\ttotal: 2.9s\tremaining: 6s\n",
            "326:\tlearn: 0.2186536\ttotal: 2.91s\tremaining: 5.99s\n",
            "327:\tlearn: 0.2184006\ttotal: 2.91s\tremaining: 5.97s\n",
            "328:\tlearn: 0.2180888\ttotal: 2.92s\tremaining: 5.95s\n",
            "329:\tlearn: 0.2176619\ttotal: 2.92s\tremaining: 5.93s\n",
            "330:\tlearn: 0.2174004\ttotal: 2.93s\tremaining: 5.91s\n",
            "331:\tlearn: 0.2171398\ttotal: 2.93s\tremaining: 5.89s\n",
            "332:\tlearn: 0.2169437\ttotal: 2.93s\tremaining: 5.88s\n",
            "333:\tlearn: 0.2166424\ttotal: 2.94s\tremaining: 5.87s\n",
            "334:\tlearn: 0.2163494\ttotal: 2.95s\tremaining: 5.86s\n",
            "335:\tlearn: 0.2159716\ttotal: 2.98s\tremaining: 5.89s\n",
            "336:\tlearn: 0.2155604\ttotal: 2.98s\tremaining: 5.87s\n",
            "337:\tlearn: 0.2153054\ttotal: 2.98s\tremaining: 5.85s\n",
            "338:\tlearn: 0.2151155\ttotal: 2.99s\tremaining: 5.83s\n",
            "339:\tlearn: 0.2147617\ttotal: 3s\tremaining: 5.82s\n",
            "340:\tlearn: 0.2144075\ttotal: 3.01s\tremaining: 5.81s\n",
            "341:\tlearn: 0.2139835\ttotal: 3.01s\tremaining: 5.8s\n",
            "342:\tlearn: 0.2137642\ttotal: 3.03s\tremaining: 5.8s\n",
            "343:\tlearn: 0.2134440\ttotal: 3.04s\tremaining: 5.79s\n",
            "344:\tlearn: 0.2132355\ttotal: 3.04s\tremaining: 5.78s\n",
            "345:\tlearn: 0.2129074\ttotal: 3.05s\tremaining: 5.77s\n",
            "346:\tlearn: 0.2125917\ttotal: 3.06s\tremaining: 5.77s\n",
            "347:\tlearn: 0.2123177\ttotal: 3.07s\tremaining: 5.76s\n",
            "348:\tlearn: 0.2121090\ttotal: 3.08s\tremaining: 5.75s\n",
            "349:\tlearn: 0.2117088\ttotal: 3.09s\tremaining: 5.75s\n",
            "350:\tlearn: 0.2113979\ttotal: 3.1s\tremaining: 5.74s\n",
            "351:\tlearn: 0.2110325\ttotal: 3.12s\tremaining: 5.74s\n",
            "352:\tlearn: 0.2108887\ttotal: 3.13s\tremaining: 5.73s\n",
            "353:\tlearn: 0.2105777\ttotal: 3.14s\tremaining: 5.72s\n",
            "354:\tlearn: 0.2103776\ttotal: 3.15s\tremaining: 5.72s\n",
            "355:\tlearn: 0.2100996\ttotal: 3.15s\tremaining: 5.71s\n",
            "356:\tlearn: 0.2096855\ttotal: 3.16s\tremaining: 5.69s\n",
            "357:\tlearn: 0.2093905\ttotal: 3.16s\tremaining: 5.67s\n",
            "358:\tlearn: 0.2090105\ttotal: 3.17s\tremaining: 5.66s\n",
            "359:\tlearn: 0.2087425\ttotal: 3.17s\tremaining: 5.64s\n",
            "360:\tlearn: 0.2086674\ttotal: 3.17s\tremaining: 5.62s\n",
            "361:\tlearn: 0.2083020\ttotal: 3.18s\tremaining: 5.6s\n",
            "362:\tlearn: 0.2080486\ttotal: 3.18s\tremaining: 5.59s\n",
            "363:\tlearn: 0.2076798\ttotal: 3.22s\tremaining: 5.62s\n",
            "364:\tlearn: 0.2074744\ttotal: 3.23s\tremaining: 5.62s\n",
            "365:\tlearn: 0.2072660\ttotal: 3.24s\tremaining: 5.62s\n",
            "366:\tlearn: 0.2068646\ttotal: 3.25s\tremaining: 5.61s\n",
            "367:\tlearn: 0.2066162\ttotal: 3.26s\tremaining: 5.6s\n",
            "368:\tlearn: 0.2063787\ttotal: 3.27s\tremaining: 5.59s\n",
            "369:\tlearn: 0.2060326\ttotal: 3.27s\tremaining: 5.57s\n",
            "370:\tlearn: 0.2058259\ttotal: 3.28s\tremaining: 5.55s\n",
            "371:\tlearn: 0.2053525\ttotal: 3.29s\tremaining: 5.55s\n",
            "372:\tlearn: 0.2050344\ttotal: 3.29s\tremaining: 5.53s\n",
            "373:\tlearn: 0.2047141\ttotal: 3.3s\tremaining: 5.53s\n",
            "374:\tlearn: 0.2043147\ttotal: 3.32s\tremaining: 5.53s\n",
            "375:\tlearn: 0.2040514\ttotal: 3.32s\tremaining: 5.51s\n",
            "376:\tlearn: 0.2037923\ttotal: 3.33s\tremaining: 5.49s\n",
            "377:\tlearn: 0.2033998\ttotal: 3.33s\tremaining: 5.48s\n",
            "378:\tlearn: 0.2032688\ttotal: 3.33s\tremaining: 5.46s\n",
            "379:\tlearn: 0.2029471\ttotal: 3.34s\tremaining: 5.44s\n",
            "380:\tlearn: 0.2027636\ttotal: 3.34s\tremaining: 5.43s\n",
            "381:\tlearn: 0.2024708\ttotal: 3.34s\tremaining: 5.41s\n",
            "382:\tlearn: 0.2021313\ttotal: 3.35s\tremaining: 5.39s\n",
            "383:\tlearn: 0.2018932\ttotal: 3.35s\tremaining: 5.38s\n",
            "384:\tlearn: 0.2015448\ttotal: 3.36s\tremaining: 5.36s\n",
            "385:\tlearn: 0.2012469\ttotal: 3.36s\tremaining: 5.34s\n",
            "386:\tlearn: 0.2009290\ttotal: 3.36s\tremaining: 5.33s\n",
            "387:\tlearn: 0.2005770\ttotal: 3.37s\tremaining: 5.31s\n",
            "388:\tlearn: 0.2003506\ttotal: 3.37s\tremaining: 5.29s\n",
            "389:\tlearn: 0.2001546\ttotal: 3.37s\tremaining: 5.28s\n",
            "390:\tlearn: 0.1998959\ttotal: 3.38s\tremaining: 5.26s\n",
            "391:\tlearn: 0.1995086\ttotal: 3.38s\tremaining: 5.25s\n",
            "392:\tlearn: 0.1992686\ttotal: 3.39s\tremaining: 5.23s\n",
            "393:\tlearn: 0.1989201\ttotal: 3.39s\tremaining: 5.21s\n",
            "394:\tlearn: 0.1987385\ttotal: 3.39s\tremaining: 5.2s\n",
            "395:\tlearn: 0.1985339\ttotal: 3.4s\tremaining: 5.18s\n",
            "396:\tlearn: 0.1982103\ttotal: 3.4s\tremaining: 5.17s\n",
            "397:\tlearn: 0.1980676\ttotal: 3.4s\tremaining: 5.15s\n",
            "398:\tlearn: 0.1977489\ttotal: 3.41s\tremaining: 5.13s\n",
            "399:\tlearn: 0.1974600\ttotal: 3.41s\tremaining: 5.12s\n",
            "400:\tlearn: 0.1971885\ttotal: 3.42s\tremaining: 5.1s\n",
            "401:\tlearn: 0.1968946\ttotal: 3.42s\tremaining: 5.09s\n",
            "402:\tlearn: 0.1966868\ttotal: 3.42s\tremaining: 5.07s\n",
            "403:\tlearn: 0.1963293\ttotal: 3.44s\tremaining: 5.08s\n",
            "404:\tlearn: 0.1960891\ttotal: 3.45s\tremaining: 5.06s\n",
            "405:\tlearn: 0.1959520\ttotal: 3.45s\tremaining: 5.05s\n",
            "406:\tlearn: 0.1958341\ttotal: 3.46s\tremaining: 5.03s\n",
            "407:\tlearn: 0.1954791\ttotal: 3.46s\tremaining: 5.02s\n",
            "408:\tlearn: 0.1953251\ttotal: 3.46s\tremaining: 5s\n",
            "409:\tlearn: 0.1949822\ttotal: 3.47s\tremaining: 4.99s\n",
            "410:\tlearn: 0.1947108\ttotal: 3.47s\tremaining: 4.97s\n",
            "411:\tlearn: 0.1943626\ttotal: 3.47s\tremaining: 4.96s\n",
            "412:\tlearn: 0.1941032\ttotal: 3.48s\tremaining: 4.94s\n",
            "413:\tlearn: 0.1938280\ttotal: 3.48s\tremaining: 4.93s\n",
            "414:\tlearn: 0.1934315\ttotal: 3.49s\tremaining: 4.92s\n",
            "415:\tlearn: 0.1932049\ttotal: 3.5s\tremaining: 4.91s\n",
            "416:\tlearn: 0.1929605\ttotal: 3.5s\tremaining: 4.89s\n",
            "417:\tlearn: 0.1928179\ttotal: 3.5s\tremaining: 4.88s\n",
            "418:\tlearn: 0.1923704\ttotal: 3.51s\tremaining: 4.86s\n",
            "419:\tlearn: 0.1921813\ttotal: 3.51s\tremaining: 4.85s\n",
            "420:\tlearn: 0.1920182\ttotal: 3.53s\tremaining: 4.86s\n",
            "421:\tlearn: 0.1917274\ttotal: 3.54s\tremaining: 4.84s\n",
            "422:\tlearn: 0.1914375\ttotal: 3.54s\tremaining: 4.83s\n",
            "423:\tlearn: 0.1910913\ttotal: 3.55s\tremaining: 4.82s\n",
            "424:\tlearn: 0.1907809\ttotal: 3.55s\tremaining: 4.8s\n",
            "425:\tlearn: 0.1905765\ttotal: 3.55s\tremaining: 4.79s\n",
            "426:\tlearn: 0.1902293\ttotal: 3.56s\tremaining: 4.77s\n",
            "427:\tlearn: 0.1900339\ttotal: 3.56s\tremaining: 4.76s\n",
            "428:\tlearn: 0.1896609\ttotal: 3.56s\tremaining: 4.74s\n",
            "429:\tlearn: 0.1894037\ttotal: 3.57s\tremaining: 4.73s\n",
            "430:\tlearn: 0.1891997\ttotal: 3.57s\tremaining: 4.72s\n",
            "431:\tlearn: 0.1887578\ttotal: 3.58s\tremaining: 4.7s\n",
            "432:\tlearn: 0.1885086\ttotal: 3.58s\tremaining: 4.69s\n",
            "433:\tlearn: 0.1883550\ttotal: 3.58s\tremaining: 4.67s\n",
            "434:\tlearn: 0.1879662\ttotal: 3.59s\tremaining: 4.66s\n",
            "435:\tlearn: 0.1877670\ttotal: 3.59s\tremaining: 4.64s\n",
            "436:\tlearn: 0.1876301\ttotal: 3.59s\tremaining: 4.63s\n",
            "437:\tlearn: 0.1873853\ttotal: 3.6s\tremaining: 4.62s\n",
            "438:\tlearn: 0.1869971\ttotal: 3.61s\tremaining: 4.61s\n",
            "439:\tlearn: 0.1866196\ttotal: 3.61s\tremaining: 4.6s\n",
            "440:\tlearn: 0.1862442\ttotal: 3.62s\tremaining: 4.58s\n",
            "441:\tlearn: 0.1859576\ttotal: 3.62s\tremaining: 4.57s\n",
            "442:\tlearn: 0.1857568\ttotal: 3.62s\tremaining: 4.56s\n",
            "443:\tlearn: 0.1854212\ttotal: 3.63s\tremaining: 4.54s\n",
            "444:\tlearn: 0.1852940\ttotal: 3.63s\tremaining: 4.53s\n",
            "445:\tlearn: 0.1849094\ttotal: 3.63s\tremaining: 4.51s\n",
            "446:\tlearn: 0.1846469\ttotal: 3.64s\tremaining: 4.5s\n",
            "447:\tlearn: 0.1841947\ttotal: 3.64s\tremaining: 4.49s\n",
            "448:\tlearn: 0.1839006\ttotal: 3.65s\tremaining: 4.47s\n",
            "449:\tlearn: 0.1838079\ttotal: 3.65s\tremaining: 4.46s\n",
            "450:\tlearn: 0.1834590\ttotal: 3.65s\tremaining: 4.45s\n",
            "451:\tlearn: 0.1830864\ttotal: 3.66s\tremaining: 4.43s\n",
            "452:\tlearn: 0.1829020\ttotal: 3.66s\tremaining: 4.42s\n",
            "453:\tlearn: 0.1826084\ttotal: 3.66s\tremaining: 4.41s\n",
            "454:\tlearn: 0.1824736\ttotal: 3.67s\tremaining: 4.39s\n",
            "455:\tlearn: 0.1823532\ttotal: 3.67s\tremaining: 4.38s\n",
            "456:\tlearn: 0.1821791\ttotal: 3.68s\tremaining: 4.37s\n",
            "457:\tlearn: 0.1818743\ttotal: 3.68s\tremaining: 4.35s\n",
            "458:\tlearn: 0.1815949\ttotal: 3.68s\tremaining: 4.34s\n",
            "459:\tlearn: 0.1811765\ttotal: 3.69s\tremaining: 4.33s\n",
            "460:\tlearn: 0.1808085\ttotal: 3.7s\tremaining: 4.33s\n",
            "461:\tlearn: 0.1805673\ttotal: 3.71s\tremaining: 4.32s\n",
            "462:\tlearn: 0.1803292\ttotal: 3.72s\tremaining: 4.32s\n",
            "463:\tlearn: 0.1800261\ttotal: 3.73s\tremaining: 4.31s\n",
            "464:\tlearn: 0.1797297\ttotal: 3.74s\tremaining: 4.31s\n",
            "465:\tlearn: 0.1795934\ttotal: 3.75s\tremaining: 4.3s\n",
            "466:\tlearn: 0.1792865\ttotal: 3.75s\tremaining: 4.28s\n",
            "467:\tlearn: 0.1790568\ttotal: 3.76s\tremaining: 4.27s\n",
            "468:\tlearn: 0.1788789\ttotal: 3.76s\tremaining: 4.26s\n",
            "469:\tlearn: 0.1786951\ttotal: 3.76s\tremaining: 4.25s\n",
            "470:\tlearn: 0.1784899\ttotal: 3.77s\tremaining: 4.23s\n",
            "471:\tlearn: 0.1781108\ttotal: 3.78s\tremaining: 4.22s\n",
            "472:\tlearn: 0.1779861\ttotal: 3.78s\tremaining: 4.21s\n",
            "473:\tlearn: 0.1777551\ttotal: 3.79s\tremaining: 4.2s\n",
            "474:\tlearn: 0.1775996\ttotal: 3.79s\tremaining: 4.19s\n",
            "475:\tlearn: 0.1773620\ttotal: 3.79s\tremaining: 4.18s\n",
            "476:\tlearn: 0.1772204\ttotal: 3.8s\tremaining: 4.17s\n",
            "477:\tlearn: 0.1769383\ttotal: 3.8s\tremaining: 4.15s\n",
            "478:\tlearn: 0.1767494\ttotal: 3.81s\tremaining: 4.14s\n",
            "479:\tlearn: 0.1765920\ttotal: 3.81s\tremaining: 4.13s\n",
            "480:\tlearn: 0.1764834\ttotal: 3.81s\tremaining: 4.12s\n",
            "481:\tlearn: 0.1763437\ttotal: 3.82s\tremaining: 4.11s\n",
            "482:\tlearn: 0.1760466\ttotal: 3.83s\tremaining: 4.1s\n",
            "483:\tlearn: 0.1758348\ttotal: 3.84s\tremaining: 4.1s\n",
            "484:\tlearn: 0.1755667\ttotal: 3.85s\tremaining: 4.09s\n",
            "485:\tlearn: 0.1753180\ttotal: 3.87s\tremaining: 4.09s\n",
            "486:\tlearn: 0.1751254\ttotal: 3.88s\tremaining: 4.08s\n",
            "487:\tlearn: 0.1749369\ttotal: 3.88s\tremaining: 4.07s\n",
            "488:\tlearn: 0.1746925\ttotal: 3.9s\tremaining: 4.07s\n",
            "489:\tlearn: 0.1745072\ttotal: 3.9s\tremaining: 4.06s\n",
            "490:\tlearn: 0.1742841\ttotal: 3.92s\tremaining: 4.06s\n",
            "491:\tlearn: 0.1740379\ttotal: 3.92s\tremaining: 4.05s\n",
            "492:\tlearn: 0.1738408\ttotal: 3.94s\tremaining: 4.05s\n",
            "493:\tlearn: 0.1734593\ttotal: 3.95s\tremaining: 4.05s\n",
            "494:\tlearn: 0.1732860\ttotal: 3.96s\tremaining: 4.04s\n",
            "495:\tlearn: 0.1731525\ttotal: 3.97s\tremaining: 4.03s\n",
            "496:\tlearn: 0.1729432\ttotal: 3.98s\tremaining: 4.03s\n",
            "497:\tlearn: 0.1727470\ttotal: 3.98s\tremaining: 4.02s\n",
            "498:\tlearn: 0.1725079\ttotal: 3.99s\tremaining: 4s\n",
            "499:\tlearn: 0.1721026\ttotal: 3.99s\tremaining: 3.99s\n",
            "500:\tlearn: 0.1718984\ttotal: 4s\tremaining: 3.98s\n",
            "501:\tlearn: 0.1717496\ttotal: 4.01s\tremaining: 3.98s\n",
            "502:\tlearn: 0.1714444\ttotal: 4.02s\tremaining: 3.97s\n",
            "503:\tlearn: 0.1713644\ttotal: 4.03s\tremaining: 3.96s\n",
            "504:\tlearn: 0.1712334\ttotal: 4.03s\tremaining: 3.95s\n",
            "505:\tlearn: 0.1709064\ttotal: 4.04s\tremaining: 3.95s\n",
            "506:\tlearn: 0.1707777\ttotal: 4.05s\tremaining: 3.94s\n",
            "507:\tlearn: 0.1706242\ttotal: 4.06s\tremaining: 3.93s\n",
            "508:\tlearn: 0.1704470\ttotal: 4.06s\tremaining: 3.92s\n",
            "509:\tlearn: 0.1700194\ttotal: 4.07s\tremaining: 3.91s\n",
            "510:\tlearn: 0.1697601\ttotal: 4.07s\tremaining: 3.9s\n",
            "511:\tlearn: 0.1695558\ttotal: 4.08s\tremaining: 3.89s\n",
            "512:\tlearn: 0.1693678\ttotal: 4.08s\tremaining: 3.88s\n",
            "513:\tlearn: 0.1690457\ttotal: 4.09s\tremaining: 3.86s\n",
            "514:\tlearn: 0.1687161\ttotal: 4.09s\tremaining: 3.85s\n",
            "515:\tlearn: 0.1684179\ttotal: 4.09s\tremaining: 3.84s\n",
            "516:\tlearn: 0.1681825\ttotal: 4.1s\tremaining: 3.83s\n",
            "517:\tlearn: 0.1679558\ttotal: 4.1s\tremaining: 3.82s\n",
            "518:\tlearn: 0.1676529\ttotal: 4.11s\tremaining: 3.81s\n",
            "519:\tlearn: 0.1674273\ttotal: 4.11s\tremaining: 3.79s\n",
            "520:\tlearn: 0.1672455\ttotal: 4.12s\tremaining: 3.78s\n",
            "521:\tlearn: 0.1669341\ttotal: 4.13s\tremaining: 3.78s\n",
            "522:\tlearn: 0.1666557\ttotal: 4.13s\tremaining: 3.77s\n",
            "523:\tlearn: 0.1662624\ttotal: 4.14s\tremaining: 3.76s\n",
            "524:\tlearn: 0.1661386\ttotal: 4.15s\tremaining: 3.75s\n",
            "525:\tlearn: 0.1660427\ttotal: 4.16s\tremaining: 3.75s\n",
            "526:\tlearn: 0.1658179\ttotal: 4.17s\tremaining: 3.74s\n",
            "527:\tlearn: 0.1655846\ttotal: 4.18s\tremaining: 3.73s\n",
            "528:\tlearn: 0.1654624\ttotal: 4.19s\tremaining: 3.73s\n",
            "529:\tlearn: 0.1652127\ttotal: 4.2s\tremaining: 3.72s\n",
            "530:\tlearn: 0.1650668\ttotal: 4.21s\tremaining: 3.71s\n",
            "531:\tlearn: 0.1646698\ttotal: 4.21s\tremaining: 3.71s\n",
            "532:\tlearn: 0.1644451\ttotal: 4.22s\tremaining: 3.7s\n",
            "533:\tlearn: 0.1641994\ttotal: 4.24s\tremaining: 3.69s\n",
            "534:\tlearn: 0.1640517\ttotal: 4.24s\tremaining: 3.69s\n",
            "535:\tlearn: 0.1637774\ttotal: 4.25s\tremaining: 3.68s\n",
            "536:\tlearn: 0.1633997\ttotal: 4.26s\tremaining: 3.67s\n",
            "537:\tlearn: 0.1631345\ttotal: 4.27s\tremaining: 3.67s\n",
            "538:\tlearn: 0.1628586\ttotal: 4.28s\tremaining: 3.66s\n",
            "539:\tlearn: 0.1626205\ttotal: 4.29s\tremaining: 3.66s\n",
            "540:\tlearn: 0.1623370\ttotal: 4.31s\tremaining: 3.66s\n",
            "541:\tlearn: 0.1622221\ttotal: 4.33s\tremaining: 3.66s\n",
            "542:\tlearn: 0.1620409\ttotal: 4.33s\tremaining: 3.65s\n",
            "543:\tlearn: 0.1616861\ttotal: 4.34s\tremaining: 3.64s\n",
            "544:\tlearn: 0.1615615\ttotal: 4.36s\tremaining: 3.64s\n",
            "545:\tlearn: 0.1614577\ttotal: 4.36s\tremaining: 3.63s\n",
            "546:\tlearn: 0.1612610\ttotal: 4.36s\tremaining: 3.61s\n",
            "547:\tlearn: 0.1610467\ttotal: 4.37s\tremaining: 3.61s\n",
            "548:\tlearn: 0.1609805\ttotal: 4.38s\tremaining: 3.59s\n",
            "549:\tlearn: 0.1607281\ttotal: 4.38s\tremaining: 3.58s\n",
            "550:\tlearn: 0.1604925\ttotal: 4.38s\tremaining: 3.57s\n",
            "551:\tlearn: 0.1603276\ttotal: 4.39s\tremaining: 3.56s\n",
            "552:\tlearn: 0.1600163\ttotal: 4.39s\tremaining: 3.55s\n",
            "553:\tlearn: 0.1596949\ttotal: 4.39s\tremaining: 3.54s\n",
            "554:\tlearn: 0.1595629\ttotal: 4.4s\tremaining: 3.52s\n",
            "555:\tlearn: 0.1593609\ttotal: 4.41s\tremaining: 3.52s\n",
            "556:\tlearn: 0.1592879\ttotal: 4.41s\tremaining: 3.51s\n",
            "557:\tlearn: 0.1591568\ttotal: 4.42s\tremaining: 3.5s\n",
            "558:\tlearn: 0.1590028\ttotal: 4.42s\tremaining: 3.49s\n",
            "559:\tlearn: 0.1586835\ttotal: 4.42s\tremaining: 3.48s\n",
            "560:\tlearn: 0.1583384\ttotal: 4.43s\tremaining: 3.46s\n",
            "561:\tlearn: 0.1582090\ttotal: 4.43s\tremaining: 3.45s\n",
            "562:\tlearn: 0.1580095\ttotal: 4.44s\tremaining: 3.44s\n",
            "563:\tlearn: 0.1578425\ttotal: 4.44s\tremaining: 3.43s\n",
            "564:\tlearn: 0.1575685\ttotal: 4.45s\tremaining: 3.42s\n",
            "565:\tlearn: 0.1575292\ttotal: 4.45s\tremaining: 3.41s\n",
            "566:\tlearn: 0.1572119\ttotal: 4.45s\tremaining: 3.4s\n",
            "567:\tlearn: 0.1571293\ttotal: 4.46s\tremaining: 3.39s\n",
            "568:\tlearn: 0.1569061\ttotal: 4.46s\tremaining: 3.38s\n",
            "569:\tlearn: 0.1566725\ttotal: 4.46s\tremaining: 3.37s\n",
            "570:\tlearn: 0.1563118\ttotal: 4.47s\tremaining: 3.36s\n",
            "571:\tlearn: 0.1562402\ttotal: 4.48s\tremaining: 3.35s\n",
            "572:\tlearn: 0.1561683\ttotal: 4.48s\tremaining: 3.34s\n",
            "573:\tlearn: 0.1559860\ttotal: 4.49s\tremaining: 3.33s\n",
            "574:\tlearn: 0.1557228\ttotal: 4.5s\tremaining: 3.32s\n",
            "575:\tlearn: 0.1554417\ttotal: 4.51s\tremaining: 3.32s\n",
            "576:\tlearn: 0.1552645\ttotal: 4.52s\tremaining: 3.31s\n",
            "577:\tlearn: 0.1551267\ttotal: 4.53s\tremaining: 3.31s\n",
            "578:\tlearn: 0.1549794\ttotal: 4.54s\tremaining: 3.3s\n",
            "579:\tlearn: 0.1548571\ttotal: 4.54s\tremaining: 3.29s\n",
            "580:\tlearn: 0.1546726\ttotal: 4.55s\tremaining: 3.29s\n",
            "581:\tlearn: 0.1544473\ttotal: 4.57s\tremaining: 3.28s\n",
            "582:\tlearn: 0.1540804\ttotal: 4.57s\tremaining: 3.27s\n",
            "583:\tlearn: 0.1538912\ttotal: 4.58s\tremaining: 3.27s\n",
            "584:\tlearn: 0.1535925\ttotal: 4.59s\tremaining: 3.26s\n",
            "585:\tlearn: 0.1534041\ttotal: 4.6s\tremaining: 3.25s\n",
            "586:\tlearn: 0.1530427\ttotal: 4.6s\tremaining: 3.24s\n",
            "587:\tlearn: 0.1528604\ttotal: 4.61s\tremaining: 3.23s\n",
            "588:\tlearn: 0.1526671\ttotal: 4.61s\tremaining: 3.22s\n",
            "589:\tlearn: 0.1524114\ttotal: 4.62s\tremaining: 3.21s\n",
            "590:\tlearn: 0.1522973\ttotal: 4.62s\tremaining: 3.2s\n",
            "591:\tlearn: 0.1520597\ttotal: 4.64s\tremaining: 3.2s\n",
            "592:\tlearn: 0.1518618\ttotal: 4.65s\tremaining: 3.19s\n",
            "593:\tlearn: 0.1516534\ttotal: 4.66s\tremaining: 3.19s\n",
            "594:\tlearn: 0.1513935\ttotal: 4.67s\tremaining: 3.18s\n",
            "595:\tlearn: 0.1512367\ttotal: 4.68s\tremaining: 3.17s\n",
            "596:\tlearn: 0.1509851\ttotal: 4.69s\tremaining: 3.17s\n",
            "597:\tlearn: 0.1507443\ttotal: 4.71s\tremaining: 3.17s\n",
            "598:\tlearn: 0.1506941\ttotal: 4.71s\tremaining: 3.15s\n",
            "599:\tlearn: 0.1504272\ttotal: 4.72s\tremaining: 3.15s\n",
            "600:\tlearn: 0.1502900\ttotal: 4.73s\tremaining: 3.14s\n",
            "601:\tlearn: 0.1500507\ttotal: 4.74s\tremaining: 3.13s\n",
            "602:\tlearn: 0.1498447\ttotal: 4.75s\tremaining: 3.13s\n",
            "603:\tlearn: 0.1494512\ttotal: 4.76s\tremaining: 3.12s\n",
            "604:\tlearn: 0.1493205\ttotal: 4.78s\tremaining: 3.12s\n",
            "605:\tlearn: 0.1492066\ttotal: 4.79s\tremaining: 3.12s\n",
            "606:\tlearn: 0.1489513\ttotal: 4.8s\tremaining: 3.11s\n",
            "607:\tlearn: 0.1487222\ttotal: 4.81s\tremaining: 3.1s\n",
            "608:\tlearn: 0.1485567\ttotal: 4.82s\tremaining: 3.09s\n",
            "609:\tlearn: 0.1483745\ttotal: 4.82s\tremaining: 3.08s\n",
            "610:\tlearn: 0.1482162\ttotal: 4.82s\tremaining: 3.07s\n",
            "611:\tlearn: 0.1479802\ttotal: 4.83s\tremaining: 3.06s\n",
            "612:\tlearn: 0.1478417\ttotal: 4.84s\tremaining: 3.05s\n",
            "613:\tlearn: 0.1477662\ttotal: 4.84s\tremaining: 3.04s\n",
            "614:\tlearn: 0.1474697\ttotal: 4.85s\tremaining: 3.03s\n",
            "615:\tlearn: 0.1472801\ttotal: 4.85s\tremaining: 3.02s\n",
            "616:\tlearn: 0.1470630\ttotal: 4.85s\tremaining: 3.01s\n",
            "617:\tlearn: 0.1470034\ttotal: 4.86s\tremaining: 3s\n",
            "618:\tlearn: 0.1469126\ttotal: 4.86s\tremaining: 2.99s\n",
            "619:\tlearn: 0.1466162\ttotal: 4.86s\tremaining: 2.98s\n",
            "620:\tlearn: 0.1464994\ttotal: 4.87s\tremaining: 2.97s\n",
            "621:\tlearn: 0.1463160\ttotal: 4.87s\tremaining: 2.96s\n",
            "622:\tlearn: 0.1460573\ttotal: 4.88s\tremaining: 2.95s\n",
            "623:\tlearn: 0.1457300\ttotal: 4.88s\tremaining: 2.94s\n",
            "624:\tlearn: 0.1455476\ttotal: 4.88s\tremaining: 2.93s\n",
            "625:\tlearn: 0.1453815\ttotal: 4.9s\tremaining: 2.92s\n",
            "626:\tlearn: 0.1452235\ttotal: 4.91s\tremaining: 2.92s\n",
            "627:\tlearn: 0.1450408\ttotal: 4.92s\tremaining: 2.91s\n",
            "628:\tlearn: 0.1449512\ttotal: 4.92s\tremaining: 2.9s\n",
            "629:\tlearn: 0.1447712\ttotal: 4.94s\tremaining: 2.9s\n",
            "630:\tlearn: 0.1446156\ttotal: 4.95s\tremaining: 2.9s\n",
            "631:\tlearn: 0.1444452\ttotal: 4.96s\tremaining: 2.89s\n",
            "632:\tlearn: 0.1443597\ttotal: 4.97s\tremaining: 2.88s\n",
            "633:\tlearn: 0.1441142\ttotal: 4.97s\tremaining: 2.87s\n",
            "634:\tlearn: 0.1438540\ttotal: 4.98s\tremaining: 2.86s\n",
            "635:\tlearn: 0.1437442\ttotal: 4.98s\tremaining: 2.85s\n",
            "636:\tlearn: 0.1436119\ttotal: 4.98s\tremaining: 2.84s\n",
            "637:\tlearn: 0.1435195\ttotal: 4.99s\tremaining: 2.83s\n",
            "638:\tlearn: 0.1432508\ttotal: 4.99s\tremaining: 2.82s\n",
            "639:\tlearn: 0.1431592\ttotal: 5s\tremaining: 2.81s\n",
            "640:\tlearn: 0.1428934\ttotal: 5.01s\tremaining: 2.81s\n",
            "641:\tlearn: 0.1427231\ttotal: 5.02s\tremaining: 2.8s\n",
            "642:\tlearn: 0.1425930\ttotal: 5.02s\tremaining: 2.79s\n",
            "643:\tlearn: 0.1423454\ttotal: 5.02s\tremaining: 2.78s\n",
            "644:\tlearn: 0.1421673\ttotal: 5.03s\tremaining: 2.77s\n",
            "645:\tlearn: 0.1419694\ttotal: 5.03s\tremaining: 2.75s\n",
            "646:\tlearn: 0.1418172\ttotal: 5.03s\tremaining: 2.75s\n",
            "647:\tlearn: 0.1415905\ttotal: 5.04s\tremaining: 2.73s\n",
            "648:\tlearn: 0.1414079\ttotal: 5.04s\tremaining: 2.72s\n",
            "649:\tlearn: 0.1412969\ttotal: 5.04s\tremaining: 2.71s\n",
            "650:\tlearn: 0.1411037\ttotal: 5.04s\tremaining: 2.7s\n",
            "651:\tlearn: 0.1408065\ttotal: 5.05s\tremaining: 2.69s\n",
            "652:\tlearn: 0.1407266\ttotal: 5.05s\tremaining: 2.68s\n",
            "653:\tlearn: 0.1406306\ttotal: 5.05s\tremaining: 2.67s\n",
            "654:\tlearn: 0.1405208\ttotal: 5.06s\tremaining: 2.66s\n",
            "655:\tlearn: 0.1403884\ttotal: 5.06s\tremaining: 2.65s\n",
            "656:\tlearn: 0.1402303\ttotal: 5.06s\tremaining: 2.64s\n",
            "657:\tlearn: 0.1401545\ttotal: 5.07s\tremaining: 2.63s\n",
            "658:\tlearn: 0.1399657\ttotal: 5.07s\tremaining: 2.62s\n",
            "659:\tlearn: 0.1398701\ttotal: 5.07s\tremaining: 2.61s\n",
            "660:\tlearn: 0.1397547\ttotal: 5.08s\tremaining: 2.6s\n",
            "661:\tlearn: 0.1395849\ttotal: 5.08s\tremaining: 2.59s\n",
            "662:\tlearn: 0.1395268\ttotal: 5.08s\tremaining: 2.58s\n",
            "663:\tlearn: 0.1393441\ttotal: 5.09s\tremaining: 2.57s\n",
            "664:\tlearn: 0.1390917\ttotal: 5.09s\tremaining: 2.56s\n",
            "665:\tlearn: 0.1388013\ttotal: 5.09s\tremaining: 2.55s\n",
            "666:\tlearn: 0.1385873\ttotal: 5.1s\tremaining: 2.54s\n",
            "667:\tlearn: 0.1384063\ttotal: 5.1s\tremaining: 2.53s\n",
            "668:\tlearn: 0.1383291\ttotal: 5.1s\tremaining: 2.52s\n",
            "669:\tlearn: 0.1381921\ttotal: 5.11s\tremaining: 2.51s\n",
            "670:\tlearn: 0.1380951\ttotal: 5.11s\tremaining: 2.5s\n",
            "671:\tlearn: 0.1379255\ttotal: 5.11s\tremaining: 2.5s\n",
            "672:\tlearn: 0.1375915\ttotal: 5.12s\tremaining: 2.48s\n",
            "673:\tlearn: 0.1375205\ttotal: 5.12s\tremaining: 2.48s\n",
            "674:\tlearn: 0.1373508\ttotal: 5.12s\tremaining: 2.47s\n",
            "675:\tlearn: 0.1371102\ttotal: 5.13s\tremaining: 2.46s\n",
            "676:\tlearn: 0.1369043\ttotal: 5.13s\tremaining: 2.45s\n",
            "677:\tlearn: 0.1368243\ttotal: 5.13s\tremaining: 2.44s\n",
            "678:\tlearn: 0.1367539\ttotal: 5.13s\tremaining: 2.43s\n",
            "679:\tlearn: 0.1365854\ttotal: 5.14s\tremaining: 2.42s\n",
            "680:\tlearn: 0.1364205\ttotal: 5.14s\tremaining: 2.41s\n",
            "681:\tlearn: 0.1362785\ttotal: 5.14s\tremaining: 2.4s\n",
            "682:\tlearn: 0.1361062\ttotal: 5.15s\tremaining: 2.39s\n",
            "683:\tlearn: 0.1359413\ttotal: 5.15s\tremaining: 2.38s\n",
            "684:\tlearn: 0.1356872\ttotal: 5.15s\tremaining: 2.37s\n",
            "685:\tlearn: 0.1354587\ttotal: 5.16s\tremaining: 2.36s\n",
            "686:\tlearn: 0.1351363\ttotal: 5.16s\tremaining: 2.35s\n",
            "687:\tlearn: 0.1349718\ttotal: 5.17s\tremaining: 2.34s\n",
            "688:\tlearn: 0.1347212\ttotal: 5.18s\tremaining: 2.34s\n",
            "689:\tlearn: 0.1346302\ttotal: 5.18s\tremaining: 2.33s\n",
            "690:\tlearn: 0.1344480\ttotal: 5.19s\tremaining: 2.32s\n",
            "691:\tlearn: 0.1341707\ttotal: 5.19s\tremaining: 2.31s\n",
            "692:\tlearn: 0.1340532\ttotal: 5.2s\tremaining: 2.3s\n",
            "693:\tlearn: 0.1338269\ttotal: 5.2s\tremaining: 2.29s\n",
            "694:\tlearn: 0.1336981\ttotal: 5.2s\tremaining: 2.28s\n",
            "695:\tlearn: 0.1335610\ttotal: 5.21s\tremaining: 2.27s\n",
            "696:\tlearn: 0.1332634\ttotal: 5.21s\tremaining: 2.26s\n",
            "697:\tlearn: 0.1331350\ttotal: 5.21s\tremaining: 2.25s\n",
            "698:\tlearn: 0.1330000\ttotal: 5.21s\tremaining: 2.25s\n",
            "699:\tlearn: 0.1328749\ttotal: 5.22s\tremaining: 2.24s\n",
            "700:\tlearn: 0.1327141\ttotal: 5.22s\tremaining: 2.23s\n",
            "701:\tlearn: 0.1324652\ttotal: 5.22s\tremaining: 2.22s\n",
            "702:\tlearn: 0.1323332\ttotal: 5.23s\tremaining: 2.21s\n",
            "703:\tlearn: 0.1322766\ttotal: 5.23s\tremaining: 2.2s\n",
            "704:\tlearn: 0.1321668\ttotal: 5.23s\tremaining: 2.19s\n",
            "705:\tlearn: 0.1320979\ttotal: 5.24s\tremaining: 2.18s\n",
            "706:\tlearn: 0.1319199\ttotal: 5.24s\tremaining: 2.17s\n",
            "707:\tlearn: 0.1318401\ttotal: 5.24s\tremaining: 2.16s\n",
            "708:\tlearn: 0.1315705\ttotal: 5.25s\tremaining: 2.15s\n",
            "709:\tlearn: 0.1312599\ttotal: 5.25s\tremaining: 2.14s\n",
            "710:\tlearn: 0.1311437\ttotal: 5.25s\tremaining: 2.13s\n",
            "711:\tlearn: 0.1309791\ttotal: 5.26s\tremaining: 2.13s\n",
            "712:\tlearn: 0.1307598\ttotal: 5.26s\tremaining: 2.12s\n",
            "713:\tlearn: 0.1306002\ttotal: 5.26s\tremaining: 2.11s\n",
            "714:\tlearn: 0.1304004\ttotal: 5.27s\tremaining: 2.1s\n",
            "715:\tlearn: 0.1302463\ttotal: 5.27s\tremaining: 2.09s\n",
            "716:\tlearn: 0.1300749\ttotal: 5.27s\tremaining: 2.08s\n",
            "717:\tlearn: 0.1300234\ttotal: 5.28s\tremaining: 2.07s\n",
            "718:\tlearn: 0.1297058\ttotal: 5.28s\tremaining: 2.06s\n",
            "719:\tlearn: 0.1295795\ttotal: 5.28s\tremaining: 2.05s\n",
            "720:\tlearn: 0.1293986\ttotal: 5.29s\tremaining: 2.04s\n",
            "721:\tlearn: 0.1291857\ttotal: 5.29s\tremaining: 2.04s\n",
            "722:\tlearn: 0.1289984\ttotal: 5.29s\tremaining: 2.03s\n",
            "723:\tlearn: 0.1289505\ttotal: 5.29s\tremaining: 2.02s\n",
            "724:\tlearn: 0.1289078\ttotal: 5.3s\tremaining: 2.01s\n",
            "725:\tlearn: 0.1287526\ttotal: 5.3s\tremaining: 2s\n",
            "726:\tlearn: 0.1285611\ttotal: 5.31s\tremaining: 1.99s\n",
            "727:\tlearn: 0.1284039\ttotal: 5.31s\tremaining: 1.98s\n",
            "728:\tlearn: 0.1282041\ttotal: 5.31s\tremaining: 1.97s\n",
            "729:\tlearn: 0.1279324\ttotal: 5.32s\tremaining: 1.97s\n",
            "730:\tlearn: 0.1277099\ttotal: 5.32s\tremaining: 1.96s\n",
            "731:\tlearn: 0.1274285\ttotal: 5.32s\tremaining: 1.95s\n",
            "732:\tlearn: 0.1273886\ttotal: 5.33s\tremaining: 1.94s\n",
            "733:\tlearn: 0.1272817\ttotal: 5.33s\tremaining: 1.93s\n",
            "734:\tlearn: 0.1271655\ttotal: 5.33s\tremaining: 1.92s\n",
            "735:\tlearn: 0.1269900\ttotal: 5.34s\tremaining: 1.92s\n",
            "736:\tlearn: 0.1267943\ttotal: 5.34s\tremaining: 1.91s\n",
            "737:\tlearn: 0.1265751\ttotal: 5.34s\tremaining: 1.9s\n",
            "738:\tlearn: 0.1263932\ttotal: 5.35s\tremaining: 1.89s\n",
            "739:\tlearn: 0.1262213\ttotal: 5.35s\tremaining: 1.88s\n",
            "740:\tlearn: 0.1260940\ttotal: 5.36s\tremaining: 1.87s\n",
            "741:\tlearn: 0.1258313\ttotal: 5.36s\tremaining: 1.86s\n",
            "742:\tlearn: 0.1256630\ttotal: 5.36s\tremaining: 1.85s\n",
            "743:\tlearn: 0.1255120\ttotal: 5.36s\tremaining: 1.85s\n",
            "744:\tlearn: 0.1254730\ttotal: 5.37s\tremaining: 1.84s\n",
            "745:\tlearn: 0.1253573\ttotal: 5.37s\tremaining: 1.83s\n",
            "746:\tlearn: 0.1251749\ttotal: 5.37s\tremaining: 1.82s\n",
            "747:\tlearn: 0.1249851\ttotal: 5.38s\tremaining: 1.81s\n",
            "748:\tlearn: 0.1247696\ttotal: 5.38s\tremaining: 1.8s\n",
            "749:\tlearn: 0.1245561\ttotal: 5.38s\tremaining: 1.79s\n",
            "750:\tlearn: 0.1244044\ttotal: 5.39s\tremaining: 1.79s\n",
            "751:\tlearn: 0.1241624\ttotal: 5.39s\tremaining: 1.78s\n",
            "752:\tlearn: 0.1239903\ttotal: 5.39s\tremaining: 1.77s\n",
            "753:\tlearn: 0.1238254\ttotal: 5.4s\tremaining: 1.76s\n",
            "754:\tlearn: 0.1236842\ttotal: 5.4s\tremaining: 1.75s\n",
            "755:\tlearn: 0.1235931\ttotal: 5.4s\tremaining: 1.74s\n",
            "756:\tlearn: 0.1235632\ttotal: 5.41s\tremaining: 1.74s\n",
            "757:\tlearn: 0.1233764\ttotal: 5.41s\tremaining: 1.73s\n",
            "758:\tlearn: 0.1232604\ttotal: 5.41s\tremaining: 1.72s\n",
            "759:\tlearn: 0.1230521\ttotal: 5.42s\tremaining: 1.71s\n",
            "760:\tlearn: 0.1227949\ttotal: 5.42s\tremaining: 1.7s\n",
            "761:\tlearn: 0.1227172\ttotal: 5.42s\tremaining: 1.69s\n",
            "762:\tlearn: 0.1226099\ttotal: 5.43s\tremaining: 1.69s\n",
            "763:\tlearn: 0.1225388\ttotal: 5.43s\tremaining: 1.68s\n",
            "764:\tlearn: 0.1223260\ttotal: 5.43s\tremaining: 1.67s\n",
            "765:\tlearn: 0.1221608\ttotal: 5.43s\tremaining: 1.66s\n",
            "766:\tlearn: 0.1219836\ttotal: 5.44s\tremaining: 1.65s\n",
            "767:\tlearn: 0.1218390\ttotal: 5.44s\tremaining: 1.64s\n",
            "768:\tlearn: 0.1217844\ttotal: 5.45s\tremaining: 1.64s\n",
            "769:\tlearn: 0.1217686\ttotal: 5.45s\tremaining: 1.63s\n",
            "770:\tlearn: 0.1214992\ttotal: 5.45s\tremaining: 1.62s\n",
            "771:\tlearn: 0.1212397\ttotal: 5.46s\tremaining: 1.61s\n",
            "772:\tlearn: 0.1210806\ttotal: 5.46s\tremaining: 1.6s\n",
            "773:\tlearn: 0.1209606\ttotal: 5.46s\tremaining: 1.59s\n",
            "774:\tlearn: 0.1208555\ttotal: 5.47s\tremaining: 1.59s\n",
            "775:\tlearn: 0.1207920\ttotal: 5.47s\tremaining: 1.58s\n",
            "776:\tlearn: 0.1207125\ttotal: 5.47s\tremaining: 1.57s\n",
            "777:\tlearn: 0.1205455\ttotal: 5.48s\tremaining: 1.56s\n",
            "778:\tlearn: 0.1203681\ttotal: 5.48s\tremaining: 1.55s\n",
            "779:\tlearn: 0.1201835\ttotal: 5.48s\tremaining: 1.55s\n",
            "780:\tlearn: 0.1200330\ttotal: 5.49s\tremaining: 1.54s\n",
            "781:\tlearn: 0.1199365\ttotal: 5.49s\tremaining: 1.53s\n",
            "782:\tlearn: 0.1197279\ttotal: 5.49s\tremaining: 1.52s\n",
            "783:\tlearn: 0.1195358\ttotal: 5.5s\tremaining: 1.51s\n",
            "784:\tlearn: 0.1194586\ttotal: 5.5s\tremaining: 1.51s\n",
            "785:\tlearn: 0.1192832\ttotal: 5.5s\tremaining: 1.5s\n",
            "786:\tlearn: 0.1191025\ttotal: 5.51s\tremaining: 1.49s\n",
            "787:\tlearn: 0.1190787\ttotal: 5.51s\tremaining: 1.48s\n",
            "788:\tlearn: 0.1189310\ttotal: 5.51s\tremaining: 1.47s\n",
            "789:\tlearn: 0.1186368\ttotal: 5.51s\tremaining: 1.47s\n",
            "790:\tlearn: 0.1186037\ttotal: 5.52s\tremaining: 1.46s\n",
            "791:\tlearn: 0.1183879\ttotal: 5.52s\tremaining: 1.45s\n",
            "792:\tlearn: 0.1182654\ttotal: 5.53s\tremaining: 1.44s\n",
            "793:\tlearn: 0.1181526\ttotal: 5.53s\tremaining: 1.43s\n",
            "794:\tlearn: 0.1180738\ttotal: 5.53s\tremaining: 1.43s\n",
            "795:\tlearn: 0.1179263\ttotal: 5.53s\tremaining: 1.42s\n",
            "796:\tlearn: 0.1176801\ttotal: 5.54s\tremaining: 1.41s\n",
            "797:\tlearn: 0.1175203\ttotal: 5.54s\tremaining: 1.4s\n",
            "798:\tlearn: 0.1173667\ttotal: 5.54s\tremaining: 1.39s\n",
            "799:\tlearn: 0.1171694\ttotal: 5.55s\tremaining: 1.39s\n",
            "800:\tlearn: 0.1170001\ttotal: 5.55s\tremaining: 1.38s\n",
            "801:\tlearn: 0.1168822\ttotal: 5.55s\tremaining: 1.37s\n",
            "802:\tlearn: 0.1167586\ttotal: 5.56s\tremaining: 1.36s\n",
            "803:\tlearn: 0.1165957\ttotal: 5.56s\tremaining: 1.35s\n",
            "804:\tlearn: 0.1165392\ttotal: 5.56s\tremaining: 1.35s\n",
            "805:\tlearn: 0.1165147\ttotal: 5.57s\tremaining: 1.34s\n",
            "806:\tlearn: 0.1164521\ttotal: 5.57s\tremaining: 1.33s\n",
            "807:\tlearn: 0.1163021\ttotal: 5.57s\tremaining: 1.32s\n",
            "808:\tlearn: 0.1161522\ttotal: 5.58s\tremaining: 1.32s\n",
            "809:\tlearn: 0.1160754\ttotal: 5.58s\tremaining: 1.31s\n",
            "810:\tlearn: 0.1158345\ttotal: 5.58s\tremaining: 1.3s\n",
            "811:\tlearn: 0.1155782\ttotal: 5.58s\tremaining: 1.29s\n",
            "812:\tlearn: 0.1154534\ttotal: 5.59s\tremaining: 1.28s\n",
            "813:\tlearn: 0.1152375\ttotal: 5.59s\tremaining: 1.28s\n",
            "814:\tlearn: 0.1150978\ttotal: 5.59s\tremaining: 1.27s\n",
            "815:\tlearn: 0.1148091\ttotal: 5.6s\tremaining: 1.26s\n",
            "816:\tlearn: 0.1146695\ttotal: 5.6s\tremaining: 1.25s\n",
            "817:\tlearn: 0.1145914\ttotal: 5.61s\tremaining: 1.25s\n",
            "818:\tlearn: 0.1145177\ttotal: 5.61s\tremaining: 1.24s\n",
            "819:\tlearn: 0.1143582\ttotal: 5.61s\tremaining: 1.23s\n",
            "820:\tlearn: 0.1141644\ttotal: 5.62s\tremaining: 1.22s\n",
            "821:\tlearn: 0.1140673\ttotal: 5.62s\tremaining: 1.22s\n",
            "822:\tlearn: 0.1139604\ttotal: 5.62s\tremaining: 1.21s\n",
            "823:\tlearn: 0.1139320\ttotal: 5.63s\tremaining: 1.2s\n",
            "824:\tlearn: 0.1137965\ttotal: 5.63s\tremaining: 1.19s\n",
            "825:\tlearn: 0.1137224\ttotal: 5.63s\tremaining: 1.19s\n",
            "826:\tlearn: 0.1136487\ttotal: 5.63s\tremaining: 1.18s\n",
            "827:\tlearn: 0.1134818\ttotal: 5.64s\tremaining: 1.17s\n",
            "828:\tlearn: 0.1133760\ttotal: 5.64s\tremaining: 1.16s\n",
            "829:\tlearn: 0.1132491\ttotal: 5.65s\tremaining: 1.16s\n",
            "830:\tlearn: 0.1130835\ttotal: 5.65s\tremaining: 1.15s\n",
            "831:\tlearn: 0.1129483\ttotal: 5.65s\tremaining: 1.14s\n",
            "832:\tlearn: 0.1127641\ttotal: 5.66s\tremaining: 1.13s\n",
            "833:\tlearn: 0.1126019\ttotal: 5.66s\tremaining: 1.13s\n",
            "834:\tlearn: 0.1123961\ttotal: 5.66s\tremaining: 1.12s\n",
            "835:\tlearn: 0.1123639\ttotal: 5.67s\tremaining: 1.11s\n",
            "836:\tlearn: 0.1122003\ttotal: 5.67s\tremaining: 1.1s\n",
            "837:\tlearn: 0.1120733\ttotal: 5.68s\tremaining: 1.1s\n",
            "838:\tlearn: 0.1119223\ttotal: 5.68s\tremaining: 1.09s\n",
            "839:\tlearn: 0.1117453\ttotal: 5.68s\tremaining: 1.08s\n",
            "840:\tlearn: 0.1115633\ttotal: 5.69s\tremaining: 1.07s\n",
            "841:\tlearn: 0.1114724\ttotal: 5.69s\tremaining: 1.07s\n",
            "842:\tlearn: 0.1113004\ttotal: 5.69s\tremaining: 1.06s\n",
            "843:\tlearn: 0.1111327\ttotal: 5.7s\tremaining: 1.05s\n",
            "844:\tlearn: 0.1109727\ttotal: 5.7s\tremaining: 1.04s\n",
            "845:\tlearn: 0.1108622\ttotal: 5.7s\tremaining: 1.04s\n",
            "846:\tlearn: 0.1107755\ttotal: 5.71s\tremaining: 1.03s\n",
            "847:\tlearn: 0.1105818\ttotal: 5.71s\tremaining: 1.02s\n",
            "848:\tlearn: 0.1105653\ttotal: 5.71s\tremaining: 1.02s\n",
            "849:\tlearn: 0.1104408\ttotal: 5.72s\tremaining: 1.01s\n",
            "850:\tlearn: 0.1104163\ttotal: 5.72s\tremaining: 1s\n",
            "851:\tlearn: 0.1103972\ttotal: 5.72s\tremaining: 994ms\n",
            "852:\tlearn: 0.1103363\ttotal: 5.73s\tremaining: 987ms\n",
            "853:\tlearn: 0.1103138\ttotal: 5.73s\tremaining: 980ms\n",
            "854:\tlearn: 0.1102259\ttotal: 5.73s\tremaining: 972ms\n",
            "855:\tlearn: 0.1102059\ttotal: 5.74s\tremaining: 965ms\n",
            "856:\tlearn: 0.1099783\ttotal: 5.74s\tremaining: 958ms\n",
            "857:\tlearn: 0.1097901\ttotal: 5.74s\tremaining: 950ms\n",
            "858:\tlearn: 0.1095794\ttotal: 5.75s\tremaining: 943ms\n",
            "859:\tlearn: 0.1095106\ttotal: 5.75s\tremaining: 936ms\n",
            "860:\tlearn: 0.1093692\ttotal: 5.75s\tremaining: 929ms\n",
            "861:\tlearn: 0.1092196\ttotal: 5.75s\tremaining: 921ms\n",
            "862:\tlearn: 0.1090480\ttotal: 5.76s\tremaining: 914ms\n",
            "863:\tlearn: 0.1089378\ttotal: 5.76s\tremaining: 907ms\n",
            "864:\tlearn: 0.1087743\ttotal: 5.77s\tremaining: 900ms\n",
            "865:\tlearn: 0.1086094\ttotal: 5.77s\tremaining: 893ms\n",
            "866:\tlearn: 0.1085333\ttotal: 5.78s\tremaining: 887ms\n",
            "867:\tlearn: 0.1084480\ttotal: 5.79s\tremaining: 880ms\n",
            "868:\tlearn: 0.1084192\ttotal: 5.79s\tremaining: 873ms\n",
            "869:\tlearn: 0.1082900\ttotal: 5.79s\tremaining: 866ms\n",
            "870:\tlearn: 0.1081293\ttotal: 5.8s\tremaining: 858ms\n",
            "871:\tlearn: 0.1079271\ttotal: 5.8s\tremaining: 851ms\n",
            "872:\tlearn: 0.1078380\ttotal: 5.8s\tremaining: 844ms\n",
            "873:\tlearn: 0.1077649\ttotal: 5.81s\tremaining: 837ms\n",
            "874:\tlearn: 0.1077127\ttotal: 5.81s\tremaining: 830ms\n",
            "875:\tlearn: 0.1074672\ttotal: 5.82s\tremaining: 823ms\n",
            "876:\tlearn: 0.1072693\ttotal: 5.82s\tremaining: 816ms\n",
            "877:\tlearn: 0.1072137\ttotal: 5.82s\tremaining: 809ms\n",
            "878:\tlearn: 0.1071256\ttotal: 5.83s\tremaining: 802ms\n",
            "879:\tlearn: 0.1071089\ttotal: 5.83s\tremaining: 795ms\n",
            "880:\tlearn: 0.1068457\ttotal: 5.83s\tremaining: 788ms\n",
            "881:\tlearn: 0.1066645\ttotal: 5.83s\tremaining: 781ms\n",
            "882:\tlearn: 0.1066159\ttotal: 5.84s\tremaining: 774ms\n",
            "883:\tlearn: 0.1063521\ttotal: 5.84s\tremaining: 767ms\n",
            "884:\tlearn: 0.1062170\ttotal: 5.84s\tremaining: 759ms\n",
            "885:\tlearn: 0.1060782\ttotal: 5.85s\tremaining: 752ms\n",
            "886:\tlearn: 0.1058582\ttotal: 5.85s\tremaining: 745ms\n",
            "887:\tlearn: 0.1057984\ttotal: 5.85s\tremaining: 738ms\n",
            "888:\tlearn: 0.1056389\ttotal: 5.86s\tremaining: 731ms\n",
            "889:\tlearn: 0.1055643\ttotal: 5.86s\tremaining: 724ms\n",
            "890:\tlearn: 0.1054080\ttotal: 5.86s\tremaining: 717ms\n",
            "891:\tlearn: 0.1052365\ttotal: 5.87s\tremaining: 710ms\n",
            "892:\tlearn: 0.1051818\ttotal: 5.87s\tremaining: 703ms\n",
            "893:\tlearn: 0.1050474\ttotal: 5.87s\tremaining: 696ms\n",
            "894:\tlearn: 0.1048323\ttotal: 5.88s\tremaining: 689ms\n",
            "895:\tlearn: 0.1047839\ttotal: 5.88s\tremaining: 682ms\n",
            "896:\tlearn: 0.1045941\ttotal: 5.88s\tremaining: 675ms\n",
            "897:\tlearn: 0.1044783\ttotal: 5.89s\tremaining: 669ms\n",
            "898:\tlearn: 0.1043706\ttotal: 5.89s\tremaining: 662ms\n",
            "899:\tlearn: 0.1042440\ttotal: 5.89s\tremaining: 655ms\n",
            "900:\tlearn: 0.1041237\ttotal: 5.89s\tremaining: 648ms\n",
            "901:\tlearn: 0.1039361\ttotal: 5.9s\tremaining: 641ms\n",
            "902:\tlearn: 0.1038144\ttotal: 5.9s\tremaining: 634ms\n",
            "903:\tlearn: 0.1036565\ttotal: 5.9s\tremaining: 627ms\n",
            "904:\tlearn: 0.1036366\ttotal: 5.91s\tremaining: 620ms\n",
            "905:\tlearn: 0.1035407\ttotal: 5.91s\tremaining: 613ms\n",
            "906:\tlearn: 0.1033813\ttotal: 5.91s\tremaining: 606ms\n",
            "907:\tlearn: 0.1033117\ttotal: 5.92s\tremaining: 600ms\n",
            "908:\tlearn: 0.1032266\ttotal: 5.92s\tremaining: 593ms\n",
            "909:\tlearn: 0.1030699\ttotal: 5.93s\tremaining: 586ms\n",
            "910:\tlearn: 0.1029001\ttotal: 5.93s\tremaining: 579ms\n",
            "911:\tlearn: 0.1027425\ttotal: 5.93s\tremaining: 573ms\n",
            "912:\tlearn: 0.1025881\ttotal: 5.94s\tremaining: 566ms\n",
            "913:\tlearn: 0.1024087\ttotal: 5.94s\tremaining: 559ms\n",
            "914:\tlearn: 0.1022903\ttotal: 5.94s\tremaining: 552ms\n",
            "915:\tlearn: 0.1021873\ttotal: 5.95s\tremaining: 545ms\n",
            "916:\tlearn: 0.1020688\ttotal: 5.95s\tremaining: 539ms\n",
            "917:\tlearn: 0.1019036\ttotal: 5.95s\tremaining: 532ms\n",
            "918:\tlearn: 0.1017975\ttotal: 5.96s\tremaining: 525ms\n",
            "919:\tlearn: 0.1017558\ttotal: 5.96s\tremaining: 518ms\n",
            "920:\tlearn: 0.1015899\ttotal: 5.97s\tremaining: 512ms\n",
            "921:\tlearn: 0.1015057\ttotal: 5.97s\tremaining: 505ms\n",
            "922:\tlearn: 0.1013358\ttotal: 5.97s\tremaining: 498ms\n",
            "923:\tlearn: 0.1011951\ttotal: 5.98s\tremaining: 492ms\n",
            "924:\tlearn: 0.1010734\ttotal: 5.98s\tremaining: 485ms\n",
            "925:\tlearn: 0.1009378\ttotal: 5.98s\tremaining: 478ms\n",
            "926:\tlearn: 0.1006945\ttotal: 5.99s\tremaining: 471ms\n",
            "927:\tlearn: 0.1006464\ttotal: 5.99s\tremaining: 465ms\n",
            "928:\tlearn: 0.1006307\ttotal: 5.99s\tremaining: 458ms\n",
            "929:\tlearn: 0.1004837\ttotal: 6s\tremaining: 451ms\n",
            "930:\tlearn: 0.1002473\ttotal: 6s\tremaining: 445ms\n",
            "931:\tlearn: 0.1000973\ttotal: 6s\tremaining: 438ms\n",
            "932:\tlearn: 0.0998716\ttotal: 6s\tremaining: 431ms\n",
            "933:\tlearn: 0.0996862\ttotal: 6.01s\tremaining: 425ms\n",
            "934:\tlearn: 0.0995115\ttotal: 6.01s\tremaining: 418ms\n",
            "935:\tlearn: 0.0993189\ttotal: 6.01s\tremaining: 411ms\n",
            "936:\tlearn: 0.0992920\ttotal: 6.02s\tremaining: 405ms\n",
            "937:\tlearn: 0.0992769\ttotal: 6.02s\tremaining: 398ms\n",
            "938:\tlearn: 0.0991367\ttotal: 6.02s\tremaining: 391ms\n",
            "939:\tlearn: 0.0990141\ttotal: 6.03s\tremaining: 385ms\n",
            "940:\tlearn: 0.0989494\ttotal: 6.03s\tremaining: 378ms\n",
            "941:\tlearn: 0.0988451\ttotal: 6.03s\tremaining: 371ms\n",
            "942:\tlearn: 0.0987270\ttotal: 6.04s\tremaining: 365ms\n",
            "943:\tlearn: 0.0985692\ttotal: 6.04s\tremaining: 358ms\n",
            "944:\tlearn: 0.0983879\ttotal: 6.04s\tremaining: 352ms\n",
            "945:\tlearn: 0.0981765\ttotal: 6.04s\tremaining: 345ms\n",
            "946:\tlearn: 0.0980976\ttotal: 6.05s\tremaining: 339ms\n",
            "947:\tlearn: 0.0979567\ttotal: 6.05s\tremaining: 332ms\n",
            "948:\tlearn: 0.0978423\ttotal: 6.05s\tremaining: 325ms\n",
            "949:\tlearn: 0.0975665\ttotal: 6.06s\tremaining: 319ms\n",
            "950:\tlearn: 0.0974974\ttotal: 6.06s\tremaining: 312ms\n",
            "951:\tlearn: 0.0973117\ttotal: 6.07s\tremaining: 306ms\n",
            "952:\tlearn: 0.0971092\ttotal: 6.07s\tremaining: 299ms\n",
            "953:\tlearn: 0.0968785\ttotal: 6.07s\tremaining: 293ms\n",
            "954:\tlearn: 0.0967606\ttotal: 6.08s\tremaining: 286ms\n",
            "955:\tlearn: 0.0966426\ttotal: 6.08s\tremaining: 280ms\n",
            "956:\tlearn: 0.0965519\ttotal: 6.08s\tremaining: 273ms\n",
            "957:\tlearn: 0.0964426\ttotal: 6.08s\tremaining: 267ms\n",
            "958:\tlearn: 0.0963856\ttotal: 6.09s\tremaining: 260ms\n",
            "959:\tlearn: 0.0962152\ttotal: 6.09s\tremaining: 254ms\n",
            "960:\tlearn: 0.0961288\ttotal: 6.09s\tremaining: 247ms\n",
            "961:\tlearn: 0.0960583\ttotal: 6.1s\tremaining: 241ms\n",
            "962:\tlearn: 0.0959314\ttotal: 6.1s\tremaining: 234ms\n",
            "963:\tlearn: 0.0957737\ttotal: 6.1s\tremaining: 228ms\n",
            "964:\tlearn: 0.0956802\ttotal: 6.11s\tremaining: 221ms\n",
            "965:\tlearn: 0.0955410\ttotal: 6.11s\tremaining: 215ms\n",
            "966:\tlearn: 0.0954148\ttotal: 6.11s\tremaining: 209ms\n",
            "967:\tlearn: 0.0952780\ttotal: 6.12s\tremaining: 202ms\n",
            "968:\tlearn: 0.0951614\ttotal: 6.12s\tremaining: 196ms\n",
            "969:\tlearn: 0.0950285\ttotal: 6.13s\tremaining: 189ms\n",
            "970:\tlearn: 0.0949656\ttotal: 6.13s\tremaining: 183ms\n",
            "971:\tlearn: 0.0949305\ttotal: 6.13s\tremaining: 177ms\n",
            "972:\tlearn: 0.0948308\ttotal: 6.14s\tremaining: 170ms\n",
            "973:\tlearn: 0.0946713\ttotal: 6.14s\tremaining: 164ms\n",
            "974:\tlearn: 0.0945337\ttotal: 6.14s\tremaining: 158ms\n",
            "975:\tlearn: 0.0944017\ttotal: 6.15s\tremaining: 151ms\n",
            "976:\tlearn: 0.0943869\ttotal: 6.15s\tremaining: 145ms\n",
            "977:\tlearn: 0.0942677\ttotal: 6.15s\tremaining: 138ms\n",
            "978:\tlearn: 0.0942128\ttotal: 6.16s\tremaining: 132ms\n",
            "979:\tlearn: 0.0941942\ttotal: 6.16s\tremaining: 126ms\n",
            "980:\tlearn: 0.0940601\ttotal: 6.17s\tremaining: 119ms\n",
            "981:\tlearn: 0.0939882\ttotal: 6.17s\tremaining: 113ms\n",
            "982:\tlearn: 0.0938068\ttotal: 6.17s\tremaining: 107ms\n",
            "983:\tlearn: 0.0937562\ttotal: 6.18s\tremaining: 100ms\n",
            "984:\tlearn: 0.0937145\ttotal: 6.18s\tremaining: 94.1ms\n",
            "985:\tlearn: 0.0936278\ttotal: 6.18s\tremaining: 87.8ms\n",
            "986:\tlearn: 0.0936110\ttotal: 6.19s\tremaining: 81.5ms\n",
            "987:\tlearn: 0.0933717\ttotal: 6.19s\tremaining: 75.2ms\n",
            "988:\tlearn: 0.0931678\ttotal: 6.19s\tremaining: 68.9ms\n",
            "989:\tlearn: 0.0930506\ttotal: 6.2s\tremaining: 62.6ms\n",
            "990:\tlearn: 0.0930321\ttotal: 6.2s\tremaining: 56.3ms\n",
            "991:\tlearn: 0.0928301\ttotal: 6.2s\tremaining: 50ms\n",
            "992:\tlearn: 0.0927191\ttotal: 6.21s\tremaining: 43.7ms\n",
            "993:\tlearn: 0.0926113\ttotal: 6.21s\tremaining: 37.5ms\n",
            "994:\tlearn: 0.0925401\ttotal: 6.21s\tremaining: 31.2ms\n",
            "995:\tlearn: 0.0924212\ttotal: 6.21s\tremaining: 25ms\n",
            "996:\tlearn: 0.0924061\ttotal: 6.22s\tremaining: 18.7ms\n",
            "997:\tlearn: 0.0923555\ttotal: 6.22s\tremaining: 12.5ms\n",
            "998:\tlearn: 0.0922419\ttotal: 6.22s\tremaining: 6.23ms\n",
            "999:\tlearn: 0.0921675\ttotal: 6.23s\tremaining: 0us\n",
            "('KNN', 0.69)\n",
            "('DTC', 0.76)\n",
            "('RFC', 0.765)\n",
            "('Adaboost', 0.795)\n",
            "('xgboost', 0.805)\n",
            "('Gradientboost', 0.825)\n",
            "('lgbm', 0.83)\n",
            "('cboost', 0.81)\n",
            "('svc', 0.775)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Printing it separately to showcase the result\n",
        "\n",
        "for i in results_score.items():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw9Jkv5A9nNN",
        "outputId": "2f3351a7-ecef-4b14-d99e-9c9f8f83ea2f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('KNN', 0.69)\n",
            "('DTC', 0.76)\n",
            "('RFC', 0.765)\n",
            "('Adaboost', 0.795)\n",
            "('xgboost', 0.805)\n",
            "('Gradientboost', 0.825)\n",
            "('lgbm', 0.83)\n",
            "('cboost', 0.81)\n",
            "('svc', 0.775)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm = LGBMClassifier(boosting_type='dart',num_leaves=45,min_child_samples=41)\n",
        "\n",
        "lgbm.fit(x_train, y_train)\n",
        "y_pred_rf = lgbm.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy: \", lgbm.score(x_train, y_train))\n",
        "print('Testing Accuarcy: ', lgbm.score(x_test, y_test))\n",
        "\n",
        "# making a classification report\n",
        "cr = classification_report(y_test,  y_pred_rf)\n",
        "print(cr)\n",
        "\n",
        "# making a confusion matrix\n",
        "plt.rcParams['figure.figsize'] = (5, 5)\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "print(cm)\n",
        "\n",
        "y_pred_prob = lgbm.predict_proba(x_test)[:,1]\n",
        "\n",
        "# call the function 'plot_roc' to plot the ROC curve\n",
        "# pass the decision tree model to the function\n",
        "plot_roc(lgbm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "YPvDiZF0_vRx",
        "outputId": "96b400b1-2890-4011-e15e-c93460e93ac6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.955\n",
            "Testing Accuarcy:  0.815\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       143\n",
            "           1       0.73      0.56      0.63        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.78      0.74      0.75       200\n",
            "weighted avg       0.81      0.81      0.81       200\n",
            "\n",
            "[[131  12]\n",
            " [ 25  32]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "def get_models():\n",
        "  models = dict()\n",
        "  types = ['gbdt','goss','dart']\n",
        "  for t in types:\n",
        "    models[t]=LGBMClassifier(boosting_type=t)\n",
        "  return models\n",
        "\n",
        "\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        "\n",
        "\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_YloVtSf8nf",
        "outputId": "cb651dc3-1edf-4eaa-b542-efb15d029cfa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">gbdt 0.832 (0.029)\n",
            ">goss 0.829 (0.028)\n",
            ">dart 0.835 (0.026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x3YX_0c0f83u"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1A4ytWyEf86K"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WfQpzc3cf886"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above model creation it looks like LightGBM , catboost, Gradient boost, XGboost, and Balanced Randomforrest classifier all gives more than 80% accuracy with default model. \n",
        "Will be performing hyperparameter tuning for the selected models only"
      ],
      "metadata": {
        "id": "aG8r4MNuLTrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Using optuna with lightgbm tuner for quicker results\n",
        "\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna.integration.lightgbm import LightGBMTunerCV\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjmDvuuL9nSf",
        "outputId": "031eebc8-9c1f-454a-fa4f-68ed41714817"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 36.0 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.1.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=66de8fd83751013d0ef3211a8246fd959aaedd1ad5bf640ad7647d4f7d43203a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    dtrain = lgb.Dataset(x_train, label=y_train)\n",
        "\n",
        "\n",
        "    param = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_logloss',\n",
        "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
        "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "    }\n",
        " \n",
        "    gbm = lgb.train(param, dtrain)\n",
        "    preds = gbm.predict(x_test)\n",
        "    pred_labels = np.rint(preds)\n",
        "    accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels)\n",
        "    print(\"The accuracy is \",accuracy)\n",
        "    print(\"classification report is\",classification_report(y_test,  pred_labels))\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        " \n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnbqqK4l9nVH",
        "outputId": "429956a1-57c8-44a6-d32a-5f1fb57ee3a1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:18,307]\u001b[0m A new study created in memory with name: no-name-ca03b692-6c5c-49c7-942e-62ab90425176\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:18,505]\u001b[0m Trial 0 finished with value: 0.79 and parameters: {'lambda_l1': 4.013905863904584, 'num_leaves': 228, 'feature_fraction': 0.8110814926520598, 'bagging_fraction': 0.8703466756542713, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 0 with value: 0.79.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:18,675]\u001b[0m Trial 1 finished with value: 0.795 and parameters: {'lambda_l1': 5.406263435925828e-05, 'num_leaves': 222, 'feature_fraction': 0.5000657454006672, 'bagging_fraction': 0.4531284614469552, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 1 with value: 0.795.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.79\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.87       143\n",
            "           1       0.74      0.40      0.52        57\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.77      0.67      0.69       200\n",
            "weighted avg       0.78      0.79      0.77       200\n",
            "\n",
            "The accuracy is  0.795\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.87       143\n",
            "           1       0.75      0.42      0.54        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.78      0.68      0.70       200\n",
            "weighted avg       0.79      0.80      0.77       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:18,873]\u001b[0m Trial 2 finished with value: 0.825 and parameters: {'lambda_l1': 0.8083361824590655, 'num_leaves': 63, 'feature_fraction': 0.49130029589336754, 'bagging_fraction': 0.8273249699773595, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 2 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.51      0.62        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.82      0.73      0.75       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:19,099]\u001b[0m Trial 3 finished with value: 0.79 and parameters: {'lambda_l1': 0.08692418937437621, 'num_leaves': 228, 'feature_fraction': 0.6877471165413989, 'bagging_fraction': 0.7243248919234708, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 2 with value: 0.825.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:19,224]\u001b[0m Trial 4 finished with value: 0.805 and parameters: {'lambda_l1': 2.2751263828324025e-05, 'num_leaves': 155, 'feature_fraction': 0.7250201915810214, 'bagging_fraction': 0.7203265216579573, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 2 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.79\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.86       143\n",
            "           1       0.73      0.42      0.53        57\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.76      0.68      0.70       200\n",
            "weighted avg       0.78      0.79      0.77       200\n",
            "\n",
            "The accuracy is  0.805\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.96      0.88       143\n",
            "           1       0.80      0.42      0.55        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.80      0.69      0.71       200\n",
            "weighted avg       0.80      0.81      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:19,374]\u001b[0m Trial 5 finished with value: 0.84 and parameters: {'lambda_l1': 1.8400225899334706, 'num_leaves': 52, 'feature_fraction': 0.9463818201160169, 'bagging_fraction': 0.8781618041089687, 'bagging_freq': 6, 'min_child_samples': 54}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:19,453]\u001b[0m Trial 6 finished with value: 0.8 and parameters: {'lambda_l1': 1.1440715517540996, 'num_leaves': 190, 'feature_fraction': 0.9973573940884208, 'bagging_fraction': 0.4871300676257299, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.84\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.96      0.90       143\n",
            "           1       0.84      0.54      0.66        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.84      0.75      0.78       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n",
            "The accuracy is  0.8\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.96      0.87       143\n",
            "           1       0.79      0.40      0.53        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.80      0.68      0.70       200\n",
            "weighted avg       0.80      0.80      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:19,595]\u001b[0m Trial 7 finished with value: 0.785 and parameters: {'lambda_l1': 3.7308535322605753e-08, 'num_leaves': 176, 'feature_fraction': 0.6127299971848958, 'bagging_fraction': 0.4035223100327749, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:19,697]\u001b[0m Trial 8 finished with value: 0.81 and parameters: {'lambda_l1': 1.630993955416046e-07, 'num_leaves': 178, 'feature_fraction': 0.6295997686289597, 'bagging_fraction': 0.7544148725619004, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.785\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86       143\n",
            "           1       0.73      0.39      0.51        57\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.76      0.67      0.68       200\n",
            "weighted avg       0.78      0.79      0.76       200\n",
            "\n",
            "The accuracy is  0.81\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.96      0.88       143\n",
            "           1       0.81      0.44      0.57        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.81      0.70      0.72       200\n",
            "weighted avg       0.81      0.81      0.79       200\n",
            "\n",
            "The accuracy is  0.78\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86       143\n",
            "           1       0.71      0.39      0.50        57\n",
            "\n",
            "    accuracy                           0.78       200\n",
            "   macro avg       0.75      0.66      0.68       200\n",
            "weighted avg       0.77      0.78      0.76       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:19,779]\u001b[0m Trial 9 finished with value: 0.78 and parameters: {'lambda_l1': 0.0015718846464029092, 'num_leaves': 110, 'feature_fraction': 0.4154959867562268, 'bagging_fraction': 0.7133918682430203, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:19,893]\u001b[0m Trial 10 finished with value: 0.815 and parameters: {'lambda_l1': 0.009134628777088809, 'num_leaves': 4, 'feature_fraction': 0.9885326650749612, 'bagging_fraction': 0.9727998836889663, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:19,993]\u001b[0m Trial 11 finished with value: 0.84 and parameters: {'lambda_l1': 7.099181067278666, 'num_leaves': 51, 'feature_fraction': 0.8562683726689446, 'bagging_fraction': 0.8578401000023035, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       143\n",
            "           1       0.73      0.56      0.63        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.78      0.74      0.75       200\n",
            "weighted avg       0.81      0.81      0.81       200\n",
            "\n",
            "The accuracy is  0.84\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       143\n",
            "           1       0.82      0.56      0.67        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.83      0.76      0.78       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n",
            "The accuracy is  0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:20,104]\u001b[0m Trial 12 finished with value: 0.82 and parameters: {'lambda_l1': 6.157241684697616, 'num_leaves': 44, 'feature_fraction': 0.8746867108638557, 'bagging_fraction': 0.9696419633705462, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:20,250]\u001b[0m Trial 13 finished with value: 0.835 and parameters: {'lambda_l1': 0.04327484803890485, 'num_leaves': 93, 'feature_fraction': 0.8781719506876735, 'bagging_fraction': 0.8680813960496603, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:20,300]\u001b[0m Trial 14 finished with value: 0.805 and parameters: {'lambda_l1': 0.213038882616195, 'num_leaves': 2, 'feature_fraction': 0.9034027412583377, 'bagging_fraction': 0.5823668303712741, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.96      0.88       143\n",
            "           1       0.82      0.47      0.60        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.82      0.72      0.74       200\n",
            "weighted avg       0.82      0.82      0.80       200\n",
            "\n",
            "The accuracy is  0.835\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       143\n",
            "           1       0.80      0.56      0.66        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.75      0.78       200\n",
            "weighted avg       0.83      0.83      0.83       200\n",
            "\n",
            "The accuracy is  0.805\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.97      0.88       143\n",
            "           1       0.82      0.40      0.54        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.81      0.68      0.71       200\n",
            "weighted avg       0.81      0.81      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:20,396]\u001b[0m Trial 15 finished with value: 0.76 and parameters: {'lambda_l1': 9.468887018524882, 'num_leaves': 54, 'feature_fraction': 0.7894830342862611, 'bagging_fraction': 0.6220765537138755, 'bagging_freq': 5, 'min_child_samples': 70}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:20,554]\u001b[0m Trial 16 finished with value: 0.815 and parameters: {'lambda_l1': 2.2752641381658865e-06, 'num_leaves': 32, 'feature_fraction': 0.9273364006299928, 'bagging_fraction': 0.8129753641833626, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.76\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.97      0.85       143\n",
            "           1       0.76      0.23      0.35        57\n",
            "\n",
            "    accuracy                           0.76       200\n",
            "   macro avg       0.76      0.60      0.60       200\n",
            "weighted avg       0.76      0.76      0.71       200\n",
            "\n",
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.78      0.49      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.80      0.72      0.74       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:20,710]\u001b[0m Trial 17 finished with value: 0.825 and parameters: {'lambda_l1': 0.0018263024140184698, 'num_leaves': 84, 'feature_fraction': 0.8033408171035897, 'bagging_fraction': 0.9173535367846086, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:20,898]\u001b[0m Trial 18 finished with value: 0.785 and parameters: {'lambda_l1': 0.010533219243036317, 'num_leaves': 123, 'feature_fraction': 0.9547896378864793, 'bagging_fraction': 0.639004327553601, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89       143\n",
            "           1       0.82      0.49      0.62        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.82      0.72      0.75       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n",
            "The accuracy is  0.785\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86       143\n",
            "           1       0.73      0.39      0.51        57\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.76      0.67      0.68       200\n",
            "weighted avg       0.78      0.79      0.76       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:21,107]\u001b[0m Trial 19 finished with value: 0.775 and parameters: {'lambda_l1': 0.4148670106014495, 'num_leaves': 77, 'feature_fraction': 0.8430577266556135, 'bagging_fraction': 0.7935180277064781, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.775\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.95      0.86       143\n",
            "           1       0.73      0.33      0.46        57\n",
            "\n",
            "    accuracy                           0.78       200\n",
            "   macro avg       0.76      0.64      0.66       200\n",
            "weighted avg       0.77      0.78      0.74       200\n",
            "\n",
            "The accuracy is  0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:21,308]\u001b[0m Trial 20 finished with value: 0.81 and parameters: {'lambda_l1': 0.00014744957008787916, 'num_leaves': 26, 'feature_fraction': 0.735379282499177, 'bagging_fraction': 0.8955612863891669, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:21,454]\u001b[0m Trial 21 finished with value: 0.825 and parameters: {'lambda_l1': 0.06405447670238418, 'num_leaves': 98, 'feature_fraction': 0.8674871126340146, 'bagging_fraction': 0.8527053279865414, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.76      0.49      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.71      0.74       200\n",
            "weighted avg       0.80      0.81      0.80       200\n",
            "\n",
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       143\n",
            "           1       0.79      0.53      0.63        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.74      0.76       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:21,593]\u001b[0m Trial 22 finished with value: 0.83 and parameters: {'lambda_l1': 0.08670652825638311, 'num_leaves': 144, 'feature_fraction': 0.9225531922429788, 'bagging_fraction': 0.9258975839959648, 'bagging_freq': 6, 'min_child_samples': 57}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:21,731]\u001b[0m Trial 23 finished with value: 0.83 and parameters: {'lambda_l1': 1.4872570174716853, 'num_leaves': 78, 'feature_fraction': 0.8487104447540684, 'bagging_fraction': 0.9888774215248379, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.53      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n",
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.53      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:21,859]\u001b[0m Trial 24 finished with value: 0.815 and parameters: {'lambda_l1': 0.027395000866813644, 'num_leaves': 101, 'feature_fraction': 0.7603683707759915, 'bagging_fraction': 0.7757646069595422, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:21,996]\u001b[0m Trial 25 finished with value: 0.84 and parameters: {'lambda_l1': 0.0021534502133413744, 'num_leaves': 60, 'feature_fraction': 0.9538576002263606, 'bagging_fraction': 0.9205338603046047, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.95      0.88       143\n",
            "           1       0.79      0.47      0.59        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.81      0.71      0.74       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n",
            "The accuracy is  0.84\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       143\n",
            "           1       0.82      0.56      0.67        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.83      0.76      0.78       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:22,116]\u001b[0m Trial 26 finished with value: 0.81 and parameters: {'lambda_l1': 0.0016193232252538227, 'num_leaves': 24, 'feature_fraction': 0.9539750158707483, 'bagging_fraction': 0.9382265977384618, 'bagging_freq': 3, 'min_child_samples': 74}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:22,243]\u001b[0m Trial 27 finished with value: 0.84 and parameters: {'lambda_l1': 3.291430678905799e-06, 'num_leaves': 54, 'feature_fraction': 0.9993989871563359, 'bagging_fraction': 0.8484061165365068, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.76      0.49      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.71      0.74       200\n",
            "weighted avg       0.80      0.81      0.80       200\n",
            "\n",
            "The accuracy is  0.84\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89       143\n",
            "           1       0.80      0.58      0.67        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.83      0.76      0.78       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:22,365]\u001b[0m Trial 28 finished with value: 0.8 and parameters: {'lambda_l1': 2.82131573057883e-06, 'num_leaves': 69, 'feature_fraction': 0.9878860313607759, 'bagging_fraction': 0.8160282344243522, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:22,475]\u001b[0m Trial 29 finished with value: 0.83 and parameters: {'lambda_l1': 5.970405990029965e-06, 'num_leaves': 38, 'feature_fraction': 0.9435808511293887, 'bagging_fraction': 0.8874986009728377, 'bagging_freq': 4, 'min_child_samples': 79}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.8\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87       143\n",
            "           1       0.76      0.44      0.56        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.78      0.69      0.71       200\n",
            "weighted avg       0.79      0.80      0.78       200\n",
            "\n",
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89       143\n",
            "           1       0.87      0.47      0.61        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.85      0.72      0.75       200\n",
            "weighted avg       0.84      0.83      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:22,591]\u001b[0m Trial 30 finished with value: 0.81 and parameters: {'lambda_l1': 2.5894842780144535e-07, 'num_leaves': 255, 'feature_fraction': 0.908921276055969, 'bagging_fraction': 0.6596829076395488, 'bagging_freq': 2, 'min_child_samples': 55}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:22,741]\u001b[0m Trial 31 finished with value: 0.82 and parameters: {'lambda_l1': 0.00028366321417803514, 'num_leaves': 54, 'feature_fraction': 0.9613483348797858, 'bagging_fraction': 0.8504234320481476, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.76      0.49      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.71      0.74       200\n",
            "weighted avg       0.80      0.81      0.80       200\n",
            "\n",
            "The accuracy is  0.82\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88       143\n",
            "           1       0.78      0.51      0.62        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.73      0.75       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:22,941]\u001b[0m Trial 32 finished with value: 0.815 and parameters: {'lambda_l1': 3.6155001479605535, 'num_leaves': 16, 'feature_fraction': 0.8225550219444275, 'bagging_fraction': 0.9358598213244749, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.78      0.49      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.80      0.72      0.74       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:23,161]\u001b[0m Trial 33 finished with value: 0.825 and parameters: {'lambda_l1': 2.017443404048559e-05, 'num_leaves': 55, 'feature_fraction': 0.895181334473484, 'bagging_fraction': 0.8452849032016114, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:23,344]\u001b[0m Trial 34 finished with value: 0.795 and parameters: {'lambda_l1': 4.3709293669520887e-07, 'num_leaves': 64, 'feature_fraction': 0.9963835027510382, 'bagging_fraction': 0.7597892721548583, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       143\n",
            "           1       0.79      0.53      0.63        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.74      0.76       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n",
            "The accuracy is  0.795\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87       143\n",
            "           1       0.72      0.46      0.56        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.77      0.69      0.71       200\n",
            "weighted avg       0.79      0.80      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:23,516]\u001b[0m Trial 35 finished with value: 0.79 and parameters: {'lambda_l1': 1.9924096868364571, 'num_leaves': 44, 'feature_fraction': 0.680182982785718, 'bagging_fraction': 0.8883312348215444, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.79\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.86       143\n",
            "           1       0.73      0.42      0.53        57\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.76      0.68      0.70       200\n",
            "weighted avg       0.78      0.79      0.77       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:23,779]\u001b[0m Trial 36 finished with value: 0.83 and parameters: {'lambda_l1': 0.3379876668245654, 'num_leaves': 121, 'feature_fraction': 0.9579425701909405, 'bagging_fraction': 0.9569177678476465, 'bagging_freq': 5, 'min_child_samples': 49}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.53      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n",
            "The accuracy is  0.805"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:23,982]\u001b[0m Trial 37 finished with value: 0.805 and parameters: {'lambda_l1': 5.45146283117967e-05, 'num_leaves': 86, 'feature_fraction': 0.564209648563939, 'bagging_fraction': 0.9997030025977705, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.93      0.87       143\n",
            "           1       0.74      0.49      0.59        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.78      0.71      0.73       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:24,233]\u001b[0m Trial 38 finished with value: 0.835 and parameters: {'lambda_l1': 0.004297047139623017, 'num_leaves': 139, 'feature_fraction': 0.9253758418720495, 'bagging_fraction': 0.9047016081647424, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:24,407]\u001b[0m Trial 39 finished with value: 0.8 and parameters: {'lambda_l1': 0.6145367384459354, 'num_leaves': 15, 'feature_fraction': 0.775734347722544, 'bagging_fraction': 0.6856741510784108, 'bagging_freq': 4, 'min_child_samples': 73}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.835\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       143\n",
            "           1       0.80      0.56      0.66        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.75      0.78       200\n",
            "weighted avg       0.83      0.83      0.83       200\n",
            "\n",
            "The accuracy is  0.8\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87       143\n",
            "           1       0.74      0.46      0.57        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.78      0.70      0.72       200\n",
            "weighted avg       0.79      0.80      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:24,578]\u001b[0m Trial 40 finished with value: 0.77 and parameters: {'lambda_l1': 3.054967381687438e-08, 'num_leaves': 71, 'feature_fraction': 0.8252648656725199, 'bagging_fraction': 0.5173326588220677, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.77\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.94      0.85       143\n",
            "           1       0.69      0.35      0.47        57\n",
            "\n",
            "    accuracy                           0.77       200\n",
            "   macro avg       0.74      0.64      0.66       200\n",
            "weighted avg       0.76      0.77      0.74       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:24,856]\u001b[0m Trial 41 finished with value: 0.825 and parameters: {'lambda_l1': 0.0051642076326517145, 'num_leaves': 141, 'feature_fraction': 0.9260376920386679, 'bagging_fraction': 0.9011165996252177, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       143\n",
            "           1       0.79      0.53      0.63        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.74      0.76       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:25,113]\u001b[0m Trial 42 finished with value: 0.815 and parameters: {'lambda_l1': 0.0003181647637137381, 'num_leaves': 174, 'feature_fraction': 0.9724125381503337, 'bagging_fraction': 0.8323102350635343, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88       143\n",
            "           1       0.76      0.51      0.61        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.80      0.72      0.74       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:25,455]\u001b[0m Trial 43 finished with value: 0.83 and parameters: {'lambda_l1': 0.0006146265795982458, 'num_leaves': 163, 'feature_fraction': 0.8840084534586197, 'bagging_fraction': 0.8784722733783344, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.53      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:25,771]\u001b[0m Trial 44 finished with value: 0.82 and parameters: {'lambda_l1': 0.1936419568943834, 'num_leaves': 112, 'feature_fraction': 0.9999478098673307, 'bagging_fraction': 0.7367625934318051, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.82\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.95      0.88       143\n",
            "           1       0.80      0.49      0.61        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.72      0.75       200\n",
            "weighted avg       0.82      0.82      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:26,033]\u001b[0m Trial 45 finished with value: 0.82 and parameters: {'lambda_l1': 0.028060467261733325, 'num_leaves': 97, 'feature_fraction': 0.8521759929518312, 'bagging_fraction': 0.7948961371138097, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.82\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88       143\n",
            "           1       0.78      0.51      0.62        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.73      0.75       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:26,265]\u001b[0m Trial 46 finished with value: 0.815 and parameters: {'lambda_l1': 3.2828639417049548, 'num_leaves': 54, 'feature_fraction': 0.8859884906859282, 'bagging_fraction': 0.8646585018016963, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.78      0.49      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.80      0.72      0.74       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:26,568]\u001b[0m Trial 47 finished with value: 0.795 and parameters: {'lambda_l1': 0.02566934602295498, 'num_leaves': 39, 'feature_fraction': 0.6688323301310609, 'bagging_fraction': 0.9672577299819204, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.795\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.92      0.86       143\n",
            "           1       0.70      0.49      0.58        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.76      0.70      0.72       200\n",
            "weighted avg       0.78      0.80      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:26,876]\u001b[0m Trial 48 finished with value: 0.82 and parameters: {'lambda_l1': 0.004057835889622558, 'num_leaves': 194, 'feature_fraction': 0.9319244744974643, 'bagging_fraction': 0.9109984941248513, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.82\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.95      0.88       143\n",
            "           1       0.80      0.49      0.61        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.72      0.75       200\n",
            "weighted avg       0.82      0.82      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:27,085]\u001b[0m Trial 49 finished with value: 0.8 and parameters: {'lambda_l1': 7.439871340913433, 'num_leaves': 88, 'feature_fraction': 0.9739638697170143, 'bagging_fraction': 0.8049652090938021, 'bagging_freq': 1, 'min_child_samples': 59}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:27,264]\u001b[0m Trial 50 finished with value: 0.825 and parameters: {'lambda_l1': 7.842107045151334e-05, 'num_leaves': 214, 'feature_fraction': 0.9046938165431067, 'bagging_fraction': 0.9504244463848858, 'bagging_freq': 6, 'min_child_samples': 66}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.8\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87       143\n",
            "           1       0.76      0.44      0.56        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.78      0.69      0.71       200\n",
            "weighted avg       0.79      0.80      0.78       200\n",
            "\n",
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88       143\n",
            "           1       0.76      0.56      0.65        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.80      0.75      0.77       200\n",
            "weighted avg       0.82      0.82      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:27,527]\u001b[0m Trial 51 finished with value: 0.805 and parameters: {'lambda_l1': 0.01378093233254836, 'num_leaves': 143, 'feature_fraction': 0.4077450200316947, 'bagging_fraction': 0.8673273191850888, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.805\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.87       143\n",
            "           1       0.75      0.47      0.58        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.78      0.71      0.73       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:27,856]\u001b[0m Trial 52 finished with value: 0.815 and parameters: {'lambda_l1': 0.001086326649768386, 'num_leaves': 62, 'feature_fraction': 0.9395273974940881, 'bagging_fraction': 0.8302658524921571, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       143\n",
            "           1       0.75      0.53      0.62        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.73      0.75       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:28,332]\u001b[0m Trial 53 finished with value: 0.82 and parameters: {'lambda_l1': 1.3383196202680318e-08, 'num_leaves': 49, 'feature_fraction': 0.8719300762024549, 'bagging_fraction': 0.906772868089695, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.82\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88       143\n",
            "           1       0.78      0.51      0.62        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.73      0.75       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n",
            "The accuracy is  0.815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:28,511]\u001b[0m Trial 54 finished with value: 0.815 and parameters: {'lambda_l1': 0.004456072183016707, 'num_leaves': 108, 'feature_fraction': 0.4460022246432328, 'bagging_fraction': 0.9259378843512236, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.96      0.88       143\n",
            "           1       0.81      0.46      0.58        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.81      0.71      0.73       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:28,833]\u001b[0m Trial 55 finished with value: 0.805 and parameters: {'lambda_l1': 1.007937356293732, 'num_leaves': 30, 'feature_fraction': 0.9736069543895238, 'bagging_fraction': 0.7754952617559887, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.805\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.92      0.87       143\n",
            "           1       0.72      0.51      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.77      0.72      0.73       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:29,055]\u001b[0m Trial 56 finished with value: 0.84 and parameters: {'lambda_l1': 0.05391049373166635, 'num_leaves': 76, 'feature_fraction': 0.9161299552149514, 'bagging_fraction': 0.856664834840014, 'bagging_freq': 6, 'min_child_samples': 58}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:29,233]\u001b[0m Trial 57 finished with value: 0.785 and parameters: {'lambda_l1': 0.18769372667512566, 'num_leaves': 131, 'feature_fraction': 0.9126668195037553, 'bagging_fraction': 0.40570902334173037, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.84\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       143\n",
            "           1       0.82      0.56      0.67        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.83      0.76      0.78       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n",
            "The accuracy is  0.785\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.95      0.86       143\n",
            "           1       0.75      0.37      0.49        57\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.77      0.66      0.68       200\n",
            "weighted avg       0.78      0.79      0.76       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:29,508]\u001b[0m Trial 58 finished with value: 0.805 and parameters: {'lambda_l1': 1.719607773228893e-05, 'num_leaves': 79, 'feature_fraction': 0.9404412354079164, 'bagging_fraction': 0.8349215509075186, 'bagging_freq': 6, 'min_child_samples': 64}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.805\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.95      0.87       143\n",
            "           1       0.78      0.44      0.56        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.80      0.69      0.72       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:29,755]\u001b[0m Trial 59 finished with value: 0.795 and parameters: {'lambda_l1': 0.09745296163610229, 'num_leaves': 66, 'feature_fraction': 0.8622106411248855, 'bagging_fraction': 0.8630676383011102, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.795\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87       143\n",
            "           1       0.74      0.44      0.55        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.77      0.69      0.71       200\n",
            "weighted avg       0.79      0.80      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:30,006]\u001b[0m Trial 60 finished with value: 0.815 and parameters: {'lambda_l1': 0.002849982080846003, 'num_leaves': 15, 'feature_fraction': 0.8360175079263246, 'bagging_fraction': 0.9812777306851077, 'bagging_freq': 7, 'min_child_samples': 60}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       143\n",
            "           1       0.74      0.54      0.63        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.73      0.75       200\n",
            "weighted avg       0.81      0.81      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:30,303]\u001b[0m Trial 61 finished with value: 0.84 and parameters: {'lambda_l1': 0.045036772488189214, 'num_leaves': 94, 'feature_fraction': 0.8938575945553257, 'bagging_fraction': 0.8928396679017985, 'bagging_freq': 6, 'min_child_samples': 48}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.84\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       143\n",
            "           1       0.82      0.56      0.67        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.83      0.76      0.78       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:30,550]\u001b[0m Trial 62 finished with value: 0.82 and parameters: {'lambda_l1': 0.007520375842347852, 'num_leaves': 71, 'feature_fraction': 0.9077842567720751, 'bagging_fraction': 0.9392370100907411, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.82\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88       143\n",
            "           1       0.77      0.53      0.62        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.80      0.73      0.75       200\n",
            "weighted avg       0.81      0.82      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:30,784]\u001b[0m Trial 63 finished with value: 0.82 and parameters: {'lambda_l1': 0.056283880762519, 'num_leaves': 86, 'feature_fraction': 0.8869478978398401, 'bagging_fraction': 0.8716679568131408, 'bagging_freq': 6, 'min_child_samples': 54}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:30,955]\u001b[0m Trial 64 finished with value: 0.805 and parameters: {'lambda_l1': 2.0264757877457735, 'num_leaves': 93, 'feature_fraction': 0.9795753262933697, 'bagging_fraction': 0.8140052602979754, 'bagging_freq': 7, 'min_child_samples': 69}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.82\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88       143\n",
            "           1       0.78      0.51      0.62        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.73      0.75       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n",
            "The accuracy is  0.805\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.95      0.87       143\n",
            "           1       0.78      0.44      0.56        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.80      0.69      0.72       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:31,243]\u001b[0m Trial 65 finished with value: 0.83 and parameters: {'lambda_l1': 0.001074380683453041, 'num_leaves': 39, 'feature_fraction': 0.9498980118802752, 'bagging_fraction': 0.9141641119377482, 'bagging_freq': 6, 'min_child_samples': 58}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       143\n",
            "           1       0.78      0.56      0.65        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.81      0.75      0.77       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:31,547]\u001b[0m Trial 66 finished with value: 0.83 and parameters: {'lambda_l1': 0.01589771966048875, 'num_leaves': 59, 'feature_fraction': 0.7984800614020025, 'bagging_fraction': 0.8864845457920193, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:31,713]\u001b[0m Trial 67 finished with value: 0.825 and parameters: {'lambda_l1': 0.7281307254478196, 'num_leaves': 77, 'feature_fraction': 0.7188672369684652, 'bagging_fraction': 0.8483868834209612, 'bagging_freq': 7, 'min_child_samples': 51}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89       143\n",
            "           1       0.83      0.51      0.63        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.83      0.73      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n",
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       143\n",
            "           1       0.79      0.53      0.63        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.74      0.76       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:31,959]\u001b[0m Trial 68 finished with value: 0.81 and parameters: {'lambda_l1': 4.711027674975722, 'num_leaves': 45, 'feature_fraction': 0.9217326565522937, 'bagging_fraction': 0.5775743830865243, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.77      0.47      0.59        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.71      0.73       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n",
            "The accuracy is  0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:32,161]\u001b[0m Trial 69 finished with value: 0.81 and parameters: {'lambda_l1': 7.853034938890818e-07, 'num_leaves': 109, 'feature_fraction': 0.5423256251187822, 'bagging_fraction': 0.9485279777737603, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.77      0.47      0.59        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.71      0.73       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:32,454]\u001b[0m Trial 70 finished with value: 0.815 and parameters: {'lambda_l1': 0.11557525801886383, 'num_leaves': 153, 'feature_fraction': 0.9624746395020991, 'bagging_fraction': 0.7792756469173351, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.96      0.88       143\n",
            "           1       0.81      0.46      0.58        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.81      0.71      0.73       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:32,738]\u001b[0m Trial 71 finished with value: 0.825 and parameters: {'lambda_l1': 0.04683744329225054, 'num_leaves': 128, 'feature_fraction': 0.8974798653902585, 'bagging_fraction': 0.8858896502947982, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       143\n",
            "           1       0.79      0.53      0.63        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.74      0.76       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:33,086]\u001b[0m Trial 72 finished with value: 0.81 and parameters: {'lambda_l1': 0.38635497321145473, 'num_leaves': 117, 'feature_fraction': 0.8620624020511767, 'bagging_fraction': 0.9225430777692575, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       143\n",
            "           1       0.74      0.51      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.78      0.72      0.74       200\n",
            "weighted avg       0.80      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:33,330]\u001b[0m Trial 73 finished with value: 0.83 and parameters: {'lambda_l1': 0.0004489692360351842, 'num_leaves': 102, 'feature_fraction': 0.8145115770445546, 'bagging_fraction': 0.8993003748825739, 'bagging_freq': 6, 'min_child_samples': 50}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.53      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:33,612]\u001b[0m Trial 74 finished with value: 0.825 and parameters: {'lambda_l1': 0.029978354708829855, 'num_leaves': 50, 'feature_fraction': 0.9161137911943948, 'bagging_fraction': 0.8514766472136568, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 5 with value: 0.84.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:33,793]\u001b[0m Trial 75 finished with value: 0.805 and parameters: {'lambda_l1': 0.002455378749911977, 'num_leaves': 74, 'feature_fraction': 0.9471416072050157, 'bagging_fraction': 0.8214672368559178, 'bagging_freq': 5, 'min_child_samples': 62}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       143\n",
            "           1       0.79      0.53      0.63        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.74      0.76       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n",
            "The accuracy is  0.805\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.87       143\n",
            "           1       0.75      0.47      0.58        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.78      0.71      0.73       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:34,083]\u001b[0m Trial 76 finished with value: 0.83 and parameters: {'lambda_l1': 8.836741417911182e-08, 'num_leaves': 60, 'feature_fraction': 0.9907682241814852, 'bagging_fraction': 0.8997090551787006, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       143\n",
            "           1       0.79      0.54      0.65        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.77       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:34,352]\u001b[0m Trial 77 finished with value: 0.835 and parameters: {'lambda_l1': 0.01023737488363644, 'num_leaves': 91, 'feature_fraction': 0.9314342286549864, 'bagging_fraction': 0.9662874345435305, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 5 with value: 0.84.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.835\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       143\n",
            "           1       0.82      0.54      0.65        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.83      0.75      0.77       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:34,702]\u001b[0m Trial 78 finished with value: 0.845 and parameters: {'lambda_l1': 1.9934368699840848, 'num_leaves': 22, 'feature_fraction': 0.8329762498052657, 'bagging_fraction': 0.8392320432237224, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 78 with value: 0.845.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.845\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       143\n",
            "           1       0.84      0.56      0.67        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.84      0.76      0.79       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:34,962]\u001b[0m Trial 79 finished with value: 0.825 and parameters: {'lambda_l1': 2.4130246863142273, 'num_leaves': 22, 'feature_fraction': 0.8494020660880004, 'bagging_fraction': 0.752696901466747, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 78 with value: 0.845.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:35,134]\u001b[0m Trial 80 finished with value: 0.84 and parameters: {'lambda_l1': 7.204826448004793, 'num_leaves': 35, 'feature_fraction': 0.7551740145570688, 'bagging_fraction': 0.8354976478995292, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 78 with value: 0.845.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       143\n",
            "           1       0.79      0.53      0.63        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.74      0.76       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n",
            "The accuracy is  0.84\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89       143\n",
            "           1       0.80      0.58      0.67        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.83      0.76      0.78       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:35,277]\u001b[0m Trial 81 finished with value: 0.83 and parameters: {'lambda_l1': 9.333408372933057, 'num_leaves': 34, 'feature_fraction': 0.7830670772417275, 'bagging_fraction': 0.9671501326601186, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 78 with value: 0.845.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.53      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:35,507]\u001b[0m Trial 82 finished with value: 0.82 and parameters: {'lambda_l1': 1.3532384083195639, 'num_leaves': 24, 'feature_fraction': 0.8352342417445481, 'bagging_fraction': 0.8390426841342282, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 78 with value: 0.845.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:35,666]\u001b[0m Trial 83 finished with value: 0.805 and parameters: {'lambda_l1': 3.7311465099630166, 'num_leaves': 8, 'feature_fraction': 0.7530356967999597, 'bagging_fraction': 0.8591901085904948, 'bagging_freq': 3, 'min_child_samples': 64}. Best is trial 78 with value: 0.845.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.82\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.96      0.88       143\n",
            "           1       0.82      0.47      0.60        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.82      0.72      0.74       200\n",
            "weighted avg       0.82      0.82      0.80       200\n",
            "\n",
            "The accuracy is  0.805\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87       143\n",
            "           1       0.76      0.46      0.57        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.70      0.72       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:35,903]\u001b[0m Trial 84 finished with value: 0.815 and parameters: {'lambda_l1': 0.5782006976731296, 'num_leaves': 46, 'feature_fraction': 0.6421841339696411, 'bagging_fraction': 0.7957192593147477, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 78 with value: 0.845.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.78      0.49      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.80      0.72      0.74       200\n",
            "weighted avg       0.81      0.81      0.80       200\n",
            "\n",
            "The accuracy is  0.845\n",
            "classification report is "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:36,082]\u001b[0m Trial 85 finished with value: 0.845 and parameters: {'lambda_l1': 5.0456921359406035, 'num_leaves': 8, 'feature_fraction': 0.7651809590303996, 'bagging_fraction': 0.8756828768112648, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 78 with value: 0.845.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:36,227]\u001b[0m Trial 86 finished with value: 0.83 and parameters: {'lambda_l1': 6.591490413683053, 'num_leaves': 9, 'feature_fraction': 0.7540644217684804, 'bagging_fraction': 0.8769766931744885, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 78 with value: 0.845.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90       143\n",
            "           1       0.82      0.58      0.68        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.84      0.76      0.79       200\n",
            "weighted avg       0.84      0.84      0.84       200\n",
            "\n",
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       143\n",
            "           1       0.78      0.56      0.65        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.81      0.75      0.77       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:36,447]\u001b[0m Trial 87 finished with value: 0.825 and parameters: {'lambda_l1': 1.2282317863536485, 'num_leaves': 36, 'feature_fraction': 0.7400501951988075, 'bagging_fraction': 0.8161470245949455, 'bagging_freq': 3, 'min_child_samples': 60}. Best is trial 78 with value: 0.845.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:36,570]\u001b[0m Trial 88 finished with value: 0.795 and parameters: {'lambda_l1': 2.320840370170917, 'num_leaves': 2, 'feature_fraction': 0.7083139822428963, 'bagging_fraction': 0.841763276644119, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 78 with value: 0.845.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       143\n",
            "           1       0.79      0.53      0.63        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.81      0.74      0.76       200\n",
            "weighted avg       0.82      0.82      0.81       200\n",
            "\n",
            "The accuracy is  0.795\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.98      0.87       143\n",
            "           1       0.86      0.33      0.48        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.83      0.66      0.68       200\n",
            "weighted avg       0.81      0.80      0.76       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:36,799]\u001b[0m Trial 89 finished with value: 0.765 and parameters: {'lambda_l1': 9.899852035141203, 'num_leaves': 29, 'feature_fraction': 0.768689265731, 'bagging_fraction': 0.9284223047494305, 'bagging_freq': 4, 'min_child_samples': 71}. Best is trial 78 with value: 0.845.\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:36,936]\u001b[0m Trial 90 finished with value: 0.835 and parameters: {'lambda_l1': 5.569285005634695, 'num_leaves': 19, 'feature_fraction': 0.8200868331951408, 'bagging_fraction': 0.8845199941421401, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 78 with value: 0.845.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.765\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.94      0.85       143\n",
            "           1       0.69      0.32      0.43        57\n",
            "\n",
            "    accuracy                           0.77       200\n",
            "   macro avg       0.73      0.63      0.64       200\n",
            "weighted avg       0.75      0.77      0.73       200\n",
            "\n",
            "The accuracy is  0.835\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       143\n",
            "           1       0.82      0.54      0.65        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.83      0.75      0.77       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:37,219]\u001b[0m Trial 91 finished with value: 0.85 and parameters: {'lambda_l1': 0.18204388422954523, 'num_leaves': 53, 'feature_fraction': 0.7959845595031398, 'bagging_fraction': 0.8695337771568936, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.85\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90       143\n",
            "           1       0.83      0.60      0.69        57\n",
            "\n",
            "    accuracy                           0.85       200\n",
            "   macro avg       0.84      0.77      0.80       200\n",
            "weighted avg       0.85      0.85      0.84       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:37,627]\u001b[0m Trial 92 finished with value: 0.84 and parameters: {'lambda_l1': 0.2026406758087317, 'num_leaves': 52, 'feature_fraction': 0.7384098905952432, 'bagging_fraction': 0.8581180012706952, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.84\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89       143\n",
            "           1       0.80      0.58      0.67        57\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.83      0.76      0.78       200\n",
            "weighted avg       0.84      0.84      0.83       200\n",
            "\n",
            "The accuracy is  0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:37,810]\u001b[0m Trial 93 finished with value: 0.835 and parameters: {'lambda_l1': 0.26924796597881967, 'num_leaves': 42, 'feature_fraction': 0.7296539467903338, 'bagging_fraction': 0.8739927865605956, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.97      0.89       143\n",
            "           1       0.85      0.51      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.84      0.74      0.77       200\n",
            "weighted avg       0.84      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:38,074]\u001b[0m Trial 94 finished with value: 0.83 and parameters: {'lambda_l1': 0.12229737011216735, 'num_leaves': 57, 'feature_fraction': 0.8058106518899587, 'bagging_fraction': 0.8569508557770407, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.53      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:38,317]\u001b[0m Trial 95 finished with value: 0.81 and parameters: {'lambda_l1': 3.658087053283633, 'num_leaves': 68, 'feature_fraction': 0.7884387548111327, 'bagging_fraction': 0.799947620868753, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       143\n",
            "           1       0.77      0.47      0.59        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.79      0.71      0.73       200\n",
            "weighted avg       0.80      0.81      0.79       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:38,524]\u001b[0m Trial 96 finished with value: 0.81 and parameters: {'lambda_l1': 0.4940163371548219, 'num_leaves': 51, 'feature_fraction': 0.741481968019915, 'bagging_fraction': 0.8359526223294461, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       143\n",
            "           1       0.74      0.51      0.60        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.78      0.72      0.74       200\n",
            "weighted avg       0.80      0.81      0.80       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:38,962]\u001b[0m Trial 97 finished with value: 0.8 and parameters: {'lambda_l1': 0.19481859688811415, 'num_leaves': 11, 'feature_fraction': 0.6918429105458074, 'bagging_fraction': 0.8937858938684249, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.8\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87       143\n",
            "           1       0.74      0.46      0.57        57\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.78      0.70      0.72       200\n",
            "weighted avg       0.79      0.80      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:39,294]\u001b[0m Trial 98 finished with value: 0.83 and parameters: {'lambda_l1': 0.9219690248231355, 'num_leaves': 82, 'feature_fraction': 0.7960613817126514, 'bagging_fraction': 0.9150949363904582, 'bagging_freq': 3, 'min_child_samples': 58}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.83\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89       143\n",
            "           1       0.81      0.53      0.64        57\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.82      0.74      0.76       200\n",
            "weighted avg       0.83      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:39,512]\u001b[0m Trial 99 finished with value: 0.785 and parameters: {'lambda_l1': 0.07116912331893514, 'num_leaves': 30, 'feature_fraction': 0.7523179889748607, 'bagging_fraction': 0.8236105313125106, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 91 with value: 0.85.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.785\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.86       143\n",
            "           1       0.72      0.40      0.52        57\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.76      0.67      0.69       200\n",
            "weighted avg       0.78      0.79      0.76       200\n",
            "\n",
            "Number of finished trials: 100\n",
            "Best trial: {'lambda_l1': 0.18204388422954523, 'num_leaves': 53, 'feature_fraction': 0.7959845595031398, 'bagging_fraction': 0.8695337771568936, 'bagging_freq': 4, 'min_child_samples': 48}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of finished trials: 100\n",
        "Best trial: {'lambda_l1': 0.15323096143927795, 'lambda_l2': 0.6282461268479401, 'num_leaves': 45, 'feature_fraction': 0.9593589690959037, 'bagging_fraction': 0.9319851029904072, 'bagging_freq': 4, 'min_child_samples': 41}\n",
        "\n",
        "Best Accuracy is 0.82"
      ],
      "metadata": {
        "id": "7qeHFcgCU8Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### CATBOOST\n",
        "\n",
        "import catboost as cb\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    param = {\n",
        "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
        "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
        "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
        "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
        "        \"bootstrap_type\": trial.suggest_categorical(\n",
        "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
        "        ),\n",
        "        \"used_ram_limit\": \"3gb\",\n",
        "    }\n",
        "\n",
        "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
        "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
        "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
        "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
        "\n",
        "    cbc = cb.CatBoostClassifier(**param)\n",
        "\n",
        "    cbc.fit(x_train, y_train, verbose=0, early_stopping_rounds=100)\n",
        "\n",
        "    preds = cbc.predict(x_test)\n",
        "    pred_labels = np.rint(preds)\n",
        "    accuracy = accuracy_score(y_test, pred_labels)\n",
        "    print(\"The accuracy is \",accuracy)\n",
        "    # making a classification report\n",
        "    \n",
        "    return accuracy\n",
        "  \n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50, timeout=600)\n",
        "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbHZK08B9nbr",
        "outputId": "37af0ed2-7e36-4420-c38b-007c2c294c7e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:39,667]\u001b[0m A new study created in memory with name: no-name-f9b15654-2c61-43cd-8b01-babe1050928d\u001b[0m\n",
            "\u001b[32m[I 2022-02-24 16:28:51,073]\u001b[0m Trial 0 finished with value: 0.74 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09868662662041747, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3412079141434642}. Best is trial 0 with value: 0.74.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:52,595]\u001b[0m Trial 1 finished with value: 0.735 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08585709101334543, 'depth': 2, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.961125348187876}. Best is trial 0 with value: 0.74.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:57,078]\u001b[0m Trial 2 finished with value: 0.715 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.013125677808355203, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.74.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:28:59,348]\u001b[0m Trial 3 finished with value: 0.765 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.05782116611974807, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:06,168]\u001b[0m Trial 4 finished with value: 0.76 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.058078822153104344, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6511003297468326}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:11,186]\u001b[0m Trial 5 finished with value: 0.74 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.06736771581939403, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4884412631667159}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:27,170]\u001b[0m Trial 6 finished with value: 0.74 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08999735938996024, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.3791279775186878}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:28,288]\u001b[0m Trial 7 finished with value: 0.755 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.033785027593542606, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.11182914588272386}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:29,876]\u001b[0m Trial 8 finished with value: 0.735 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0486685101395772, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.9292853080973913}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:32,017]\u001b[0m Trial 9 finished with value: 0.745 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.021653851947564598, 'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:33,124]\u001b[0m Trial 10 finished with value: 0.74 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07289234904990605, 'depth': 1, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:35,768]\u001b[0m Trial 11 finished with value: 0.765 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.04982198834314353, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9777247872686714}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:38,327]\u001b[0m Trial 12 finished with value: 0.76 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0460697977489378, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:40,700]\u001b[0m Trial 13 finished with value: 0.735 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.03843637383767501, 'depth': 3, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:42,009]\u001b[0m Trial 14 finished with value: 0.745 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.06188132909121481, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9994874185764296}. Best is trial 3 with value: 0.765.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:45,908]\u001b[0m Trial 15 finished with value: 0.795 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07509706857694579, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9620112343502487}. Best is trial 15 with value: 0.795.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:49,960]\u001b[0m Trial 16 finished with value: 0.8 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07818143410430801, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 16 with value: 0.8.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:55,282]\u001b[0m Trial 17 finished with value: 0.78 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07773551734198572, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7563976884959073}. Best is trial 16 with value: 0.8.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:29:59,331]\u001b[0m Trial 18 finished with value: 0.81 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08107661779506699, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 18 with value: 0.81.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:30:03,643]\u001b[0m Trial 19 finished with value: 0.81 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08558099886571385, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 18 with value: 0.81.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:30:12,269]\u001b[0m Trial 20 finished with value: 0.805 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09358513989483741, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 18 with value: 0.81.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:30:22,092]\u001b[0m Trial 21 finished with value: 0.805 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0999356260822527, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 18 with value: 0.81.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:31:02,007]\u001b[0m Trial 22 finished with value: 0.815 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.084938954049946, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.815.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:31:38,382]\u001b[0m Trial 23 finished with value: 0.78 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08411484605297369, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.815.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:31:48,671]\u001b[0m Trial 24 finished with value: 0.77 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06733220705121347, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.815.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:31:52,483]\u001b[0m Trial 25 finished with value: 0.795 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08342364914259912, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.815.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:31:55,125]\u001b[0m Trial 26 finished with value: 0.79 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09303473876821719, 'depth': 3, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.815.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:07,497]\u001b[0m Trial 27 finished with value: 0.785 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06712884580347896, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.09349590194725721}. Best is trial 22 with value: 0.815.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:14,731]\u001b[0m Trial 28 finished with value: 0.8 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08189789220380778, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.815.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:19,236]\u001b[0m Trial 29 finished with value: 0.825 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09177448168808457, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:25,331]\u001b[0m Trial 30 finished with value: 0.81 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09555750884479014, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:31,357]\u001b[0m Trial 31 finished with value: 0.81 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09542162451439881, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:35,438]\u001b[0m Trial 32 finished with value: 0.805 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09091232147916774, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:39,749]\u001b[0m Trial 33 finished with value: 0.81 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08856417927991414, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:45,955]\u001b[0m Trial 34 finished with value: 0.755 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08900247210013253, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 8.990081525835045}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:55,701]\u001b[0m Trial 35 finished with value: 0.795 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0992543172605176, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:32:58,375]\u001b[0m Trial 36 finished with value: 0.825 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0734337049818372, 'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:33:01,096]\u001b[0m Trial 37 finished with value: 0.79 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0704853899419256, 'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:33:03,183]\u001b[0m Trial 38 finished with value: 0.76 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07935003077972778, 'depth': 1, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.34714730787806}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:33:04,551]\u001b[0m Trial 39 finished with value: 0.805 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08717134527041769, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:33:06,974]\u001b[0m Trial 40 finished with value: 0.785 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07357336026110596, 'depth': 2, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:33:11,248]\u001b[0m Trial 41 finished with value: 0.795 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08747952286471809, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:33:15,429]\u001b[0m Trial 42 finished with value: 0.8 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09505828308964842, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:33:54,185]\u001b[0m Trial 43 finished with value: 0.81 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09681792652890395, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:33:57,502]\u001b[0m Trial 44 finished with value: 0.745 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06190788521873574, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:34:03,783]\u001b[0m Trial 45 finished with value: 0.825 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0952441566476203, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:34:18,434]\u001b[0m Trial 46 finished with value: 0.76 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09159346274826567, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.845485033178962}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:34:19,528]\u001b[0m Trial 47 finished with value: 0.72 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.021328499157624865, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:34:22,313]\u001b[0m Trial 48 finished with value: 0.78 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0809686206298549, 'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-24 16:34:25,367]\u001b[0m Trial 49 finished with value: 0.785 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08565883774264897, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.15894762494964565}. Best is trial 29 with value: 0.825.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is  0.785\n",
            "Number of finished trials: 50\n",
            "Best trial:\n",
            "  Value: 0.825\n",
            "  Params: \n",
            "    objective: CrossEntropy\n",
            "    colsample_bylevel: 0.09177448168808457\n",
            "    depth: 7\n",
            "    boosting_type: Ordered\n",
            "    bootstrap_type: MVS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " ### Checking the Skewness of the data\n",
        "\n",
        "print(data.skew())"
      ],
      "metadata": {
        "id": "900FQDVc9nkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15612e48-9339-4d56-90cf-c2546af243a2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "months_as_customer             0.362177\n",
            "age                            0.478988\n",
            "policy_state                  -0.378280\n",
            "policy_csl                    -0.874183\n",
            "policy_deductable              0.477887\n",
            "policy_annual_premium          0.004402\n",
            "umbrella_limit                 1.806712\n",
            "insured_zip                    0.816554\n",
            "insured_sex                    0.148630\n",
            "insured_education_level        0.042350\n",
            "insured_occupation             0.319316\n",
            "insured_hobbies                2.374582\n",
            "insured_relationship           0.003942\n",
            "capital-gains                  0.478850\n",
            "capital-loss                  -0.391472\n",
            "incident_type                 -1.626495\n",
            "collision_type                 0.632780\n",
            "incident_severity             -0.077502\n",
            "authorities_contacted         -1.330950\n",
            "incident_state                 0.818479\n",
            "incident_city                  0.730218\n",
            "incident_hour_of_the_day      -0.035584\n",
            "number_of_vehicles_involved    0.502664\n",
            "property_damage                0.863806\n",
            "bodily_injuries                0.014777\n",
            "witnesses                      0.019636\n",
            "police_report_available        0.802728\n",
            "total_claim_amount            -0.594582\n",
            "injury_claim                   0.264811\n",
            "property_claim                 0.378169\n",
            "vehicle_claim                 -0.621098\n",
            "auto_make                     -0.054778\n",
            "auto_year                     -0.048289\n",
            "fraud_reported                 1.175051\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(abs(data.skew()) > 1) "
      ],
      "metadata": {
        "id": "N6cDJ1EV9nnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670623ff-401e-4042-d530-0a73e826214e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "months_as_customer             False\n",
            "age                            False\n",
            "policy_state                   False\n",
            "policy_csl                     False\n",
            "policy_deductable              False\n",
            "policy_annual_premium          False\n",
            "umbrella_limit                  True\n",
            "insured_zip                    False\n",
            "insured_sex                    False\n",
            "insured_education_level        False\n",
            "insured_occupation             False\n",
            "insured_hobbies                 True\n",
            "insured_relationship           False\n",
            "capital-gains                  False\n",
            "capital-loss                   False\n",
            "incident_type                   True\n",
            "collision_type                 False\n",
            "incident_severity              False\n",
            "authorities_contacted           True\n",
            "incident_state                 False\n",
            "incident_city                  False\n",
            "incident_hour_of_the_day       False\n",
            "number_of_vehicles_involved    False\n",
            "property_damage                False\n",
            "bodily_injuries                False\n",
            "witnesses                      False\n",
            "police_report_available        False\n",
            "total_claim_amount             False\n",
            "injury_claim                   False\n",
            "property_claim                 False\n",
            "vehicle_claim                  False\n",
            "auto_make                      False\n",
            "auto_year                      False\n",
            "fraud_reported                  True\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "umbrella_limit ,insured_hobbies ,incident_type,authorities_contacted,fraud_reported  all are skewed , lets check if we can update the distributions or not"
      ],
      "metadata": {
        "id": "xZBZzL3_zEXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Looks like most of the people have availed Umbrella limit\n",
        "\n",
        "data.hist('umbrella_limit')"
      ],
      "metadata": {
        "id": "Jr1q6GkC9nqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "cdb19cf7-2d84-4f4e-8dee-ce1fea7e8d36"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff222559ed0>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['insured_hobbies'].value_counts,data.hist('insured_hobbies')"
      ],
      "metadata": {
        "id": "13-O9xHi9ntW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "9a2f69f8-6767-49d7-981a-d9473481e893"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<bound method IndexOpsMixin.value_counts of 0      0.20\n",
              " 1      0.27\n",
              " 2      0.29\n",
              " 3      0.29\n",
              " 4      0.29\n",
              "        ... \n",
              " 995    0.23\n",
              " 996    0.20\n",
              " 997    0.16\n",
              " 998    0.27\n",
              " 999    0.09\n",
              " Name: insured_hobbies, Length: 1000, dtype: float64>,\n",
              " array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff221c553d0>]],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### The target column is not balanced that's why it didnt perform well in other models except in Balanced random classifier\n",
        "\n",
        "data.hist('fraud_reported')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "veDJEzeS1i1w",
        "outputId": "71ba1096-1133-45b8-ef79-d139947964cd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2217753d0>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.hist('authorities_contacted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "wfUOzgSU1jCf",
        "outputId": "b9dd858a-031c-4e88-9559-0ede148ea789"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff221741190>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data['months_as_customer'],data['age'], hue=data['fraud_reported'] )\n",
        "\"\"\"\n",
        "from the graph it can be concluded that most of the fraud cases are done by the customers new \n",
        "to the company and that too comparatively younger ones. \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CKQB8V0K9nwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "925f7480-7c0d-463d-9c32-f7e84f95a76f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom the graph it can be concluded that most of the fraud cases are done by the customers new \\nto the company and that too comparatively younger ones. \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAE+CAYAAADicfmoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hcxfW/37u9r3rvzZK75YZxAVNsbIMxvZgWCCWBJD9CIPAlhXQSUoEAgQAJhN5DAIMpBgzGDXfZkiyrd63K9n5/f6y88nplwMZyEfM+D8/qzp2ZO3uRPp6ZM+ccSZZlBAKBQPDVURztAQgEAsHxhhBOgUAgOEiEcAoEAsFBIoRTIBAIDhIhnAKBQHCQCOEUCASCg0R1tAfwVUhJSZELCgqO9jAEAsEoY+PGjT2yLKcebLvjQjgLCgrYsGHD0R6GQCAYZUiS1Hgo7cRSXSAQCA4SIZwCgUBwkAjhFAgEgoPkuNjjHI5AIEBLSwter/doD+W4RafTkZOTg1qtPtpDEQiOK45b4WxpacFsNlNQUIAkSUd7OMcdsixjs9loaWmhsLDwaA9HIDiuOG6X6l6vl+TkZCGah4gkSSQnJ4sZu0BwCBy3wgkI0fyaiPcnEBwax+1SXSAQfDPxB0PUdbvodvjIsupQKiWaez0kGzWUpJnQqpUjPobjesa5P/feey8VFRUsX778sPa7atUqzjzzzMPa56HQ39/PAw88cNDt7rrrLv74xz+OwIgEgiOLPxjiuQ3NLLn3Y654bB2L713N29s7uOWFLZx5/2r+vaYBjz844uMYVcL5wAMPsHLlSp566qloWTA48i9xX0bqecFg8JCFUyAYLezucvHz13YQHkxc4Q+F+fsHdZwzJRtZht++uYvaTueIj2PUCOcNN9zAnj17WLRoEVarlcsvv5zZs2dz+eWX09DQwNy5c6msrKSyspJPP/0UiJ9J3nTTTfzrX/8CYMWKFZSXl1NZWcnLL7/8hc++6667Yp7X3d3Neeedx/Tp05k+fTqffPJJTL1Zs2ZRWlrKI488AkQs3Lfeeivjx49nwoQJPPfcc9HxzZ07l6VLlzJ27Fhuv/126urqmDx5MrfeeisA99xzD9OnT2fixIn8/Oc/j47pN7/5DWVlZcyZM4fq6urD85IFgqNMt8MbFc29OHxB1MohKeuwj7zBc9TscT700EOsWLGCDz74gPvvv5/XX3+d1atXo9frcbvdrFy5Ep1OR21tLZdccskX+r57vV6uvfZa3n//fUpKSrjooou+9PlVVVXR51166aXcfPPNzJkzh6amJhYuXMjOnTsB2Lp1K5999hkul4spU6awZMkS1qxZw+bNm9myZQs9PT1Mnz6defPmAfD555+zfft2CgsLaWhoYPv27WzevBmAd955h9raWtatW4csyyxdupSPPvoIo9HIs88+y+bNmwkGg1RWVjJ16tTD8JYFgqNLZoIetVIiEBpSz2SjJro8V0iQk6gf8XGMGuHcn6VLl6LXR15gIBDgpptuYvPmzSiVSmpqar6w7a5duygsLKS0tBSAyy67jIcffvgrP+/dd9+lqqoqes9ut+N0RpYPZ599Nnq9Hr1ez/z581m3bh2rV6/mkksuQalUkp6ezkknncT69euxWCzMmDHjgOcs33nnHd555x2mTJkCgNPppLa2FofDwTnnnIPBYIiOTSA43vEFQhQmG/nrRZO57cWtuPwhEg1qbj69jA2726jINPPtOUWUpJlHfCyjVjiNRmP057/85S+kp6ezZcsWwuEwOp0OAJVKRTgcjtb7Omca931eOBzms88+iz5nX/Y/AvRlR4L27Xd/ZFnmjjvu4Prrr48p/+tf//pVhiwQHBd02r28u7OT59Y3U5Zu5opZ+bz1g7n0OP2ka/2k17/CZa5nCJXMRJFzFZIqZ8THNGr2OL+IgYEBMjMzUSgUPPnkk4RCIQDy8/OpqqrC5/PR39/Pe++9B0B5eTkNDQ3U1dUB8MwzzxzU8xYsWMB9990Xvd67tAZ47bXX8Hq92Gw2Vq1axfTp05k7dy7PPfccoVCI7u5uPvroI2bMmBHXr9lsxuFwRK8XLlzIY489Fp3Ntra20tXVxbx583j11VfxeDw4HA5ef/31gxq/QHCsEA7LPL22iTtf2c7WlgFe3NjC8kfW4g+FqczUkr36DlRv/xjaN6Nc/w+kp86H/uYRH9eonXHuy3e/+13OO+88nnjiCc4444zoLC43N5cLL7yQ8ePHU1hYGF3y6nQ6Hn74YZYsWYLBYGDu3LkxgvVl3Hvvvdx4441MnDiRYDDIvHnzeOihhwCYOHEi8+fPp6enh5/+9KdkZWVxzjnnsGbNGiZNmoQkSfzhD38gIyODXbt2xfSbnJzM7NmzGT9+PIsWLeKee+5h586dzJo1CwCTycR//vMfKisrueiii5g0aRJpaWlMnz79cLxGgeCI0z7g4R8f1cWUOXxBdrbbKZEHYPtLsQ3srdC9CxJyR3RckizLX17rKDNt2jR5f2POzp07qaioOEojOjTuuusuTCYTP/rRj472UKIcj+9R8M2hvd/Dwr9+hN0be8zvweWVLMqww4OzIByKbXT5q1A8/yv1L0nSRlmWpx3suL4RS3WBQHB8kpmg54cLymLK0i1axmZaILEQZtwQ2yBjAqSN/ETgG7FUP1w8/vjj/O1vf4spmz17Nn//+9+/Uvu77rprBEYlEIwyHB109/ZT61DjlbRMyknggeWVrKruIjfRwNT8RMKyDCoNzP4BZE+F3e9C1mQoOQ3MGSM+RLFU/4Yj3qPgmKK7hoadG/je5+ls64iccilJM3LdvGJsTh+PfFxPr8uPQaPk0SunMas45Ws9TizVBQLB8c/O13nXnhMVTYi4WdZ1Ofn3p430uvwAuP0hfvzSVnqcvqMyTCGcAoHg2CAUgt461nXFy9LnTX3kJxtiypp6PQy4A0dqdDEI4RQIBMcGSiVkTOSU7FDcrTklKdR0xh4JHJ9lIcWkOVKji0EI5zHEihUrGDNmDCUlJdx9991HezgCwcggy+BzRj6BXqcPly8QOVZUehrzTG2cM3bIbfL0ilTGZZn54Wml6NQRycpL0vO7cyeg1yixe/yE94/8McIIq/oxQigU4sYbb2TlypXk5OQwffr0aFQkgWDU0FMDm56C3Supnv9P3mxS8s7OTkrTzCyvTGHmmptJOuEHXJRazKQSP7IMySYN1S3dLEjr583LsrFr0slIslDf4+LXb+xkXX0v0wuTuHRGLhWZ1iPyNYRwHiKvbmrlnreraev3kJWg59aFY1g2JfuQ+1u3bh0lJSUUFRUBcPHFF/Paa68J4RSMHpzd8OI10LEV94Qr+McWHy9vagNgZ7uDj2q7eXLZXQx093PZG5tjmt6+qJwr3+zk+cr3mGzVsFG6hD++U8PGxj4AdnU4WF3bzbPXzSLdEh8j4nAjluqHwKubWrnj5W209nuQgdZ+D3e8vI1XN7Uecp+tra3k5g65ieXk5NDaeuj9CQTHHLbd0LEVgNrSq3ltS3vM7X53gN3eBF5u0MY1/WR3DxkJBnary6D6TWq6HFHR3Et9j5u6rpEPYgxCOA+Je96uxhOI3cD2BELc87YIGCwQHBDlkCFHJQdRKeIjgykVYFLHN9WrlfiCYVSEQVKiUQ4vXeoDlB9uhHAeAm39noMq/ypkZ2fT3DwU1aWlpYXs7ENf+gsExxzJJVAeybgwZvPvuHp2fszt/GQD5VIzy3KcqJVDoqpUSMwoTEIR9lPmXAeVV1CWbmbR+FgPoVlFSZSkmUb+ezDCe5ySJCUA/wTGAzJwNVANPAcUAA3AhbIs9x2gi2OSrAQ9rcOIZFbCoUeenj59OrW1tdTX15Odnc2zzz7L008//XWGKRAcUdr7PezudmJQwjhtJzpnC5jSIHUMLkc/u7vd2Mp+Ss60X1DiWM+l5jDFqRP5dI+N4hQjc3I1lNbcR0f5Fdx3UTIDvhCSBCpJAp+T++fJpFnmQ+4MxqmNXDeviBmFSYTCYVJMOlQKiU67l0TjyB9RGmnj0N+AFbIsny9JkgYwAP8HvCfL8t2SJN0O3A78eITHcVi5deEY7nh5W8xyXa9WcuvCMYfcp0ql4v7772fhwoWEQiGuvvpqxo0bdziGKxCMOLWdDq59YgMOb5DnT+5Ft+pGCEUOp4dPup23pFP50YpuADRKBQ+eO4lTUyzkluRw/rTcyPGkdQ+zO+FErn2pi/reyOprXKaFvy+vpCAlFxhyDVYAU/ISMWmV/Oy1HazZ0wtAiknDA8srmVGYPKLfd8SW6pIkWYF5wKMAsiz7ZVnuB84G/j1Y7d/AspEaw0ixbEo2vzt3AtkJeiQgOyFypuzrWNUBFi9eTE1NDXV1ddx5552HZ7ACwRHglU2tNNjcfHeKluJPfxwVTQDFh3eTKvdGr/2hMLe92UpbZ+dQB107YePjvNKZRn3vkBvljnY77+3qOuBz1zX0RUUToMfp55GP90TOhY4gIznjLAS6gcclSZoEbAR+AKTLsrzXnNYBpA/XWJKk64DrAPLy8kZwmIfGsinZX1soBYLRQCAU5rM9NgCytG7wxO+8WUO9wNAZS5vLT7/HT9beAmcHwYRi1nTEG4w+b+zjmjnD592q73bFle1otdPr8mPUDmNlOkyMpHFIBVQCD8qyPAVwEVmWR5EjoZmGPfIvy/LDsixPk2V5Wmpq6ggOUyAQfB3USgWLJ2QCUOUwErbGGn1QKOlSxM6PCpL1pJv3OW+ZWICqeztL8sPsz/zytAM+e3x2/IH3eWWppFtGNtPlSApnC9Aiy/LawesXiQhppyRJmQCDnweehwsEguOCheMzWDwhg39ucrF15h/BOpgwTWshfPZDKI1JmLSRBW52gp6/LMkmOT1rqIOUMXDG3SxUfc7iMRF3S0mCi6bnMKckBbwOCAX3fyxT8xP41uyC6NGmqfmJXDozD41qZA8MjWg8TkmSPga+LctytSRJdwF7Uzba9jEOJcmyfNsX9SPicY4c4j0KDhduf5BGmxtJAkvARlvzHjr8emyaTObkavF6PbgDYNUrsVgTyUgaxj2yt4EBH2yx66nrcbOr3c78fDVzG/+OUfLDrBsjAYv3weMLsrPTgS8YoiTVRKr5q3sOHWo8zpG2qn8PeGrQor4H+BaRWe7zkiRdAzQCF47wGAQCwRHAoFFRkWnh88Y+lvxjJ6GwDHi5fl4iF763G9tgLE2AJRMy+OMFk9FrlLGdJBWwtbabKx5fFy16bgM8uugCTv3wPKh9B779HqSURO/rtSoq8xJH+uvFMKLzWVmWNw/uU06UZXmZLMt9sizbZFk+VZblUlmWT5PlfcxtAoHguGdtvW1QNCPo1MoY0QR4Y1sHzX3uYdu//Hm8q/GTtWrkrErw9keyWB5lhOfQMcTVV19NWloa48ePP9pDEQgOmf1nkVK8oRy1UhrW5RLAqou3hidoQQoOOp0oR85a/lURwnkMcdVVV7FixYqjPQyB4GsxszAZi25oF7BjwMvYLEtMnRtOKiYvybB/UwDOnpIV44uuUkgsL3RDxzZIrYD0oz+xEGHlDpWtz8N7v4SBlogF8dSfwcSvt107b948GhoaDs/4BIKvg7svsiT2DkByCUGlFl97Ff4QBJLGYE3LRatWDtu0ItPCc9fP4v2dXXQ7vUzNS+Tiadk09EZmjMkGNXnJRlQHCMgxOTeBF26YxYc13QRDIU7OUzOp/UUCi/5Md+oJNNt0lAU7SezbDpICUsvBkjlir2I4hHAeClufh9e/D4HBpcNAc+QavrZ4CgRHHWc3vHMnbH0OgPCie1B8ej/GgUaMgD9lLC2n/YO80vEHFL+KTAsVmZFZ5rZmG1c8vpG+wfxA0/ITmVeazDmVOeQmGePaSpLEpNwEJuUmRMt2mG/gW/9aT5ejAWjgjFITv0x4m7Rt/4C0sXDRk5EgIkcIsVQ/FN775ZBo7iXgiZQLBMc77VuiokliAeGe3SgGGqO3NT1VaOtX0tgb77WzP75AiPver4uKJsCGxj7CSKyp7fyClkM4vQHuer2KLseQK+aKWifbkhZELrqqoPrIbnGJGeehMNBycOUCwfGEcx9BSyxE1b4xrkpi72bqfPFJ1fbH4QuypdUeV25z+vH5/MO0GKYPb5CqtoG48nafNrJUl8PQvG6YliOHmHEeCnu9Ir5quUBwPJG0j194x1aCxQviqnRmnkyi4cvDtyUaNJwxNt5lOt2iY2JOwjAthhmOScNpY+NDWhTpnBHRBBhzxlfq63AhhPNQOPVnoN7PF1atj5R/DS655BJmzZpFdXU1OTk5PProo1+rP4HgUPCmTKLnmnV0L3wQtBZUGgPBiZfiKj8Pd9nZuCqvQ1syn5z9rOKBUJgBd2zGSaVC4qoTC5lTkgREQsrdclox09JlTiiOhH4b8PhxOwdwuePPdcp+F2Gvk5tOKeHi6ZHUMlqVgjtPyWBi05O4y5bhOuNvUDR/pF7HsIil+qGw1wB0mK3qzzzzzGEYnEBwaARCYba29tNt9/GvT3vpdmRzXuULLChOYafRxYMf1qNRSVxUnMsnq3s4taKVU8pTseo17Gq389gn9ayr72XBuHQunpFHUUokGrvdF2ZGYQpLJ+UwP7mXxO0PoXrvQ0JFp1BbeDE3rHAxJlnFdROUZBnDyFmVpOsV+HevoqOnm1f7i3ml2kd5holnrzuBdIuWNL3EJ3V388BHTQR7ZL5jgJPKgph0R0bSRtRX/XAhfNVHDvEeBXvZ0NBLh93L/3t2M8HBWaNGqeCupWP5v1e2x9S9Y1E5d6/Yxb0XT2FafiLnPfQpbf3e6P2ZhUk8csU0uhxelv39U5y+IDdOt3Bz2y2obEO5uQKp47kn/W4e3mDHolPx6rx2AikVlJj8BN/7DT/R38kL24f2SC06Fa/eOJvmPg9XPha7r/nIFVM5fWxsOo0v41B91cVSXSAQALCxoZfmXndUNAGm5CXw2ua2uLpbWvopTjXx2Cf11HQ6YkQTYG19L429Lmo7nTh9kahGJyT0x4gmgLp7O7MTI4YfuzdITTgLnbOZcPWbtBaez0s7Yg1Ldm+Qmk4HL38eb4h96rMmjtREUAinQCAAwKBRxmWJ9ARCwy5/jRoV3kCIBL0a3TAH4RVSJE7nvuHdgtLwrpL7lmsVYYIoQZeIKuxBq4rvW6tSkjxMXqFEowZpOP/OEeC4Fs7jYZvhWEa8P8G+zChKJjNBR4ppSJS2tgxw4bTcGL9yrUpBSZqJtn4P180rpjTdzLzSlJi+rjyxgMIUIxWZFsrSI3udLzbocZScHVPPXnY+z+2J5FGvSNVSFtpNOLkU5ZgF5NY+w80nxGatLM8wUZ5hZunkbLT7iLJaKbF85pHLFHHc7nHW19djNptJTk4+Yv/KjCZkWcZms+FwOCgsHD4tgWAUIsvQUw22OtAnQupYMAwdC6ppt9Pp9LG5qZ9et59ZRcmckKunrnOA1XsGUKlUTM5LxheGLruXTKueyXkJ2J1u1u3pZmeHk8pcK5WFqfR6wzTZ3CQaNdR2OmjqcXJhSYi8gQ0oenYRzJpGs3kyz1d5KDTLVKYEsBj0mLLLMWlV+Fs2Y+9qYnOwgHWdkJ9qYU5pKvnJRmRZZlvrAJ/sthEKh5lTksLEnAQUBwgcciAOdY/zuBXOQCBAS0sLXq/3AK0EX4ZOpyMnJwe1+uhHmxEcIeo/gqcugODg383Ei2Hhb8CYMnx9vxs+ewDe/xUYkkFjYuW8F/nuS7sJhCLacdnMPG7N3431jesi/Ti78Sy+l4Xvp9PUG3nONbMLOHtyFt97ZhOhcCRfjkGj5I8XTGRS7pGNpbkvx2og4xFDrVaLmZJAcDC4bPC/m4dEE2DrszDxIig5Zfg2PdUR0QRw2+isuJI732qKiibAf9Y2cVaCkpkhP9gjhiT9Oz/iO5VPc8eqSJ2VO7sIhmUae2Ndld/f1X1UhfNQOa73OAUCwUHgs4Ntd3y56wvSfrl6Yi4H9LkxPuN76Qnu5xDid5GqHPJlz0nUs6013m2yqi3eHfN4QAinQPBNwZQGRcPMLJOKDtwmIQ9UQzl80m3rmZgZ6zEkSZCv2U8ALVlUuYdicO7ssA/rNjm39ABbBMc4x+1SXSAQxOPxh/AHQ1gH/cj7nR68fj+pOgmlQoJFv4VXv4dXk4DXWkRC8UzImDBsX16PB4ciheTLX0Hx/BXgd6IwJHL3srHc/noNW1vsWPQqfrF0HGXWRjCmgqsbEgtwn/kQH7wdCQISqTOeMekmdrU7aO51c8b4DFJMGqbkfTV/9WON49Y4JBAIhgiFZdbV2/jbe7V0DHi5anYBJalGnlrbxLZWOwuKdFyW3UFhoo6Nmqn87YN6Gns9XDIjl2VTssm0Di215XCYDbUt3PthE439AS6elMRp5Sls6/Ty6JpWwmG4bl4BBaYwiY5dFEqdUHYGhIPg6QVTOpjS6HP76RjwYtKqyB30a9/VNsD6xj6eXtc02E8RC8amY9YfHQPlN86qLhAIhtjS3M+5D34aTZJ2zZxCXt/SFrMfOSPXyE9mqrjgVQe+YDhafsNJRdy2sDx6lKeqvoVzHt0WU+eaE/NYVWujrnto3/LhM4ws+Oi8iGCe9guY8/++cIzdDi//3dLGr/63M6b8geWVLJ5wZCO470W4XAoE32C2tgzEZJY0apVxRpx1zS6qvMkxggjw+CcNdNiHLO27Ohxxdf6zroVTK2L3KJ/erYlkngT47O+xcTyHodPu5bM98Ultn1135FwlDxdCOAWCUYBhv8ySSkX8n7ZSITFc8CCLTo1KOXRwXKeOb2vRqXEP+pzvJVUPkt8ZudBaQfHF8TlVCgXmYQaQbNIed04sQjgFglHAlLwEUs3a6HVNh4M5JbEW62sqzUwObiMvKfbo0P8tLifNPGQ5n5BtJT9RG1PnltOKWVk1NKPUKBVcUuCIpK0AOO0uMHzxecycRD1zSlJiXCU1SgWXHkFXycOF2OMUCI4z9nQ7qetyYtAomZLgwtBfA7JMv6mYt5rVdDv9zChMRKeE3Z126nucTE6RqNQ0Y05KZ0uogO1tdmyuiEvl5NwEjNrYmWBdSxvr6vvosPuYnmch06Khxq6iptOJUiExPstMQrifEvcWTCnZkD01Gty7Y8BDo81Nl8NHKCyTaFATDMuMyTChUSnZ0Wpnc3M/CgXMLk5han7iUZtxCuOQQPANYHNzH5f9cx1OX5D7TzeyeNv3UfQPJlKz5sLyFyBtML5qZxU8dSGEvBAKICcW8smk33HZq71oVQpSzVruvXgKlfkHmCl67bD+n/DeLyLX+kScix/grBV66m2RaO03nFTETfNLoxGUGnpc/HdLK2/v6GTH4OF2i07FD04rZU2djZ+eOZb85PjMlkcLYRwSCEY5Hn+Iv75bi9MXJM2sZbr74yHRhEia6m0vDl1v+g/YmyNnK739SO2bKOxbTaJBjS8YpqXPwx9W7MK1395llK6qIdEE8PRhevO7LK8Y2k996MM91HY5otef1HUTCMlR0YRIDM2ParrpdwfYPoz30PGIEE6B4DjB6QtGBSnTqiOxb0t8pea1kc9QAJo/i7ud2LeDdMvQfubODgdO7wGE09UdX+bpI0Mba623OYeuG3rc9DjjXTLrul3kJhnocX61zJbHOkI4BYLjhCSjhrMmRs471nQ6actaGF9pwvmRT6V62BxYbRknU98zdBbzzImZJJkOYA1PKgJF7N5nKLWCjb1DxiW1UiJvn6V3ZV4i2QmxLpkAc0pS2NjYR2HKsbNM/zoIl0uB4BhlwO1HkiSMWhX9bj8mnYorZhXQ3OthfWMvOwxTyZr+HTQbHwFkmHo1lOyTyrf8TMKdVSg2PQkKJeGZ38WWOpOcxE4m5yaQatFyyfRcnL4gKjmEWXaALhFUES8et7UUz2XvkfzOTdCxDTltHJ7F97HuvxHhTTVpufu8CRSnmvAFQjh9QWYUJhEKh7nnvAns7nbSafcjI5Nq1nLNnEIm5x6fLpb7I4xDAsExxoA7wDtVHTy4qg61UuLyWQW8v7MTjVrJTfNLSDVpeGt7B49/2sDUHCO3ztCTZtaiTCoAVWT22OvysWJ7B2tq2jm3MMiYTCs9qgw2NDtoH/DyxtZ2ClKMXHliAQ99WIcvEOSHU9XM9X2EZuJ5rHcm8eeVNTT3eriwMpM5OSo+qOnBrbRwyYw8QrKMVacmM0HP1pZ+7ntvNzvaBrhjcQWf7O5hVXU3E7KtzC1LIRiSmVmYxLhs69F9scMgrOoCwSjhf1vbuOnpTTFlty8q5/crdpFo0PCnCybxrX+tj7n/3HUnMLMoOXr9/Ppmbntpa0yd3583gU/rbDHJ17QqBd+dX8JfVtYA8OwSNRZlkGVvSPhDQ95DF0zNYVNzP7u7nEzNT+Sxq6Zh1Wto6HGx9O+rsXuCnD05i5pOBzvbh4xFmVYdZ4zPoDDFyBWzCr72uzncCKu6QDAKCIbCPLmmIa58a0s/RSkmel1+dnXEx7D8qGbIkOPyBXnsk/q4OkpJwRtb22PKfMEwofCQQH7Ypafaa40RTYD/bmnj1PI0ADY29tE0eBxpd5cTuydiXMpPNsSIJkD7gBezTsVjq+sZcI8OwxAI4RQIjikUkkTaPlbvvVh06uixoeGySibuk/VRpZBIMWnj6kiSPKzLo3Kfw+fJWtBJgbg6Vr06muZXqZDQDo5h37FISAx3jl0pSaSYNKhVo0duRs83EQhGAQqFxJWzClDv4ztu1CgpSDbSYfcytzSFidnWSGzNQax6NXP2CQisVSu5cX5JXB2XLxS3XC5KMdLviQilRa9ijqmV8RYfhSmxlvHLTsjnf4Oz1WvnFlKQHLk/JsPMCUVJAHxY0805U7Jj2p1Ulsr21gF+cFoZBs3osUWLPU6B4BhjbwbH9Q29KCWJklQDVS29ZJmVTM0xkpqWybbWATY09mJQq5hWkMSYDHNMH6GwzNaWftbusaFSKqjItGDVqWi0uQiEIx4+uUl6ClKMbGqwoVMEmZ7gYoy2B7IqafQaWd/YR6fdy8RsK8GwzLbWfsZlWZmSl0CSXo2ts4ld3X76/RKpCSa2tXsYl2VhwBtkR9sAWVY9Rq2S7FUpaI8AACAASURBVAQDE3KscTnbjwWEcUggGI30NsILV0J/QyRnkNoIV7wG2ZVf2nRnu50bntxAp8OHNxAmP9nA41dOpyjN9KVtv4yu+u3837s9vFsXOZqkUSr415VTOLEs42v3fSQRxiGBYDTSuBraN4GnD8KhiHiu/isE471z9uf5Dc009nrwBiKGnkabm3d3fXHMzK+Eq4ftzbaoaAL4Q2F+/r9q+kaRAeiLEMIpEBzL9O6JL+vYAn5XfPk+BEJhNjf1x5UfFl9xv5PeYXS7rtt5YL/3UYYQToHgWCZvZnzZhItA/8WxL9VKBedUZseVnz72MCyljWkUJsQbes4Yl0bqMNb80cjoMXMJBKORnBlw+q8JNa3FW7qEkDkLf+IYkoH9T/547L3IQT8GowkCbs4Yl05rn4eQq5eQDInJqcwqTo5t4w/h9AVIMmpxeCPW9QTDF0dyR2NgXEEWf16k465VPdg9QeYWJ3LL6WXRY0qjHSGcAsGxjD4BR+ECVLYmjKt+hi+pnKZxP+D5HQ7OnpxNdqIBv9dNoPZ9dJ8/irJiMfKWZ5HsLaRNvpwfF09FseJ2UKiQx/4fkjoTiMwKNzf38ZeVtexoG+C0inQKUyJZMb93SgkLx6Vj0R9YQHWphZw7M5WZpRm4wyqyUpIxDpeXY5QirOoCwTGMz+NEfvk6dLVvDBVqTLw64yl2+NK4fVEF7tqPMD+zFE75KXx4dySk3F4mXwqtn0P3rsj18peg9DTqe1wsvW81jn32JGcVJ6NVKlhV082Dl1WyaPzRyTx5JBFWdYFgFOLraYoVTQC/k1KplSfWNNLj9CI1ro6Uh3yxogmw/WUo2yf83I6XAajrcsaIJsCaOhsTcyOBOJ5d13RYv8doQwinQHAMI6k0oImPYemTtCQaNCglBegH9y0VwyyVDUng3ceSbs4CQK+J34vUqRUEgpEVaFaCPu6+YIgRFU5JkhokSdomSdJmSZI2DJYlSZK0UpKk2sHPLzYPCgTfYEzpRbjm/iSmzJs5g/f60vjJmRWkmLXIBbPBmBIRyKSi2A6mXws7Xo38rDXD2LMAGJNu5sT9DEXLZ+bz1vZ2tCoFF03PHbHvNBoY0T1OSZIagGmyLPfsU/YHoFeW5bslSbodSJRl+cdf1I/Y4xQcL2xv6WdXhwOFQmJspoXyTAs4OqFzB/gGIKUMUitgv7zn3Q4fO9vthGWZQChMj9NPhkVHWbqJJJWPYPMG1F3b8Bqz2aOtoEuRikWnoijVTIZVh6N5O7RsQGtOYkCyUu1NpF82UJRiwOV00OEMkpVooFzVidGaAikltPZ52NLcT3Ofm8IUI0atgtZ+Hxqlgok5VopSv76H0bHOoe5xHg0z2NnAyYM//xtYBXyhcAoExwPr63u57skN9Lkj+4w5iXr+cfFYxn10I9S9G6mkVEcMNEUnRdt12j3c9sJWFAoFOrWCt7Z3ACBJcPsZ5Swen0nu2NNh7OlUNfZx7RMbsLmaAZiYY+WB5ZUozMXctt1JZoKeboePVTXNjMuyMK0giX9/2hB91p2n5nBV4/dQL7mb7MxJZCdGluR7up1c8+8N0bQaVr2ap749k/HHYPDhY4GR3uOUgXckSdooSdJ1g2XpsizvDQrYAaSP8BgEghEnHA7z3IbmqGgCtPR5+LjWBu2fD1UMBeCt28DdFy3a3mrnw9oepuQlREUTQJbhgVV11AxmkXT7g/x5ZTU215Bb49aWAT5v6mdLcz+r62zkJhlYNRib8/Sx6XGxPX//QSt7Sq6Edf+MuHAO8mFNd0wuogFPgCfWNBAKH/unbo4GIz3jnCPLcqskSWnASkmSdu17U5ZlWZKkYf/PDArtdQB5eXkjPEyB4OvhDYTY3eWMK6/ucoMpHdy9Q4W23eB3giGyvd87KIT7Bw+GiIANDIZ9c/tC1HTGP6O1z4NZp4zrIxiW2V/3gmGZAYUF2jdHrPCKSHi42mH63d5qxx8Ko1d8Mw61HwwjOuOUZbl18LMLeAWYAXRKkpQJMPjZdYC2D8uyPE2W5WmpqakjOUyB4Gtj0KpZMC5+8TS/LDEilPsy7hwwpUUvi1IjVnO1QkKliPUHGptpITshEtg4yahh2ZR4N8qJOVaKB/cjdSole7vwBcJY9eqYuikmDTnunTDpElAPxdw8aUz839h5ldnovyGeQAfLiAmnJElGSZLMe38GFgDbgf8CVw5WuxJ4baTGIBCMBL5giE67F7cvQKPNRUOPk64BL/NKUrjihHzUSgmdWsF3Ty6msjAVzn4gciwIoGwxnPRjUGnpdfmwOX2My7LyxNXTCcsyP1lSQcZgBPhJOVbuWFxOhlVHl8OLNxhi+cw8lk3OQiGBWavi18vGMykngUk5Cdx97gTe3tHObQvLSTVpeW5DE3cuLqd4MChxWaqBh5ckkqXog7FLY77TjIIkfnzGGPRqJSqFxJWz8lk0YfQfgD9URsyqLklSEZFZJkS2BJ6WZfk3kiQlA88DeUAjcKEsy70H6AYQVnXBsUN1h4P7P6ilMi+RXR0O3t7RQVGKkatmF1LTYWdKXiLtA1667F66nT4WjsugMi8Bi78LAh6wZGMPqXhnRyd/fa8WgGvnFrGrfYCVO7v41uxCTq9Iw+4N0GX38fsV1QTDMudPzcEbCLF4QiblGWZa+z1oVApyEmMjtbf2eQiEQqiVCryBMBlmFV5HL30+Bcl6iUTJBdbcaArgfZFlmeY+D+GwTHaCflSlujgQIpCxQDDC2Jw+Ln7kM9LNOtRKiQ+qhxKkGTRK7j53Ao9/0sCm5qFwbgXJBn57znhOLBlaCr+9o4Prn9wY0/cPTy/jvvdrCYRkbj69FJNWxa/+tzOmzi0Lyvj3pw289J0TyU+OPxQvOHiEy6VAMMI02tzUdkbS4+4rmgBuf4gGm5vyzNgUFg02NzWdsbEzX97YEtf3uvpeJmQnALCxoY9P62xxddbu6SUvycie7i+OxSkYeYRwCgRfEb1GiSRFLOjGA7gs9rtjfcUlibjMknvPTu5LklHDgCdiXVcppGHjWu6tYxjm2YIjixBOgeArUpRq5Lq5RbyxrZ3vzi+OuTclN4GCZGOcVfzcKdlU7JdIbdmU7Bjh1auVjM+2UtftQiHBZbMKmFWcPGydohQjZemj36PnWEfscQoEwxAMhantctBp99Hn8pNq1tLS50EhSeQn6yMBgP0hep1eTknsJtHdgEdhxG4dw3a7geY+D2NTtczSNaDrq4n4kmdOgsQCGnqcNNnc1PW4UCsVlKUZcfmC9DgDKBVwSko/JnstPllNs6aITQMm8pMNdDv8FKUamZATWdLv6XZSPejeWZFpIS/J8CXfSrA/x5PLpUBwzPNxbTf1PW5+99ZOfnPOBK5/ciMuf8TTpiDZwA9PH8Pf3q3moTlucl68EkIBjIA550Ssix8geXIJfP4kvPS9iAsQQPmZtM75LWc/Ws2AJ4BKIZGdoOO2M8p5dHU9nzf188JZWhKeuhL8TlRAcWIJW8v/xPfeCXDNnELueGUbT317JhqVguX/XBvdGsi06nji6hmUppuH/0KCw4oQToFgP7odXt7d2RU12LyzoyMqmhAx+OzqsHPTSfkUrl0eEwNT2/Ipns4toPLCuz8bEk2AXf8jUHwZA56Id08wLNPY62Fnu4MGm5sZeSbG1T8c8SoaRN23mxOkHXgCxdTbXCQZNby8sQVZImY/tX0gMmYhnEcGsccpEOyH2xfCoFHR1Osm06ob1ord7fBh1ipR9cdnoVR6esFrj3WzHCTs6Ysra+hxkWrSkm9RYuivjrtvdDaSoFfT0uchw6LD6Q+yo9UeV6+6I75MMDII4RQI9iPNoiMUDnNaRRobGns5Y3x8ZsjSdBPbOtwMlC6LuxdMKoXEAsjeb+tMoUKdUhRXf1ZxMnXdTj5s9NJReH7c/fak6bTbvUzNT2RHm53yDAvnT8uJq7dg3GHIYCn4SgjhFHyjsXsCdAx4Ce4THMPjD3Lx9FwumZHHlNwEQuEwF0/LRaWQMGtVfO+UEkrSTNi9YVrG3kCg4uzIuSNjCo4l/0CdMxnM6fiW3Ev7affjKjkLEvIInf9vdJljuX5eERqlAr1ayW0LysixqrllQRlhWebl4Am4Jl0NCjWesqXsPucN3nWXcsmMPFr73JxTmc2SiZmcVpHG9ScVkW7WsnxmHn+/ZArjsiy4vN+MvOZHG2FVF3wjkWWZtfW9/OaNKhp63CybksW3ZhewuXmAP71Tgz8Y5uIZuSglyErUMzbDjNMXwhsIEwyH+eXrO/EEQvzi7HH0Ddgx+bvwyGry0pKYka2jzp/Afe/Vsqqmh3FZZr51Qi7PbGjmukoLkkJibZea+flqxu9+GFXnVoIzb6SnsxkvOhIsJpoTZvCXD1tY2zDArMIEbj4lH5PJQpZ1yBWyr6OBN2q93P9xKzIyF0zNwRcIs3hiJlPyRGKFr4JwuRQIDoKd7XbOvv+TaBg2SYJfnT2en7y6PabeTaeU8PjqevyhMN8/tRSlJPGHtyP7kCVpJiblWHnp89ZofYUE/72ymDvf7WFLy1CuH4texWUz83nk4z28eG4Cq9rVfKf1djTtG+DUn8EHv4nGx2yffgfnbJlOh90bbZ+XpOPFqyeTljKY7sLexopNe7jhrX3yCQE3n17GE5/W89J3ZlOQItwyvwzhcikQHAS7u5wxsSsLk418tifezfHjmm6mFSQRCMmYtEqq2ocMMCeVpcYEHgYIy9Dq1cSIJoDdE0SllAiEZBr6/CwrCEREEyDojQkq3KgrixFNgKZeL009+xh/HF28sif2sD3A2j02ClJMMUGJBYcfIZyCbyT7u0zavQGSjZq4eilmbTTQcCAEiYahOv1uPynDuEbqlTIaZfyfllKKCJ1JDfaAEpSDfe2XndIgBfZviiSBQbtPPZWaPFP8ajHFpKXP5ceoFW6ZI4kQTsE3krFZVirzEqLXPU4/J49JJcEwFG5Nq1IwqyiZba0DjM+y0NDjIt2ii9Z5a3sHy2fmIe0z8RuTqqPY6OP7p5bGPG9eaQpV7XYmZerJSjJz52ofHdNuidx02yIJ3AYpbnqOy6bFBkX+9sx0ijJShgoS8jm7TId5HzE1apSMy7IwJsNMmTjPOaKIPU7BqGdTUx+1nQ6QJJIMGswaBZ1OHwOeICVpJty+IC39XjKtOtLMGqo7HKQY1bh9AQIBP1mJJoJIkbObeg0GlURrrx2r0YBOo6He5saiU5Fu0aJVSrTbfVj0avxBmXqbizSTBq0UJux3UZakoMsNqQYFaM1s7/JRZnBSqupC7Wwj6HNit1SwQyrB6Q/RPeCgMFHLxNwkEhL2M/i4bFS397G1O4RPVpNuNaBWKqjIspA+GAxZ8MUIl0uBYBg+22Pjuic2YB88ppNu0XLdvKJorEuNUsEdi8v59Rs7CYVlbl04hpPytfz4tZ3s6PRG6/z+3LH86KUdjEnV84+KzeRr9axRLeGGp9dH8/qcUJTEovEZ/Py/VQBkWLU8efVMStPNbKjr4op/V+Ee9ECqSNPx59MT8Np8lH72YzTdW+kvu4BfBS/npSoHsAmAP18wiXkT4s9sAmBMZkxJMmNKRujlCQ6IWKoLRi3BYJjn1zdHRROg0+6juddD0uB+pj8U5rXNbZw8mHPnkY/r2NYdiorm3jpPftbMyWNSqep0s1E1hfbcM/njOzUxydA+29OLTj00F+kY8PHuzi5cviB/WFkbFU2AnV1earrcnJHpRNO9FYBdGUt5qSo2adpdr++gudd9+F6K4LAghFMwavGHQtR1x2dv7LB7o8IJ0NLnJs0cMfL4AjI2V7xxprHXQ7o5svzt8qoIyCo6Hd64ei5f7AH02i7HYJBjT/w4PKDFF70eCMcbp+zeYFyfgqOPEE7BqMWgVXPWpKy48rGZlpjjOvPL0/hsT8SvvCzdRHlafKDhsyaks2bwuNIEswNLwMZJZbGZIRUSUQHey4KxGSQbNZw/Jd4dckKyRJdsjV4XKHvirPFT8xLJSogfj+DoIoRTMKqwOX0RF8pAgPaubuaVJHLdvEK0KgUmrYqbTytlXJaZ75xUxOLxGVw0LYecBD31PS5OKEriplNKKbME+PPiDLKsOr5VaeWJ87IoSTNg9wR4dPl48rKzSDfCbafmc0p5KpIUCev2pwsn02X3Rp915+IKZhYloVBIXHJCIZdOy0KlkEg0qPnj4kyy0pL45VqZ5pP/CsYUyjb9jsfOzSZ/MK7mvNIUfnfuBCz6+MRqgqOLsKoLRgVuf5B3qzq5+61d/GpRHh/X9fP8FhsZFg2/PLOcoKRiY0MvGVY9n9bZeHdnJ6XpJm4+rQyNUoFBq0SWZeSeOibX3Ic6MYdA7ixUq36FZG8lMOFS+iZcQ4tfT0nPB1jW3A1BH72n/J6m5HnISh0tfW7sXj9T8pKxGtRk7zNTbOv38Pb2Dvo9fkJhmJJrZU5pKh0DXnzBELlqO3opCJYser0yDm+QFIsWo0bYb0cS4XIp+Ebzye4elv9zLWeMTSHNIPHEhqFkagoJblkwhvUNvXj8IdbWD4V706kV3H3uBH7z5i4WFum4a+AnqDo2Rdwg3/81yPsE/5h8Nd6ys0h8/pyYZ/ef/hfOWl3AJTPz+MOKas6cmMmfLpiEVj10CP3e92r488ramHYvXD+L6YVJh/tVCA4C4XIp+EazNyvkeRNTeH5LrOtkWI4kWJuQbY0RTQBvIIzdE6Tb4WNuqisimhDJgb6PaALotz+NydMW9+yEqic5b1Iq6sH9yTe2tdM+MGQ46nH4eGptU1y7zS3xsTkFxwdCOAWjggxLxCjT6wqQbo63TqsUEt5AGJM2fumrH3S/dIY1oBo07iji68nmDIKKeBdLr7mQxj4fe/O0JRk06NRDf1o6jWJYA0+yMb4vwfGBEE7BqGBWcTIZVi33fNDMHaflx7hBVmSYcPlC/G9rG1fNLohpN7MwiaZeN0snZfHAVpmu6bdFbrhtkDbkBokk0Tf3l/SbSsCQPFSu1jMw8Wq6XEG2DQb2+NlZY8mwDgmlSavm1oVjYjJg5icbqBSh345bxB7nIVDb5aCtz0PbgBedWsmkHCtFqSJl65GgfcBDfbcLY6CX4kA1em8nCnM6kimDbm0u/Q4Hu/vDDAQ1JBp1eAMh8pMMuAIhuh0+dCol3U4fRq0Ki06FUauiusNBXrKBUk0vhkAvu4NpNPf7mZ4aJM29G8nnwJ9UxpZQAQ19fooSFJQFq9G62vEmj2VnOBe1SsmebhdGrZLKvETyk2NDunXZvVS122nocZFg0JCVoKOu24VKITEx28qYTMtReqPfbITL5RFiS3M/6+pt3P9BHQOeyEHpJKOGp789k3Lxyz+itPV7eGZdE6bQAFf0/g197f+Gbp7yE/yZp/G9//ayq3vIVfLPF4zn+Y0tfFJnY/H4TB78sC7a5IzxGeQnGWjuc/OL/1Xx2LIMmvsV/OyDmn3qFFCYbKCrycdLGzdFy797cjFvblPR0t/FnYuT+d2bu6Jh6sakm3j4imlR8ex2+Lj1hS18WNtDZV4Cl52Qz/VPbqRvMNlagkHNf66eyficoTOdgmMbsVQ/CIKhMK9vaaOq3REVTYBel583trUfxZF9M9jeOoBKqWCyri1WNAE+vQ+f1xsVTYi4Sj72SSOdDh9LJmTy2Cf1MU1WbO/AoFUxJsOCLMNWp4Xfru6Pq1OeYeGlja0x5Y+urmfxhEzmlqTy2ua2mNie1Z1ONjUN9VPVPsCHtT0AnDkpi7X1vVHRhEi2ypc2tRzaSxEcFYRwHgSBsMyAx0/7QLz7XHWH4yiM6JtFvztAMBTGGIp3o8Q7gByKd5Vs6vOQZtaiVEj4guG4+8FQOJpvKBAK4w3E13H5410efcEwSoVEmkVLa3/870PXPu6Y+/4jq1UqaB+mfm3nMN9JcMwihPMg0KuVTM5LZHpB/Nm7pcO49gkOLyXpJjQqBc2KrKEgwHvJmYGsig+ldu7kDHa0DtDS56E0LXYfem8wY+Wg0cakDFORboyrY9ap46zxJWkmWvs9rKmzcWp5WtxzJ+YMxfosTjFFn9HY62baML8/y6aI35/jCWEcOhhcNtwuOx93qPmsYYDnNzQjSRLfP6WE86flkCSOlxxeZBl3TzPuoEzIkIrdG8LjD+ILBhkv70bXugZp1+uEDan4TvgBvbo8Njb08qsPuun3+Ll4aiaLJuQQluDP79SwaEIm71Z1sra+lzHpJn60cAwFpjAeu40u2UqeIYDcU8uvN+v5uN5JWZqJb80pJDdBjUqCBz9upDjVTLpFR2VeAs+sb2bF9g5+umQsW1r6eenzFhL0Gm5fVM6s4iSyEiKuk6GwzMe13fzste30ufz89eLJrKvv46m1TciyzPUnFbN8Zh7Jw0STF4wswnNoJAkFoX4VvPVj6G9CnngR7hN+SLuUilGrItMqgjAcdpyd+Nc/geaze0GlpWrJy9y7wc/kXDNLrXWkf/IzlP0NhMaeR/vE77Dk6S4Arp9XwLxCM/2eEH/7sJEOu48rZxVgc/qYPyaVHqcXpULF6tpuXtncxvmVmVxr+BhLzyZWZ12FR5/ByUl9ON0evIlldLS3MLXzJTxBmef0F/HQmi7UKgWXzMjD5QuwaEImeYl6Eo0amns91HY5+O0bu3AHQtyyoIyzJmZi0Udmx71OHy5/iDSzFn8oTHt/xK89L9mAJMXnDxKMPEI4R5K2zfDPU2ISajHxIlh639CBacFhxb/uX2je/AEAztJlXGu/mn6/xD1zFIx/42wID+07+svP5lv91/BJQ2Sf8CdLKrjn7eronqYkwd8umsyDq+pYOjmL36+ojnnWd+bkcNvuK3CnjOd613XcUO7nBGMb97ZVcKXiTZK3/ZPnpz7Nbe/H7mPfsqCMJz5t4NUbZ5OdaOCFDc3c+uLWmDqPXDGV08fGR0YSHBsIl8uRpKcmVjQBtr0AdmFJHxGCPjRb/h29bMs4mTWNTuaUpKLrr40RTQBN9X9ZVjw0Y1tV3c24rKGjYbIcWS7X21z0DhNr88XN3XQXno2x7g2WFsInPTp6jKUown6Sq5/Bnz2TZ2rjk5/taLOTYNDQYHPjD4V4Zl28W+Xb+2XBFIwODko4JUkyjNRAjmm0w5zPNKWD5pv5OkYchZpgUln0Uh+0Y9aqsLl8BDXD/L8wptLhHvpVzkrQ0eP0x1RRqxQoJAmDJl4As6xaDK5mMKTQ6VGQZZDRhpy4wmqC5lxUzk6KrfHW9lSTlj63H7NOhUpSUJwW7wQhcpuPTr6ScEqSdKIkSVXArsHrSZIkPTCiIzuWyJwIebOGriUJFv0BTPHWVMFhQKFAnn4taCKik7vjIX4yz8Jb2zpwJFTgyT4xpnrvvF/z6JZIegmLXsWpFem09A2lmyjPMFPb6eCqEwtw+0MU7iNmKoXELSdaMdW9TsOMu3ijPsSJmt0ktnzA7CwFNeP/HwrbLi4vcMSkFE42akg1azlrYhbFqSYUConLZubH1Tl9bGy2SsHo4CvtcUqStBY4H/ivLMtTBsu2y7I8foTHB4z8Hmd7v4ftbQMMeAIUp5oYl2VBo9pvZjLQCh1bwN0HKWWQOQlUkU3/5l4321sH8ARClKWbGZtpQaEQm/1fhT2dfWxvthEKBChJUmLW63B5/eQG6lDprYRtdQRR4UqvZJvdhN0TZFqSl/RAMzpPJwRcuK2lbPDlY/PJpJq1eP0hTFol3Q4fM8zdWO21BBUaPCmTqXNIuCQj/e4g/lCYkzICWPurkDw2gglFuAw5ZHZ8gKSzEEosodpnJSXUhdXdTJ1hIjvtGoKoSDVpcPtDJBs1KOQg/pBMjytEillLt8OHVh1J1StccY9tRtzlUpbl5v0sf6ED1T2e6Bjw8v1nN7G+IRLiS5LgocumsnDcfhv61uzIf/vR2OPiqn+tj6ZiUCsl/nPNTGYWJcfVFcRS3THA8n9uiC6rjRolTy5LxqpTYXnxIqpOeZyL30/hylkFvPRuE20DXi6YlkO/zcelnf9AWb8CADNQdtI9XLu1nF/NT+SE1Teh7d4CC38LL/wCgpHD6CZrHn2n/Yvl/4kYh+4+I4uU1X9Av/vN6JgUC/7Cso3lNPa6eOaKdMaXZrO5OZmfr1fz9o4hd81r5xbx3s5OOuxeblkwBoUEv/xfFbIMxalGHrtqepy/umD08FX3OJslSToRkCVJUkuS9CNg5wiO64ixo20gKpoQMST8/LUddA+TiGs4NjT2xeSvCYRk/rSyRiTY+gq8u6M9Zi/S5Q/xdJUXOeDGN/YCXulMIxiSCYTCtA3Gt8xJNDBZ24ZpUDT3kv3Zr7iwRCbbU422azPknQjVK6KiCaAcaMLcvia6zznX2hUjmgDWD3/Oz+ZEZravbmnHFwyxvaWft3d0xtR7Yk0DiyZk4vaHWFdv4/+zd95hcpXl/77P9N5ne+9JNr33QMAQAhIEFCmKiggq4hdFKaKIYkFFf4pipwlSQi9CQiAhgRTS22Z777uz0/vM+f0xm92dzIIBCSTL3NeVC+Y97ykzu/vMOc/zfj5PbY+HBcWJL8vGfh972pKlm2kmFicaOK8FvgHkAp3AjOHXpz3uQGqVtc8TJDCO9G48+jyhlLF2h59gZELckJ9UWsfp/NjgkoAYJ2oup94poFPKknTd0VgcTcyXsh8hNxZFFGnYnXitywBPqumwyt+FXpV40JKFx5HJhtzopYmfad1AmFAkjis4vuTyWDam2xUkLorYdKNqpoET/OJNc3pyQoFTFMUBURQvF0UxUxTFDFEUrxBFcfC/73nqU5apH5HDHeOCGTlkGk5sfebMAlPK2KVz89MqkBNgvMLJpeVxRIkS7YEHuKg4Qp8nRJF1dPWCQiahTchJWT8byV/Chk45QVN5It/SshXKzk45vitzIb3uRGB0aQvhOJlmOH8xb/Ymjn3RNCsGtZyyDB364ySXFZk6O++nZwAAIABJREFUOoYSgX9JmQ2rVjHSKROSJZdpJh4nWhz6/TjDLmCXKIrPfehXdRwnszgUjcXZ2jDAHS8cpsMRYO3MXL55Rtm7LyOJx8DdBVI56LMIRqKsP9LLXS/V4PRH+MLCIr60uCjd0vV4oiEGHE78ohyz6ESUyHFJLWyu7eY3rzURiYlcN8/EBZMMRBR6CtueZUiZy5OuSbzd7GR2kZV/bWvFoJbxwzVVTIkexrz5dqSDR4lVrKFxyvUcjeViVEuYqnaiGTqKynEUMehE2PMQKHWEVvyI9qyzaO3qodPhpcmv4zuTh9BsvBXpYC3BstVEFt9ERKZjIKJCqdWhUqoY8obp9wbY0jCIQiolGouTb9Fw9ytHWTszl4pMPTFR5K6XajBrFPxgzSRWTs5ALU+7Np7qnFTlkCAIfwWqgCeHhy4CmgEr0CSK4rff74nfDx+FcsjhC+EPx8jUq5DL3uVG3NUB2/8M7/wVlHo4+ycw6QJQaun3BAnHRLIMqpQ72E864YEW3mj04HC5WO1Zh+nIv0BtwbX8Tg5qF5Np1jLkcvNaTR+bmgP8cIWZiq7neTS+kmdrg6yqzmJRsYk8hZ9Q0Mc/DsbY3uRg3QVqMod2I6l7mahEhWvJD4j01ZL11h0QcBCe8UXaJ12NXimjdiDMs4ed3JhzhNxdP4ewl+ica9huuQCtVkuZ2ouy9nkU+x+GeV8lnjUNpyyDXx5Qs7Gmj19ePI1fv1pLTY+H+cUWrl5aQo5BhVUrRSEGCcXlxCRyVHIpNn36aeN04WQHzu3AYlEUY8OvZcAWYAlwUBTFye/3xO+Hj11yeYwtv4GNdyaPfeF5KFn+8VzP6UA4wN4De/jOphBPlr2Gdd8fkzZ3rH2KG7dr2DmmQGfTKfjW0hx++J+WpLmPXGjjhTY5j+3u5ldnarlk1+UQHrVji2dMQZJVDQceHxmLLPw2j+qu4kcvHOH5cyNMe/2LScfsmX8bWnM2+le+mXzdZ/0Y/AM8EDmbkC6XP7zeiHdMwa8sQ8dt51YxOcdIpiHVlSnN6cHJllyagbEL0rSAZTiQplZHJiJ+B+x5KHW8ddtHfy2nE54u6ofirCmRY61/ImWz1V3DgU5X0tiUHCNPHUztANkp2nhmf6K6XSLpSwqaAJK+w4k1tmOQH3wUbcSBXa8k2/FOyjGzGh5H72lIve7O3WDIo1I5iEWrTAqaAA19XrqcQYLhdBHwk8iJBs67gX2CINwvCMIDwF7gV4IgaIHXTtbFnVLI1GAuSR03pH0U3xOFFqM8TptHJGIoSNkcUdtQSpN/Dfs9IUqsqXdxaiFM7nDuOCAZJwctU0E0+Xs8bioiJFHhDUYJaFN/ViFjCVHZONJZfRZEgwQkWsZLvChlEnRKGaeBR06ak8CJVtX/ASwmIbl8GvgBUCeKok8UxZvea19BEKSCIOwVBOHF4dfFgiDsEAShQRCExwVBSO3leiqiUMOK7ydXc80lULT447um0wF9FlPzzLR7ROqnfidRVBsmZpvEjnAJN59blbRLoS7GFZUkmQdn6BVUBfdx63IbUonAYy1anFWXJu0XXvFDwu17RgekcpwLvo/BYEIpl7BTnELMWDi6XabiaNlXqdfPS+Ssj6HLgLy5BKMiD9UreH5/FxfPzks615cWF5FrUpFjTj+mfxI50Rzn1cANQB6wD1gAbBNF8cwT2PdGYA5gEEXxPEEQngCeFkXxMUEQ/gzsF0Xxvvc6xv+c43R3Q/c+8PWDtRxyZoD8A1S9RRF6D0PfkcQdaPY0MCf+EMPRGIe73NT3ejGqZUzNNZFj/mRV1kVR5Ei3m6PdHpQyCdW5ieZjbYM+onGRfneApYZezL5G4jINfeaZHHbK6XYFyTSqyDercPmjBKMxel1B9CoZJq0CROj3hpDEwkzOUtPjl9LhDDDNEqMk2ojE20vAPo29fjvtzhCVGVqcXh++cJw8m5FKm4xGR5Sg38M8aT0qVxOCxgyWMo6GbRxxwHLzAGbXYSRiHNFUiCem4HAkk5jCxKDHT45BzmBQoMcdxK5XkmtSUWbXo1fL/8unkuZU5mRLLm8A5gLbRVE8QxCEKuBnJ3BRecAa4C7gRiGh2TwTuGx4yoPAHcB7Bs7/CW8fPPcNaNw4Orb2Pphx2bvv824IAmRVJ/4dx+a6fq55ePfIo9u0PCN/vmL2J2pZ0q7WIS7/246RxmXZBhXfOLMEkPCDZw+NzJuRX8CNZ1fwxoF+7n+rZWT88/PymVds4aYnDxCNJz7IYpuG86bl8IfXG7hqURF/29ZJXe+o7+Zl60VuPncpHUeD/G3LPr64qIgndrWPzBEEuPfS6Ty0rYX/V7QdzfafjJxPrDoPZt7Orc81D3t32rhpVQUPr2+jx+0CXCikEh756vxx26Wk+eRyojnOoCiKQQBBEJSiKB4FKk9gv98B3wOOyXCsgFMUxWOZ9g4SaqSTR++h5KAJ8Mot4Gz/0E4x6A1xx/NHkvJdBzpcHDqu6DGRCUZi/GFjfVK3x253kAKzlt9uqEuau6/dRTQm8uDbLUnj/97ZjsMXHgmaAM0DfgQh0RfIrFWMBMQpOQbeaXGgVUrRK+U8tC1xLItGPjIHEg8Jv3y1nmvnmcnadXfS+YSjL5IfahwxPNYopLgDUXrcyZ0y/7CxgVBaCZZmDCcaODsEQTABzwIbBEF4Dmh9rx0EQTgP6BNFcfcHuTBBEK4RBGGXIAi7+vv7P8ghEgTd44w5IZIq9/ugBCKxpK6Gx/CMI9WbqISisRElzVjigMMfThn3hqPEx8kS+UKpAcofjqGQSka6UULCsq3XHcKoVuAPR0eCX3Scg/a6g6hk0pTCEYAkPPr7oVXKkjpSHqN9yE8wmg6caUY50eLQhaIoOkVRvAO4HfgHsPa/7LYY+LQgCC3AYyQe0f8fYBpeBwqJnGnneDuLovhXURTniKI4x263n8hljo+tIrW9RcU54zodfVAy9Sounp2fNCaVCJSNY2w7UTGqFVw2f5yqeSzOWVXJ0kq5VCDHoCbfkpzGsOuUZI2zJtKiURCIxFDJpSP68N2tQywus9E84MWgkjMpO1HcUcpG5xzjMzNzeKfdSyRjWvIGpYGAcXSlRL8nRKE1tcJ++fwCjOrTo4aZ5qPhI+k5JAjCCuC7w8WhJ4GnxhSHDoii+J6myB+kOOQLRxn0hNApZVgGdiO+8n2EgTrEKRfhWXIbQxITJo0C43Byv98TxB+OkWVQoZQne3EGwok7Sp1S9q4a9LZBH3/b0sS63Z3kmFTcft5klpTZkEknXncSMeCiyxUAmYocq5GoqxtvKEpPTE9Df4BfvFxDHPj+OVVk6pWIwJO72/nPoR7yzRq++6kKBjxBiux67n29nj1tTqblGbnx7AqG/GF2Njt4clcHFp2Cb6woQ6OQMknRh6jLxiMq6HMHqe/zMSVbh0IqwR7vR61S8LsdPg53ubliYSEPvNVCtyvIRbNzuXxuHrjasclDGN/5HYqmDYhZ0xBX3MarwQq2NQzx7L5OtEoZ31pZhi8U459bm/EEo3xlaTGfn5tPZroh34TklG7WdlzgLCFxB2ohsR70ClEU33MR/fsNnLU9bn76Yg1bGgYosWm45dxJ1LZ2YJCEsGUX8efNzRzodDEtz8CPP13NkD/CrU8fpNcTZHV1FjetqqTYlrhbbOzz8ov/HGVDTS95ZjU/XVvN0nL7uLLKaCxOnyeERiHFpJmYdygD7XU8tn+IP+4YQhDgm0tyWWlzcN8hCc/XuLHplNx+3mQWFFsY8IW54/nD7Gh2sHpKJlcuKqSux8vBDidXLSlGgoBKLjDkjzDgDdPQ5+Vgh4uGfi+rq7OYlmdEH3MxJXSQPZr5vHDYQVmGjvvfamHAG+I3q7NY5XsBze77QConuvg7DGQswiO3saVLoNsd5ECHi9XVmczKkHDHKy3oFAKfqVSRn5XBnRs6+e45lVRm6PCFY+hVckRRRCTxxBCOxckyqNIdKCcwp3Tg/F95P4HTFQjzhX/uZH/7aGFGKZNw7fJSXIEILx/sTrKCs+kUXDAjl39sbR4ZO39aNr++ZDpRUeSbj+zhjdrRHKtUIvDCNxczOcf4Ibyz04yhNp7Z08r/bRjNC07NNVJmV/PMvtGmZIIAj1+zgFufOUhD36gFnFYh5arFxfzxjQbWzsjhygUF3Pz0Ib6wsJAndnWQb1Hz8sHk4zx5eSlEg/z0LR+fmpzJ3a8mTIgNKhkvLm6g4K1bky5RPPsubulcyGN7kpuk3bW2mhcPdrOtMWHqZdLIuWR2Pg++3cLz1y+mKmucXkZpJjzpLpfDdDmDSUETEt6JcVFEr5Kl+GcOeMMpDbxeOthNrztEryuYFDQh0S2xsX8cP8hPAv4Bnm5K/pVZVGrlpYN9SWOiCPW93qSgCQmj4mM36v851EMkLtLpDNDvDbOw1MrGmtTjNDmCdEYN7Gt3EhhT2Z6br6OgZV3KJcZ79nOg258y3u0OMrvQPPLa6Y+gkksIx+JJRtRp0pwIEy5wapWyJMXJMeRSCVKJkFI4EIREw66xZBvVaBRSNEppkjntMUyf1EXPMhWTzMkGz32eEHnjLPQ3auQox3GZOpbzzTOrR9IdRrWMPndoRE45FpNSgk4aw6CWJeWLuzwR3IZxVsQZC1DJU8+rlktx+pKr+8d+7p/Yn2eaD8yEC5wFFg0/On8ygsBIkFxdncWBDicbjvRy2fzCpPnfWFFGvyc0MlciwJ0XTMGmV5JlUHPnBdWMTXGdPTmDyTmf0Mc6cxEXVmowa0YDzY6mQW5ZmZf0pTSnyMysfDO3rZmEZPg3TC4VOH96NrtbHMgkAt8+qwKpALesrsLhDdPU7+Wy+QVJx5mRb6LIoqIssJ+vLSuhzx1k6rAaqabHx+HcS0A1mjIR9TlIFSqun29K+jKcmmukKlPL8wdGHeEvmZPH5roBzpuWTVXWGLllmjQnwITLcQLU9XrY0zZEIByjzK6j2Kahsd+Pwxei1K7FF47R7QqSY1JTnqGjrtdLTbcbrVJKeaaOzqEAXc4g+RYN03ONDPjCOHxhBr0h3MEomUYV2QYlVdkGNIoJalY70ADde4mE/LgMk3hl0I5cJqXSqkAd91A3GAWJnIoMDVnhNvZH8qgbCGFQy5lqE/DGpBztC5FlVDPoC+MPx8gxqdAppFRKOzEM7selLWFftIBWV4yqbAP59GNzH4aQk4CpinqhADESwm7UMhiS4AqDQGJdZzwaotCsIoc+tK46lDIZEo2ZoGcQv2UKTbEMmvq9qORSii0KckNNNEctdPplmLRKEAUUSgWTcwzY0m79n1hOepfL04W6Xg+X/W37SBMwpUzCI1fPZ3nl+GtB/3Oom+v+lTCGWFpuQ6eS8Z8xBYqrlxRz1aJCbn/uEAc6RnOnN62qpGXAz2eOM3+YEPTXwoPng7cXOWCTKpi28iEueDpORaaeM6syuG9TEwCZeiW3n1PM9ev2jyinKrP0LC+3o1ZI+f0bjfQP55UVUgk3r64ippaxYP/j3G+5lfveOQzA7Ut0LGy5GdnAEQB0goB75d/49Ho9X1pczNN7OuhyBVHJJfz7HIGZGz6Hd/bX+UXkUrJMs/n71iac/gCgQSVv5aZVKqbmGplXfKzbaCbH9S1Nk+YDM+Ee1bfU9Sd1TgxF4/xlcyPhcZQfA54Qd75wZOT1nEJzUtAEuP/tFhr6fElBE+CBt1s41OWiYyi1EHHa07QJvGO6OsbCVNT9jSXFBmp7PGSOcThfVmHnF6+1JslNa3s8mLWJRev9Y4px4VicDTW9vNISp3X2Lfxl12h1fom2cyRoAiCKFO+6i89Xa3ng7RbOm56whAtG4jzYqCOWNYNG7UxeOdJHrzuIc0xDt2AkzvYmBy/s60pLJdOcFCZc4Ox2pUof24cCRGKpKYlgNMaAd/QPezy5Xiwu4gunSicdvjAquZTgCXbDPK3wdKcMqXwdZGkSecOxenSzVpEUHI8hCOK48sU+d4i4CAGpJklyqYp7U+ZKfL1kawW8oWhSoanVIxLT2PGLcoxqOQ5fqqSz3xMiFIuPSDHTpPkwmXCBc7xH8isXFKIdp9KeaVBxyZxRqaQ/HMOqTa6il9q15Js1KZX3T03OJBSJk2OagH6MJStShjrKLmNDkx+pREiqbm+u7eeimdlJc6USgWiMpO6Ux1g5KYNCo5S83k0UjTErbpMWgpD86zg06TKeqI2wsMTKwTF3/JdXiCg63qYw3Ig3GGXKOMW6JeU2puYaMaQr5mlOAhOuOOQLRdlY08vdr9biC0X52vJSLpqVi12fGuA6nQFc/jBP7u5g3a4OyjK13HhWJfduauBIl5svLy5iWbmdIpuWul4Pv361lupcI1NzjRRYNdh0Skrsp7kePRIgMNhBLB4nIlEwEDMgESPkuXejXH8LhD24Zl7Ly5IzsCljVOXZaI+a6HIF6XQGKLJqqDbF+PeuTh4/6CHHpOJ7Kwvp84v0eSNYdUr+vLkRXyjK2pm5VGXqWWR2kr/+q9TMvpNf1xjZ1uxkzZQM7qjuQ/PGjxA8XbgnX8azijUcGFLw6VmFfP+ZI4Sjca5ZnMfqvAghuQGtTEQjF/jngVDC3PiddsLROBfPzqMyS8fiMnu6H1Ca9yStHDoOhzdENC6SMc4fjisQ5qndndyzoY5QNMa3zypn1eQs7AYlRrUChy9EY5+Xn/3nKHvbnJTatdx14VTC0Rg3P3WQLleQ+cUWLpyZy/R8E5OyT8/lSbH+BsSNdyKrfZ6euTfzj8ineHBnL3KpwGXzC5hsFaiySDHIY2Tu+R2yQ0+Aykjb3Nv42+B0irPt+MIRPj+vELMQoN8XQS2XEo5EafHAHS/V0jbo5/L5BZw1OYOccCvZr16DEHTC8u8RkZvot80lptDjCEu5940GMmRBqmwyigpLUMkFevsHmVScRyQmsqm2H7VcYEfTAP850o9Vq+BHKyyckRWiUSjAYjYTFxP2cON9UaZJczzpwPk+eL2mly8/mHy8W8+t4pplpUAiP3bxn9+mdXC08KNVSPnS4iLufaNxZGxWgZkpOQZuPLsCs/Y006ZHQ8SevR7pocdBbebBqQ/xozc9SVNuPLuCN4/28EjhSyh3JXtN7zrjYb6/y8j0fCPLyu2snTnqNrW5to/vPXWAXvdo7tOkkfPC/Bryt/1w9CArfwgb72To6p18e72LzXWjKi2JAD//zFT+tb2NRaVWdrY4iMVFymxqnt6XXMB76kI9RnmcTu1klldmfBifTppPCGnJ5ftga8Ngyti63R14g4liRqczkBQ0ISEXPN7sYU/bECaNnC7nh+ft+ZHh7UN65CkAgrkLebIx1ciitsfD+eVylEdSu1PmBBrodPrJNal5bn9X0rZOZyApaEJC4tguPc52btgTtTOgSAqaAHExcZyFpVYUMgl725wsKLHy0qFkWSZAo1sgR+Zmd6vjv7/vNGk+BD6RgbPYnlq0qMzUo5QlNOsGlew95YLHsGgVBMMxtKrTcDmsQotoLgZA7m5nsjl1SpZRRc1gnJi5NGWbT2FDKghEYyJTjktVGNTylGKaIIBRctyKB2niLl0ri5NpSF2ErlXI6HEFicbjGNVyelxBCsaRd5oVcQIoyTWN060yTZqTwCcycC4utSVVfHVKGVcvLUE+HCwLrVpuWzMpaZ8vLykiMmYtqCDAV5YUMyXXSKHlNPyD1ViIrf4VSORI+w5yZZETw5gvgByjCp1Shkylx73ktoQZtFQBgoRwxnQ2+Qr40pJittb3c/705Kp6eYaOr69IDrZfX5JPaeOYvvR5c8DVAbYKik0yblszOclHYGGplVK7ltdqepmeZ+LOC6bw6uEerltelBSUF+SrqbZJ2eIwMr/ESpo0HwWfyBwnQMeQn5ouN+FYnMosPWUZenpcAXY0O+gY8ifuQOVSBr1hMg0qJmcbiMbjHOx00e0MYtcryDKqGPSFCUbiDHgSxajpeUaqc42nnIHxgCfE/g4nbQ4/U3OM9HtDNA14KTRImaEdJCvaRZNqEkeHJIgyFTqVnEAkSrZBhdMfRiuJUNvrRa+UUmTT0R+SIIowTT2IdmAfEqmcGu18jjhEzBoFpRlaet0hOp0BrFoFuUYlxbFmJIP1ROR6GiVFRKQapmXICfh9NEYsuIJxetwBLFoFdp2SNocfq05JgUVDgUXD0R4PXc4ANjV0DboxyKJUmUUiEhVSYw655tPwCyzNx0q6OPQ/4vCF+e4T+3h9jI3cV5YUcencAsozU00gItE4f9zUQDQusm5Xx0iDL6lE4MEvzWNJue2kXu/7wROM8JMXj/DErg7mFZlYUm7nng31I9sXlVrJMqh4em+ii4ldp+TyBQV4glG21PXz2bn5/OzlmpEF67kmNbesriI+2MCafV9H6u9j84p1fOklz8icPLOaW86t4huP7B05z3fOrmBzXT+7WodGxu5cXUJ+hpnbnj1M17B4QSLAredO4u5XarHrlXx2Tj7nTs0a9+eQJs3/Qro49D9S2+NOCpoA/9reRkNfqqIFoGXQx183NyGKJHVFjMVF7tlQizeUqpr5uGjs9/LErg4ALl9QNKIzP8bbjYNJvXb6vSGCkRhWrZzSDB3rdnckqXw6nQH6PCGmUo/U3Y6n/EJ+uSueNKdjKEBtjyfJKT8uiklBE+CXG1vxhmMjQTMxD57Z28kZVXY6nQGi8Tjbm1MLemnSfFykA+cw43VXDEXj+MPja50DkRgSiUBgHDlmrztE6BSSYvpDybnZwDj67dhxTx6eYBRBEDBp5Ax6UyWN7mAEZTTxpRJUZdDvTf0cgpF4Uj7y+HNAYrXCeFLXAW9opP1IMBLHMc41pEnzcZEOnMOUZeiSiiMAM/NN43Y9BMi3aCi2acgYZ6H1lQsL37Wp28dBkU1LxrAxx9FuDwtLLEnbtQopx8e0fEtCS76lfoBzqpN9hQQByuw6OlQVIAjYm57hyqmqlDl5ZnWSVlwhlaS47Z9ZYUUtk3J8W59zqrN5s64fQQCLVs684uRrTpPm42Ti5zjDPnB3gVyTaAkci4KrDRDAVACS0T/kXS0OfvVqLTU9bpaV27lyQSFWnYIiqzap2BOJxul0BvCGIuxpcVCaqccdjNIy4EMiCKydkfOxdEWMx0U6hvyIQK4mjiwwQEPIiC8qQS4VuGd9Hd3uALefN4XWQR9P7upABG5YWcbBThcPvNWKQSXjaytK6HYG0avklGfqONTpwuGL8PSeDmw6BdctL2FHyxCz87TMje0nb8/d9BVfyON8iod3D2DTKbhpVSWZRhVHOl10OAPkmNRMytbT7Qzx961NNPT5WDM1k6/MtRMMRzgwKPDPrc3E4iLfPqscnVKGOxhBIZWgVkhZWGpFJT8Nl32lOaVJF4fGY6Ae1v8A6l4BjRUu/As0b4Ed9yUMJRbfAHOvBt2o2sQXjtLp8PNOi4M7X6whLopctaiYq5cUkWlU0+UM8JfNjTyyo42zJ2WydlYuf3qjgf0dLrKNKn5yQTVnVmUgGacL5slk0Bfi0R1t/GlTA/eepWFO4C02mC/lF+sbGfCGWVhi4XvnVLGxpo+/b20iFhe5bH4BS0utXPvIHkrtOm5bM4mKTD3tDj8/fuEIh7rc5JnV3HbuJB7Z3kKhTYdFqyBTr8SqU+APx+h2BjmjSIFdA1s6JezrcBIIxyiyaen3htDIZTy0rYVgNM7q6izseiUGlYzpeUZ+vb4euVTgtxdPxhbpJti+m53SudyxoYMBb5j5xRYumJHDrEJzuplampNCOnAeTyQIz14Lh59JvFboYN41sPWe5HkX/QOmXpw09OL+Lr75771JYz+7sJrL5hfyj61N/OTFGiQC3PPZ6fx5cxNHe0alinKpwIvXL6XyI27H8NKBLr7x6F5WV+j5Lb9h1+xfceVj9UmP4Csq7YSi8ZFOjwBfW1bCv99pwx1I5CifuW4RNzy+jzbHqHJKLZfylaXF3Pt6A5Cowif+a+M3G2opsemYlmfkmeGqPCQe1X950TS+t+5A0nVeuaCQDUd6mZ5vpNuVaN97xzmFXNb6Q44WXsEFryqTrnlhqZVyu47vrKrEmHY6SvMhk66qH4+3D448N/o6ezq0b0+ddyywjuHVIz0pY+t2d+INRXhqdyI45JjUBMLxpKAJEImJNPWPX4k/mWw4kjAePitfRNW2iRaPkJK33FTbn9TpEWBHs4PpeaaR193uQFLQhEQxaez989uNg8wqNNPm8GPXKVlQYkmRTGbqVRzscKZc51sNA8wuNLOptp8FwwvW51gjKJo30hwxpVzztsZBDJqEaihNmlOFiRs4FVoYlhQCiTynuSh1Xta0lKFJ4zwWTsszopbLRrwfh3xh1AppSkEJElLMj5pjj7JtXgnosxnPJjTXpE4xHS6waOhyjgYlnUo+bpfIsTneHKOKAU8Im06BKxChyxlMUU+5ApFxJZAFVg3drsDweRNa9d6gFAy5mGWphsg5RhW+UBT96ShrTTNhmbiBU2uF8347oodmqBkKFoJ2zMJ0fQ5M/nTKrp+akkmeSYVWIR2u6ir43Jx8pBKBLy4qwqCW4QvH6HT6uW5FaVJF+JLZeVR9DDZzZ01OXPPTdWFaFt/N1PBBlpYn7ugkAuhVMm5bU8XullEjDLNGzpQcAy2DPjQKKUvLbVRk6LjpU5UopJIRvf7n5ubxdsMAkFjgf9XiYhr6PIgklmy93TjAl5cUJwXcUruWbJOKKdmGkc/HolGwalImR7rcXLmgkLfqE8f0ya14z76byYMbWFUx2rXy2LnmF1vIGad1cJo0HxcTM8cZcEHXbug5BLrMRGFIEPDoSlB6WpA6mxFlKuLZM1FkTUrd39tPuG0X8b4awuZyIpkzsWYlmrL1uALU93lRBB1UxurxqLNpiGXR7Y6SbVIzs8A0sv7wI0EUoXsfuLoISlQEo3AwmMERp5TSbAsyqYQuZwCDsllxAAAgAElEQVSHL0yBRYNJLad/uF1IpUVKVBQ43BdmyB+mPEOPJxhmmWkAXf9e4rEIwYxZOI2VdLvD9LqC2PQKRARaBrwgikzPkFPl3Y4Q9lJnWUGDR0a1MUxBoAZxsB6vvowOzWSiKjNHuz0M+cNMyTESjMRoHPBSaVMzx+jCZM3C09eCNximLpZDX0Agw6Ai26imLEOHYhzTlTRp/lfSXS6PEY/Dngdhw+2jYyVnEDz3/yF77Q4UR58eGfbN/Sac9QMUyjF3M2E/bP4Finf+DoAKYNZVsOouHFEFtzx9kGjIz+9tz2A69AAmIP/YnJl3gfIjfkxv3wEb7yRauAyFGOPh4Aru2tIGwCVzItT3etjXPtp24trlJbxR28eFM3LRq3T86tVa6seoozZdYSHjyc9CKNFITSdTEr7gCUry5vHAWy3ML7Fyz4bakV5LarmUxz+lZtrGrzJdkGBfuw77/seRH3wcAA3gOm8dV7/QTuuY3On3z6nkb2824w1FuXGRhetMGzEv/BpmuYrRZiZp0pyaTLyv8aFmeOOu5LGmN5AN1KAeEzQBtLv+RLCnLnnuYD0MB80R9jwAA3XU9Xh4o7afL1REMB96YNw5HymxKGz7E5SfjYwo7XErv9k+2jkyz6ROCpoAD29rZXlFBp3OID3uYFLQzDQo0TW/MhI0AYiGsB15iA6Hj5ZBH4c6XUkN6gKRGM90mcFSAmKcLP/RkaB5jHq3LCloAjyyo43Vwwvr/7BjiNaIHgYb/uePJE2aj4KJFzijwcS/4wn7UsfEOGLkOBPi41+PGT8mVVTE36XC+277niziUXB3AAIIAiGJOimovZvEUSmT4ApECB/XAVKnlKP096bsI/N2EYtHMajkDPlTpY+dPkCVqMxLIqntkv3x1Acbhy880kgtEhMJooRx9k2T5lRk4gVOUyGUrkweUxkRbRWgT5YORjOnIrOVJM81F4PlOONeUxFYSymxazGq5exym1LNfYfnfKTIVTD3q+BoQgx6yA3WcWbpaPM4ASFF4ri8ws7u1iEmZxvIMamTDJubBrw4i89NOc3QlCsx6zR0DPnHlT5eUhKFnsR6Ta++FNGQm7S9XONPMTY+b1oObxxNuLnPKdCTH2pIXgWRJs0pzIQrDoWjcdq6upEM1pG//3fIpTI481bInY23ZQ/yrb9C2b2TQOFKYgu/hS6/mo4hP/5QDJlEQC6TkBtpRnzzHqQtmxCLliEsv5kOeT6hSJxwLMav19fx5bIAc9rvR9n+JhQuhWU3QdaUk/L++1x+upx+pFIp8TiY1VKyGEARcYNcC127iYoCEjFGS8zKA406Xq73M6vAzMWz8/jH1iYa+30sr7BTnqlHAHJMKvKMaoaCEVoG/OxudWDSKFhcoGKpuAf9trshFiG08Ab6c8/CH5NjlATY2hmj0yewbncHggBfX1bEZFOUjHAHKpWKJkkBFbI+VNvuQertITL9CtyWavaFcvndxnp63CEunpWLWaPgL282sbLCzDUVPspyMyBjnEJdmjQnkbRyCGgd8PHQ9lYe3tZKXBS5dG4eVy8uoChjdIF3KOAl4nOi1NuICDJe2N/NT188gicUZXGZlUtm57Gr1Ulj9yALsiWUFebjDkv4+X9qcAejrKzK4ObVVRjVciwqkIVcoDYlHNJPAltqe7nl2cN0DAUotWu5YkEhc3WDTNr/M6RNG0FthlU/h9Iz8MRktPY66HQGaPErkcrkVOea8AYjeIMRso1qmgf87G13EghHmVlo5rcb6nAHo5xRYeM7K4t4dl83T+3vY22lhkXFBkSNne+uO4A7GOXMUh23TfMR12Xh1BTiDkb5y+ZGdrYMYdcruXFlGX/c3ITTH+HJz+VQ2bkOyY77IB7FNeWLtE3/FqLSTLFdjS8UR4jHsMgCyNVGkJ1mze7STAjSVXVga+MA/9jaPPL6XzvaybNouXZM4FSqdSjVicfZvU2DfP+pUUng/nYXC0qs/Gt7KwDbWuEmY5RfvVo7Mmfj0T6sOgV3rZ2KTCYBxclrQ9sy4OO6R/fhDSXkkI39Pt5p6Obzyr8kgiZAYCghLf3yenZ4i7j6ofqkY1yzrITn93Vx7tQsfvryUQaG7dm+t6qSH79wZGTeG3UD6NVyWgf9DPkj3L/Xxf17XVx/ppJILPHl+nqjF5NSz08tT/KW8Soe39NLTXdCOdXvCXH780e4fmU5975ej7R3H5K3fjdyfOPBf2LWFbJ25xQevnr+mJbKp3lf+jSfSCZUjnPzcUbEAOsP9xIex38SoOE4aeTkHANbhxdlQ2LhuC+U6jP54oFuBrypKpcPm3aHfyRoHmNhZhxV3YupkwfrxzX73VjTy6xCExqlbCRoAvjH+UzWH+ll7nE5zH3tziTd/Ut1PpxyO7l62UjQPEY0LhKJxSmyasnp3Zxy/Ly255ieo6FlcJxCXZo0pxETKnBWjNNaoTJLh0IuHWc22I7zzOx2BSixa0dex0VQjbNveYYOnfLk36ybtYoUn8oml0DcWp46WWOj1J5691Zq19E5FEAikFSgUYzTE6nEpk1pdVxg0STpxMtsKrThQYIREZMm1XRDIZXQ7w3hMlalbHOap9HijGD5KAUCadKcBCZU4DxrciZ5Y9rH2nQKLpqV967zp+UbWVo22hnRH4qxanIm5Rm6EfmgJxhh4ZjuiUqZhFvXTEL/ETj1lGVo+fbKsqQxvdlG+/wfjUpJAco/BTkzWFhqpSpLN3Kd2UYll8zJo6nfxyuHevj6GQl5qFEtp3MowIIxhsZKmYTvf6qMA+2jkswii5rpuYaR1iBKmYTb5wkMZSxgKCrjmqUlSYH94tl5tDp8OP0RGo0LRtoPA6Cxsj9jLfOLrWmLuDSnPROqONTvCVLb46HV4UculVCVqWNa/hg3IFGE7v3EWrcRjkGvaSa1FGHTyfEGo/giMdr6XRikUWbaYhjkcYY0JWQa1RztduMNRSnN0I17Z/uBEEXo2Q+t2xnSFLKHSezuDJJrUVNo0bCrdQirVkGJXUtLvxezRkamTkaXK0KVvJuscDtBqY52ZQkqYxZdrgCRaAyNQkZDnxd/OMqkTC02nYyjvQHsUi9zpI0oHTXELWW49GUcdStxRJVYDVrESIBio0DzYIDJWjcWx37iYT/ejNnsD2aSrYqgFv1sd1mxGzWoZBKC0TgOX4ilNi+a3t0Inm5i2bOI2iZh8zUS9/YSQk6fpoxeaTYVmfqPVpKaJs178IkvDvnDUX67oY5Hd7aPjH12Tj4/zNCPPlZ37oYHzkUaDaEGiuQaepc/zFFvGcFonLteGu3kaNUqeGzZAAOCk3jJLJZW2D/8i+7cDQ+sIW7I44mS3/PzrYdHNs3IN1Fq1/K71+rJMqj4zKxcbnvuCGq5lP87u4LrXx5AENTcem4Fv3qyFou2nYtm5zEpW8931x0YcUE6f1o2Tn8IoiF+b30a4+EHR86hqVpDdiRAMODnd+ZbMdhy+cn6dl64xIr2359NFJ4ApUTKGefew68PFfPHXV6gF7NGzlWLi3H6wnx7vgbNk19BPjBabPKe8/9gwVVIADVQOPwvTZqJwIR5VG/q9yUFTYAndrUne2Puuh+iY4o6ET9THBtoc/h5cX93UpfGQV+YHf5cJvl28dqRVDXNh8LuByEapG3SV7lnjFQSEkWZgmGrth53EJlUQCoRCERiHO1xU2jVIIrw7HA3yB53EIVUoHMokGQdV5ahY0uDgyvLw5jHBE0Ajr4E+fNRdW3nLOsgj+5sY3GpDaF500jQBCAeQzj4OGuLRwtKQ/4I3mCUdXs6oOtAUtAE0G2+A29f64fzOaVJc4oxYQLneJ0bAYLHxkURPF0p2xX+XlRy2bhSQldEQBF14w6cpFa/w9cTkiQ3NTvGWMlkOBpHOpxQdPojI/6Uif9P5FvjcRH/cV03jx1DIb7LKgAxNrLd5Y9g1igQAuO04g0MoZQkf8b+cDShPIqOIzUNeRBjp06L5DRpPkwmTOAstmopHVMRByi2aSiyDo8JAsz+Usp+bfmfJhqLjxhOHEMQYJ7JQ4dpHssqM1L2+1CYfRUAeZ3/YWVZct7UoJIRG46lUomAQSUnPDwwp9A8shRo9dQsNtf1I5UIqBRSyjP0jFU3hqNxLFoF250motbjKt2mQvA7QGWkLpbN+dNzeGF/F/HiM1KvtXIN+5zJnpj5Zg12vRLsVSBLXs/qr74clTXtc5RmYjKhikN1vW7+srmJLfUDLC6zce3yUnJNKrpcQdRyKfnqKNS9DG/eTVyQ0THtW7zgr2ZZdRGN/V5aB7w8uacLs1rC/81VU6V00meaikouo1jtR2nIoMsv4AlGyTIqMarff5HDG4zQ4/ThC4bJUQaw9W1HePNummfcxEODlbx8ZJBJWQY+Ny+f326oQ6OQcfXSYv69o41ed5BrlhTgjUAwGqfArKGp30O1IcBUq0ivaCIejWGTuNnVJ6EjqqPYqiHPIONPm5r4fFmEuV3/Qt22CTFvPkLRIkL1m2iZfRtSuRx1zEdYZSVfJyLrPQib74awB2Z/iVjxcpoiFroCMg50+dAqZTh8ES6YkUN5ph5fw1vI3/wFCmcDvkmfJT7zC+izPmLtfpo075O05HKYSDSOKxjBoJLR5vDzg2cOsb3ZgUEl44fnT2bNtGzUUS8xEZxxNTqVDKVMSiwusq9tiJpuN7JYgEKLkl1dUe7d1Eg4FufqeRlMzTNxxystOHxhpucZ+cVF08YoYP47DX1e3m4c4JVDPbzdOIhGIeW2VaVcJL5GOBziVcVK9vYlzDayDSounVfAv99pY1NtPxfPymPt9Ez8kTh3vVzL/g4XJo2cH68uYfXB/0PR/Q7xVT9H2H4ffqWd54tv564tLryhKItLLfxwoRKDxYojqiEz1Iq6dxcN2jm4lZmUubeR/ebN4B8knjWd+PzrkDkawJAN7TuJeAfZOOmn3PpKBw5fmOocAz9ZW011rhH5mPWgQb+bWNCHxpSJIJkwDzNpJjDpwHkcgXCMGx7by/rjCjtPXbeQ2YWpDj+1PR7O+8MWIjERiQDfPquCezaM+mveeHYFv3utLqmANDPfxINfnjdij/ZeBCNR7n61lj53iBcPdCdte/QcCVEkfOGV5PzkZ2blsr/dSWN/Qmnzubl5NPX5eKd1tHAjCPDcqhDTPG9C40ZwtrFjxSN87pXklfOfnprB3caneVr9GT579AZ2T7mVH+0z8OslAtUvfRrE0RxrPGs6EmtJ4hF8y685suSPnLdel/Tep+Ya+NfV8z/QXXeaNKcK6S6XxzHgDbGhJrUa3jwwvtyv3eEb0WTnmNQp88KxeFLgANjb7hxZHP7frydMNCayZYyk8xgtYRMH3amNzbbWDyQFebtelRQ0IVHzao4YEz2WnG0gCDSFjMcfivVHB3DI7CzJDCHrP0xTyMicQjMyd0tS0ASQ9OwHWyX01YC5iJaoOeW9H+x00+M6+bLTNGlORSZs4NSpZCnFIkiVWR7Doh0dd/jCZBmSix3jSRTteiUG9YkthdUpZcTi8XGvySoPUqBJ1cSX2nV0DI2a+3oDEbKNqaYiNlkQ4rFEZ09RxK5IDWjldh3ayABdAQVoLNgVITqGAsRU1pS5aO0QcIApH7x9WGWpXw42neKE33uaNBONkxY4BUFQCYKwUxCE/YIgHBYE4cfD48WCIOwQBKFBEITHBUE4Kc96Zo2COy+oRilLdGu0aBWcU51Jdc74OcmKTD3XLEuYGvvDMeKiyKSsUe13fa+Hz84arbxLJQI/v3AqWYYT675o0ig4b1oOn56ek2QuvLDYxPTADmZH9zI3b/RYOqWMy+YXsLc9cYcpCDA1z8gd509BNcZ8+KKpVib3vgAH18Gi60EQmOp8nTNKRu9gVXIJty41oaxaxbMtclqX/ZZp4f3k6ER8piqGJl85eqESKZEz74C+owlZZ9BFVec6rpg5eucrlQjceUE12cZ058k0n0xOWo5TEAQB0Iqi6BUEQQ5sBW4AbgSeFkXxMUEQ/gzsF0Xxvvc61gfJcQKIosiBDid72530u0PMK7Ywp8iC9l0MOjyBCLW9Hvo8IQqtGswaBfVdDiIhP+WGGCa9jqNeNYO+MMU2LeUZuqR+48doH/Lj7Gkly7UfnbseIXsabtsstnSCQSNHLhFweINkaiXIFEr2tQ6CGGNmgQV3GNyhOHa9kv3tTlRyKSV2LVaNgm53kAMdLgqtGixaBaIokq8T0TmPogoOoLCXoiBEcLATn7WaQ149/oiISSOjecBPgVVLTbcHpUxgap6JQ50uHL4wC4pMVEnaUHraCesLcMVVFA1tRZE5CXwDoLEwKM+m1iVlMCKnwG5mSq5x3PeeJs3pxCldHBIEQUMicF4HvARkiaIYFQRhIXCHKIqr3mv/Dxo4O4b8fPEfO2kck6/81cXTuGTOyVtfOOgN8fiWg3yh/zfoml4eGfdM+zLX9HyabW1+BAH++cW5qGQCX7x/18j6TKVMwk/XVuMPR/nR86NKnCVlVsoz9Nz/dsvI2PIyM19flMWlD9dw7Edo0sh5fPkQkZx5XLOuieWVdva1O6np9nDbmkn8+tVaQtE431pZxqM72pJs5n50/mS6nQH+uqU5cZxlA1Ru/T+46iXIe9+/V2nSnBacksUhQRCkgiDsA/qADUAj4BRF8VhCrwPIfbf9/1cOd7mTgibAz16uodd98pqq1fZ4qFb2JgVNAP3B+/lCRUJ5I4qwbnc76/Z0jgRNgFA0zs4WBxtr+pL2nVVo5sFtLUljmxuGOOyAsd97Tn+E7b5sWgd9dLmCZBlU1HR7KM/Qsa/NSSgaRyGVEIuTFDQhIU+dUWAeOc42fx5IZLD/sf/xE0mTZuJxUgOnKIoxURRnAHnAPCDVpPFdEAThGkEQdgmCsKu/P9Wg+EQIjiPD9IVihGMn7y47EIkhH0/eKIooGJUgRuNiSvACcPkjKRVsYNyxsR0tj+GOSIgMTz4mt9QpZbiDiXNLJUJKd0sAdyC5OOWOCIl2IN6TpNNPk+Y05iNJUomi6ATeABYCJkEQjiUZ84DOd9nnr6IozhFFcY7d/sGciSoz9UldHAGuXFhAtuHktbuoyNRTG8kkbkhOB0SzZvLmwGixaWGplUtm5aTsv6jUyvS85OVEjX1e5hSak8Yy9Eoq7MkrBAQBFpg9FFo0yKUCogh6pYyDnYmWIJAI7FatguOaTrJmWjZ9nuDIcRZZfOAfhJlXvL8PIE2aTwAnszhkByKiKDoFQVAD64FfAl8EnhpTHDogiuKf3utY71c51OP0Ig068cRlDIbl/HlzM00DXj43J5/PzMoj16wGbx94ekGQgEQKxjxQJgJbjyvAoDeccCQSBPKtGpSy8V3kIWGu0erwEY7GsekUNPX7MItDOIMgiwfJkbnpkuaxvTPESwd7+MysPOYVWVBIJezvGOKvW5qRCAKXzi0g26TEH47R4wry2DvtZOgUfG1ZETa9hqf3drKxpo/p+UauXFCIXhphd6efB7a1Y1JJuGGOimq9jwN+K5ONYfb1g1OewYYjvajkEuYWWXh0Zxu5RhUXz8nn71ubGfKFOX96DotKLfzilToE4nx7loKFzfcim3oh0oqzQfkh+Y+mSXOKccoVhwRBmAY8CEhJ3Nk+IYrinYIglACPARZgL3CFKL6bdU+CEw2cfe4gu4/Uk6mJ870NDhr6/Vg0cv5w6TQqs03Y9MN3mu074elrYKgZdBmw6FvQcwhx+c1sGdTx3Sf30+cJkWdW85UlxTT1e7luRRk5ptTlN65AmH/vbOe3G+r4+opSGnpdXD0vg/t29PPq4V5kEoHL5hWQaVBx/1stfHdVBXKpwKA3TKvDT0WmDrVciisQ4eWDPRTbtNywoojcwbfw1G9F4WrFkzGb+wJnsa3ZyeQcIzkmFf5QjPvfbuGschPfW6THKrgwWDJwOZ2Y138L6cBRUJvxnP0bHhyqpsMZwqiSMb/EgkQQqFL0QSxEMK4g6+hDqEoX4ypaRSAKWiGAXikHVdqpPc3E5pQLnB8mJxo4n93TQZW0g2++FqChf3ThuFQi8NL1S6jKNoC7G/5+JrjHWMzJVLDoeposy1jzlD/Jos6uV3Lu1GxKbBq+uKiY43mzrp8v/HMnU3IMFFg0XFYWYYfTwL2bmpPm/WTtFH7+cg2xOFy7vIQiq5YWhx9RFPn9xoakuVuutJC/bnWi8iNT8tyCJ7jhteQi19VLi3lqdwdD/ggXTNJzd/hnyIsXINa+grS/ZnSiRMqGJU/y1fWji9j//NkKzth9PcrObclv5qtvQO6s//o5p0kzUTglq+ofNXvanIRC4aSgCRCLi7QNDHdkdHcmB02AaBAQ6Rjypvh69ntC6FUyntvXRTSWWlQ52OkCYFaBmbcaB8gyaXi9NtXPcnfLELMLLYSicWIiROIiXUMBjnS5U+ZGB5pGy+WWUjZ2pa473d0yxJScRC701QYfg/lnI5FIk4MmQDxGVjxZG2/HlRo0ARyNqWNp0qRJYUIFziKbBoVSMW73Rat++DFbbQZ5qi4cqQKrVpXSVVIllxCPi8wpsoy74Ltw2KW9fchPmV1PIBRiUvb43SbrehPBWyGVIAEsWsWIy/tYJPox/p+ebqZbUgN2iV07IsessqvQD9VAPA6aVAmlR5pcWPILGjAVpMxDe5J8R9OkmWBMqMC5ojKDFo+En59pRjqmbHzNkoLR3uCWElhzD0kRcu7V0LyV0sICvreqcmRYEODaZaUc7XZz8bt0y5xVaGZBiYU36/o5f3o2f9rl53MzbNjHaOLLMnQUWDT0ukNcsaCQaCyGTCqQaVCSbVRTbBvVr2cZlMhzqmHuNYmBwBBn6FoptScCrF4pozJLR6ldR8ugH7Vcyg/mxNE3vkA4fzFdy+5OFLuUejAXElh0E892GcnQKxEEmJJjYGu3QO3cnyZ3ypxxBWRN/aAffZo0nygmVI4ToKnfS9Tdhz8So8sTw2bUM7kgA51cgK490LQZdJmJAOrrB4WWoCqTvR49bzc7KcswYDfpGAwkKuQ97iAHO1wUWrXMKzIzKSfVeWjAE+Jor4doNI5VLRCNhnCGZXQ4g+hVMgqtGva3u8gwqLDpFOiVUgbdPnY1D6JVyZmcb2PQEyImQrFNy/9v787jo67uhY9/vrNnmewLCSEJBBDCLougoGitVq9ib+t1ebyt1Vpr7WL73KeLt8+rt+1zb0ufVlvt9lhbq9faDarVulXLokIFIRAgQEgCCZB93yeTWc7zx++XZCYzpESJIcN5v17zYn5nzm/mnGH48vv9zu98z9xsNw3Nzbj7TnLCn87uOj/zpqfitFsoq+vG4wuwJC+FQDDADKeH2YPlOJwuqC2hb+Y11PuTeKvWT3NfgPk5SSQ6bZxo6SU7OY4ZqXGc6uhnTmYC820NWDtOQHwaZBVDXMq5/qvTtPPaBb/KJYDXH+A3u07yxM6a4bIr52by8G2ZcOpt+O+bRlKoORLhrpchZwnbSqr4zKaha4MNZCY62XT3In5b2sIv3jwx/F4Lpyfx49uXMTMj/FQ8w+1krdsJ3fW07v49n6lczp5TI4vE3bZyBgdqjamPl8/J4LPrZ/Gxp0qHL2MmxZ3inrWzePj1CmwW4bF/vZgTbQNYJJvvvFxOIKj48rUO/t/24/R4jRvVLQLfvmkBb1b289YxF89cXE5B5WYaUy/j9r+00t43cnP9166bRxD4xvNl3Ht5EfevL8JiESAVphWfq69f0y4YMXWqXt3ax5Mh87kBtlW0UNXYDTsfDc87OdgLFa/R2dnJ/916Kmyfll4v1Z1+ntwZ/l5ldd0cre85cwOaDlNhnR0WNAE2l9TygfnZALxZ2UpZQ0/YVMluj59er58EhxV/UHGwtouqph62lbcQCCqS4+y09XqHgyYYM4meL61n2YwUaru8HLYVw4IPU9IUDAuaAM/tq+N0Wz8fWpjDT7ZVcrojfPBM07TxianA6fNHJhsG40iU/ugrN/oCAXq8kVMz/QEVNo98yIA/+mqaxk4DeIORX6k/qMJm6nijTJUc8AWwm7OcAoACes1A6bRZ6B+M/Nxer988coQBZQWrnX6/nLFegtOK1x/EP4FTTjXtQhBTgTM/PYFVheHLYuSmuCjKSoLV90fuMO86MtPTueeS8NFku1WYnmTjqovCp3qmxttHBpmiyZzHbE6TkRieYnRNUToHa43blnKSXcybFp7M2CJG1vnOfmM+eWF6PDlJLq6cZ7SrucfLzIyEiBH/Dy2YRm27B6fNwjxbI1TvYFmWhA2MAdywOAe308brR5rYsDiXvFSdR1PT3ouYGxyqbunlmXdOsa28mY+vKeCiaW5yk+OMDOsVr8DOR4wR58u/DIXrwO6iubWVlw+38vTeJnKS7Hzu8hmsKsrlSFMPf9pXx9byZuZNc3P32plcMjNKxvRQDaUcaRrgsaN2Smu7uXq+kTz5R1sqWVmQyq2r8nFahaC3F7enns5BsKYXUtcdwCLGMsBpCXZOtvfjtFnoGwww6A8iAmnxDl451Mi+0x18ZFkeC3KTON3ex4JsJwuPP04rqVgLL6WiL55Hd3XQ2ufj+oXTyEuNo6KpF4fNwq0rZ1CQHpmFXtMuRHrmUIhgUHGovouvbD7IscYeEp02vrVhATcszsEZ7AexgmPk/snjzb1895WjOG1Wegd8XDYng9tX5uOOsxMMBmnqHiA5zkH8GRIgj3a6rYff7D5Na+8gq2elsbmklhsW5yAInR4f852tXFrxfeJObgGrnbZln2Nj+xVsPxXg/iuLcNktZCY6eWJnDYXpCbT3D/LXw40IsGFJLh+Yn0W/18dXnz1MnN3Kg1dkMK8gj89vKqOp28uyvCQe+uc5pLiTEauRLUkw1izSNG2EnjkUotfr55vPH+ZYY8/w9r9tOkB5Y49xtBkSNH3+ID/fXsXfjjbz0qEG3qhs5Tsvl3PQnO2+qQkAABjNSURBVBFksVjISYk/66AJ8MLBJh57s5p4h40fvFbB7uoOEl12fr/3NM3dHpY2/9kImgABH+l7f8gn8lto7fPy0GsV9A74eaOihbK6LtwuG6+WNaKUMSD059J6jjb0UNM2QFqCA48vwDf+1sT++j6auo0p//tru7nxsVK6B4OkJjjJcrt00NS0cygmA2dLj5f9pzsjyk+1R44mt/V7I5YQBqhs7o0oOxv9g35eMpf/TY6309TtxWKBpq4Bls5IJT7QS/rJVyL2y+w6RHqCg16vn7QEJ9uOtTA3282B2sh+HKrrorXXS3HImu6hI+4AfYMB6jonLmGzpl3IYjJwJsXZmB4lk1GmO3KFS7fTzoLpkVmAcqOsJnk2XDYrywuMG8n9gSAJDivBoLFY2+n2fvrFRW/m0oj9ehJn0e3xY7MIA34/C3KTqOv0UJQZOX1zZkYCbqct7Lai0XlHrRYhPUGvea5pEyEmA2em28V3P7KIzETH8DK/H19dwLwoI+IJThtfuXYe7pBT8avnZ0UkEz5bFotwxyUFLJqexJajTdy3vgiLmLcECczMTuVY0d3GnHJ3DsSl4sldw9/6ZuELBvnUulkEAnDz8jxS4x3kJLuYkTbyn0Bhejw5yS4yk5ycbDMC54b5SczNCJ9n/40b5kcNupqmvXcxOTgEUN7QzdbyZtr6vFw6M4Wlg/tJHzgFRVdC1vzhOm9WttDvDXDp7HS6PX7sViGgFDsq21hekMLKwjS6PD52VLXS2DXAujmZLMtPib5S5mA/3vrDlHY62VYrxLkcLM9PwWaB+s5+CjKSyQnUkthVxRHHQt6o8ZASZ2NVYSoN3V5SE1x0eAJ4A9DYPUBT9wCLpieT4LAx4PNjtVqJd1iJt1vo8QzSP+gn0+mnwC240qbR2O2jocvDtCQXc7LduOxnTr6saZoeVQ9zrLGbWx7bRZdnZI2fX16fxNVv3mxkeb/rFY75c7jlsbfD6vz2U5fw+Bsn2FYxssbRQ/+ymI2vHKOldyTX8qO3LWXD0ihrzB39C9tak7nrpZHZRUkuG/ddUcSapFZaPUE+sP/zvLn0h3xiVJ0/XD3A290ZNKg0XilroLZj5Prk/euL2FxSy42LsthV00V5Yw//fv08/s+LR3n8tnl8cGnRWX83mqaN0KPqIfbWdIQFRICH9wfpmb3BWCe8bh8lNe0RdQ7Xd4UFTYDTHZ6woAnwvVeP0T6qjP52+ire5JHS8P+Iugf8dPT7eLshyGrXKTxpxTxyILLO370z+fm+fhKd1rCgCfCb3Se5YXEOT+2q5ZribAJBxc6qNpbkJfPwttN0d3ed9Xejadp7F5OBs9/njyjr9QYJ2M1rfv4BPFGmTvr84QFNxEiCPFrfoH94JclhAT8BsdIzGFl/MBCkzy9Ygj4C9kS6oywU0udTw7ccjTYwGMRpM+axD02x7PP6iXNY6RkMRk2wrGnaxInJwLmiIC1i2uGnF9tIqXoOrHbIWcLy/NSIOhdNc1MQMhCjlLGapGNUAuN7180ie/RKme4skrKL+NSi8LoWgZwkF2unKU5YCkk6vY17F0fWuTSlk+tmx2ERiHeEX5u8aWkuW8qbuOqidEpqOgC4fG4m+0528unV2aSlhicq1jRtYsXkNc5AUPFOdTs/315Fc4+Xu1dkcHXXZtI6D8HaL0H+GgIKSk93cLiuG68/yMzMeFbnOqjv9PD0vlb+fqKD/7Eqn+UFqQQCQeq7B2joGqAgLY5lBWlkjbqhvL3XS31bF5agl5Y+RUW7n2MNXayalU6uox+Lz0OTJZN18SeRtioOJl1ORXsQfzDIomnxZAzWYU1IY2edH6czji3lzZxq7+fa4iwUxtFqbloiv9tTy80X53GwrouVuQ4+WJxNeto/mAaqaVpUenAoikF/AF9AGSPg3h4j47nNuJezo3+QJ3fW8NNtVfiDitUzU/nOsk5mvXw7gaxFNFz5EE8dT+RIQw/zcpL4za6TeP1BluQm8oMPz2VOfs7w5xyu7+ILv9vP8ZY+4h1W7lk3kzfKW1g3N4P5WS7m5qSR4LTx4sEGXjhQzw2Lc/jx1ir6BgPMTI/n7rUz+faLR0hy2fnJNW4W+sqwFt+Az5WGLdBPEAs2ZzyDgSB2qwWb8uPz+0lI0Lcbadp7oQeHonDYrCO3DTndw0EToPRUJ49sqcRvXlTcVd3Bk8fd+DMXYG09ysH6Ph7fUcOaogx+taMar9+4jnigvpdHtlfj9RqrRnZ7fHz9uTKOtxirUPYPBnh0SxVXL8jmJ9uOU93h566n9lLZ0st3Xinn2oXT2PjqMfrMNHHVbf08vesk1y3Moa1vkHte6qTN4ye+9Jckx9lJcKfgdicR57AZ8+UdNhxOlw6amjaJYjpwjuVwfeRI9F+rvXTmXg5J09nTYscixhTK0bZUdtPWaaxO2drrpTTK9M6hQNvl8RmJkVv7w8pDVTT1kp9uzJ/vGwxQL1lw5M8wELkCpqZpk++CDZyhC6QNWTbNgbv9MPQ1Mz81QFAR9SbyRTnxJMUbg0jJcfawmT1DhgaU3C4bLpuVaUnOsPJQ05JcdJhZ220WId3SCzPWgEOnf9O089EFGzgvzk9l/dyRRMVpCQ4+VzyA8/Sb4PNwaVIrNy6Zxsm2vrB6SS4bD15TRKLbmL6Znujkux9ZjMs+8lXetDSXfac6WDc7g9PtffzotqUsL0jlxiW57K5u45YVIytmOm0WPrO+iFfLGhGBb12RxKyaP8IlnwZrTC0JpWkxI6YHhwBoOUawaguB1uO05VxOKfPIz51GcW4y7X2DVDb14PEFKMpMZIa0QmsFDY4ZvN3qYs/JLhbkJlOck0i/Z4BBrxe32832ijbinTauvCiT4txklFKcaOnjZGsPLmsQvN2I30tGciJNwWTeqW7HF1RctyCbUx0eTrX1kZcaT1Ap3E4bu0+0UZiRwMIsJxdJDc7UPEiZcW6/RE3TIuhR9Wjaa+CpG6Dr9HBR/WX/xb8eWMhP77iY+TmRWZF6Bnw8+OwhXjRTwwFcuyCb79+8hD017XzyqZF2JDptbLpvzcj7lP0JNt89/HrpNX/klpeCDAaMpYZvW5XPT7ZWDb+eneTkoxfn8bPtxwG4ZUUe39qwkDiHnmOuae8HPaoeTePBsKAJkFvyfW6dZ2V3dZTF2zBWygwNmgB/PdxEZVMPj26pDCvv9fpH3qe/Hbb+58iLKQW8VJcwvODb9Yty+N3u8NU0m7q9Yeng/ri3lurWvnF1UdO0919sB87AYGSZf4B4K3gGo09T9J1h+uJgIEhvlNUw+4fKgn7whSRKtjnpDZkK77BZ8Pgi9x89xfJMn69p2vkjtgNn9gJwhN/v2LboUzxd7mf1rLSou8zMSIjIxVmc42Zutpv7rpgVVm61CGuKzFk7iVlw6QMjL7ZWcGP+SOB+/UgTH7k4L2z/OLs1bNrnqsI0CjPi0TTt/Bbb1zgB6koIvv0zLC3lNM+5jR22NeTmz2RlXgLWjuPGkWLqTHCNXO883tzLppLTbCtvYe2cDK5flMPc7EQCQcW2Yy38emc1aQkO7ruiiJWF5rz4gI9g8xF83S20+pwgFlIcQXpUPI8fhtJGL1+6eg6Vzb1s2ltLboqL21bmU3Kyna3lLXywOJuPLs+LepuUpmkTQw8OjSXgNzIiWeKwCjg8rfDWQ7DncVBBmHUV/NNDkD5yRNnWM8BLZY38ekc11W39rJ2dwX9+eCGFGQl4fAHjfWzmII6nm+Cex7G88V0jgGYvQq26D+tfPgsiqIvvwr/uy9hTcgHjpvpgUOG0GUecHl+AeIcVGb1wuqZpE0oPDo3FagNnInF2qxHsTr0N7zxmBE2AE1uh9LdGOiTT7poOvvH8YarN5Sl2VLWyuaQWpdTI+wxp2I9l67chYFzUtDQdwnr0OchfA0ohJU9gP/32cPV4h41Elx27zYLFIiQ4bTpoatoUcmEEztFO/j2yrPwF8I6sbLmnuj2iyitljfR6I6dg0n4i+mfkLhvZrn7j3bRU07Tz0IUZOHOWRJblXxa23npxlJUvL5mZRrwjymye5CjLaExbCO3HR7anX/xuWqpp2nnowgycM9dBwbqR7eQZsOpTYBk5/V4zK314xDwz0cklM1O589KCiOTHAOQsJbjo1pHtuFTU4tuh8nVjO38NzFp/7vuhadqkuDAGh6Lpa4WWY8a9nhlzIDkvokp7nxdLUxlx1a9h97Rgmb8BZqwKOzId5unC33yUwd4OOhw5WGwuMny12B1xkDkXEjIj99E0bVK928GhCzeLREKG8RhDWm8V/OHD4DXTu+39FdzyNBRviKwcl4ytYDU2YCSszjuHDdY07XxxYZ6qn61Tu0aC5pDt3wWPXlVS0y5kOnCOxR9lOUr/wMhtTJqmXZB04BxL/mpjVcxQl30R4vWqkpp2IYvZa5xef4Djzb109Ptw2Cy4nVbsNivdHh/Tkl2kxts52d5PZ58Pq1WYnZlISrwj/E1ylsKdL8LbP4Oeelj1aZh99eR0SNO080ZMBs62Pi8/336cJ3ZUE1SwIDeJz181my/94QAeX4DMRCff++giXi5r5Nl9tQQVLJ6ezMO3LmF2lnvkjSwW46hz+gpQgbDF3jRNu3DF5Kn6/lOd/PKt6uGUbYfru3nxYMNw5qHWPi8VTb1sLqkdrnOwrosndtRET+tmtemgqWnasJgMnEfrI1eH3FPTzsJcI11ckstOXacnos6W8ia6PL6Ick3TtFAxGTiLsiLXHC/OSeZ4izEXvWfAR3aSK6LOysI03K6YvHqhado5NGGBU0RmiMg2ETkiIodF5AGzPE1EXheRSvPPcz5EvTw/hWsXZA9vZyc5uXn5dPab65/brRbmZCVwxZyMsDr3r5+N06bX+9E0bWwTNuVSRHKAHKXUPhFxAyXAh4FPAO1KqY0i8jUgVSn11bHeazxTLhu6POysaqW5e4AZqfHYrRYSXTbinVYsYqGrf5DpqfGkJ9qpae2nvW8QEZg3LYnclMj10TVNi13n3ZRLpVQD0GA+7xGRo8B04CZgvVntKWA7MGbgPFuewQAPvVbB5pLa4bLlBSn84mMrSE+MHNxJzdcDPpqmjd/7co1TRAqBZcBuINsMqgCNQPYZdhu3mrbesKAJUHKyk8rm3jPsoWmaNn4THjhFJBH4E/BFpVTYcLcyrhNEvVYgIveKyF4R2dvS0nJWn3WmBSKDo5eS1DRNew8mNHCKiB0jaD6jlHrWLG4yr38OXQdtjravUuoXSqkVSqkVmZlnl5KtMD2eD8zLCiubnZnI7Cij7Jqmae/WhF3jFGMRnV8BR5VSD4e89AJwJ7DR/PP5c/WZiS47/3HjAlYUpvFqWQOXzc7gIxdPJ8vSA6cPGXk004vAFnkrkqZp2tmayFH1tcBbwCFg6CT63zGuc/4RyAdOArcopSIX+AnxbhIZDwYCOKxWaDoCmz4BrcdALHDZA3DpFyA++rrqmqZdOM7HUfUdwJmWbvzARH3uEIfVCr4BeGOjETTBSAe344dQuA5mT3gTNE2LUTE5c2iYpx1ObI8sb6t635uiaVrsiO3A6UqBGZdElqcUvP9t0TQtZsR24HTEw1X/G9zTRsqWfUwv1atp2nsS+xktcpbAPVug7Tg4Eo0VLV2Ra6ZrmqadrdgPnGAs/Rtl+V9N07R3I7ZP1TVN0yaADpyapmnjpAOnpmnaOOnAqWmaNk46cGqapo2TDpyapmnjpAOnpmnaOOnAqWmaNk4TllbuXBKRFowUdOORAbROQHMmS6z1B3SfpopY7lOBUursMqWHmBKB890Qkb3vJs/e+SrW+gO6T1OF7lMkfaquaZo2TjpwapqmjVMsB85fTHYDzrFY6w/oPk0Vuk+jxOw1Tk3TtIkSy0ecmqZpEyLmAqeIfEhEjolIlYh8bbLbc7ZE5AkRaRaRspCyNBF5XUQqzT9TzXIRkUfNPh4UkfMypb2IzBCRbSJyREQOi8gDZvmU7ZeIuETkHRE5YPbpW2b5TBHZbbb9DyLiMMud5naV+XrhZLb/TETEKiL7ReRFc3tK9wdARGpE5JCIlIrIXrPsnPz2YipwiogV+ClwHVAM3C4ixZPbqrP2JPChUWVfA7YopeYAW8xtMPo3x3zcC/z8fWrjePmBf1NKFQOrgc+afx9TuV9e4Cql1BJgKfAhEVkNfA/4oVJqNtABfNKs/0mgwyz/oVnvfPQAcDRke6r3Z8iVSqmlIbcenZvfnlIqZh7AGuCvIdsPAg9OdrvG0f5CoCxk+xiQYz7PAY6Zzx8Dbo9W73x+AM8DH4yVfgHxwD7gEoybqW1m+fDvEPgrsMZ8bjPryWS3fVQ/8swgchXwIsay3lO2PyH9qgEyRpWdk99eTB1xAtOB0yHbtWbZVJWtlGownzcC2ebzKddP85RuGbCbKd4v87S2FGgGXgeOA51KKb9ZJbTdw30yX+8C0t/fFv9DPwK+AgTN7XSmdn+GKOA1ESkRkXvNsnPy27sw1hyKAUopJSJT8hYIEUkE/gR8USnVLSLDr03FfimlAsBSEUkBngPmTXKT3jURuQFoVkqViMj6yW7PObZWKVUnIlnA6yJSHvrie/ntxdoRZx0wI2Q7zyybqppEJAfA/LPZLJ8y/RQRO0bQfEYp9axZPOX7BaCU6gS2YZzKpojI0IFIaLuH+2S+ngy0vc9NHctlwAYRqQF+j3G6/ghTtz/DlFJ15p/NGP/BreIc/fZiLXDuAeaYI4IO4DbghUlu03vxAnCn+fxOjGuEQ+UfN0cCVwNdIacf5w0xDi1/BRxVSj0c8tKU7ZeIZJpHmohIHMY126MYAfRms9roPg319WZgqzIvop0PlFIPKqXylFKFGP9etiql7mCK9meIiCSIiHvoOXANUMa5+u1N9gXcCbggfD1QgXHd6euT3Z5xtPt3QAPgw7i+8kmMa0dbgErgb0CaWVcw7h44DhwCVkx2+8/Qp7UY15kOAqXm4/qp3C9gMbDf7FMZ8A2zfBbwDlAFbAKcZrnL3K4yX5812X0Yo2/rgRdjoT9m+w+Yj8NDseBc/fb0zCFN07RxirVTdU3TtAmnA6emado46cCpaZo2TjpwapqmjZMOnJqmaeOkA6emado46cCpnXMikiIi94dsrx9KVzaVje6XduHSgVObCClALAaY971fIdMetfOIDpwXOBEpFJFyEXlSRCpE5BkRuVpEdprJXleZyV//bCZ43SUii819vylGAubtInJCRL5gvu1GoMhMIPt9syxRRDabn/WMOR0TEdkoRqLjgyLygzHaeaOZOHe/iPxNRLLN8ivMzyk1X3OP8R5fNRPbHhCRjWbZdhFZYT7PMOdsIyILxEhYXGq2bc7ofpnT874vImXm+95q7rteRN4QkefN72WjiNxhvt8hESky62WKyJ9EZI/5uCzke31aRHYCT7+rv1htYk321Cj9mNwHRg5QP7AI4z/SEuAJjCloNwF/Bn4M/IdZ/yqg1Hz+TeDvgBPIwEj2YCcyr+h6jPRjeeZnvI0xHTMdI+/h0Ay2lDHamRpS7x7gIfP5X4DLzOeJmDkko+x/ndnWeHN7aKrddszpdWYfasznPwbuMJ87gLgo/fooRlo5K0Z6slMYOR7XA53mcydGsohvmfs8APzIfP5bjAw+APkYc/qHvtcSIG6yfx/6Ef2hTwM0gGql1CEAETmMkSFbicghjGBRgBEkUEptFZF0EUky931JKeUFvCLSzEh+w9HeUUrVmp9Rar7vLmAA+JV5DXSs66B5wB/MjDYOoNos3wk8LCLPAM8OfUYUVwO/Vkr1m/1oH+OzwAjuXxeRPPN9KyUkHZ5pLfA7ZaSZaxKRN4CVQDewR5lJIkTkOPCauc8h4MqQNhWHvG+SGCn4AF5QSnn+QRu1SaJP1TUwloMYEgzZDvKPc7aG7hsYo35EPWUkwl0FbAZuAF4d43N+DPxEKbUI+DRGsgmUUhsxjkDjgJ0iMt7cmH5G/h24hgqVUr8FNgAe4GURuWqc73s236kFWK2MpR2WKqWmK6V6zdf6xvl52vtIB07tbLwF3AHG9TugVSnVPUb9HuCM1xqHmEdXyUqpl4EvAUvGqJ7MSH7EobRgiEiRUuqQUup7GGkFzxQ4XwfuEpF4c780s7wGWG4+H0qjhojMAk4opR7FSD22OEq/3gJuFSMjfCZwOUbGoLP1GvD5kM9cOo59tUmkA6d2Nr4JLBeRgxgDJHeOVVkp1YZx9FcWMjgUjRt40XzfHcD//Adt2CQiJRjr3Az5ovk5BzFS8r1yhja9ipFzca95qeB/mS/9APiMiOzHuMY55BagzKy7EPjvKP16DiO93AFgK/AVpVTjGH0Y7QvACnPw6Qhw3zj21SaRTiunaZo2TvqIU9M0bZz0qLp2XhGRrwP/Mqp4k1Lqv85y/0VE3vvoVUpdci7ap2mgT9U1TdPGTZ+qa5qmjZMOnJqmaeOkA6emado46cCpaZo2TjpwapqmjdP/B9wZLOioR3FgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_RFC={'n_estimators':[100,200, 350, 500,1000], 'min_samples_leaf':[2, 10, 30]}\n",
        "gr_reg =GridSearchCV(BalancedRandomForestClassifier(),param_grid=param_RFC,cv=5)\n",
        "gr_reg.fit(x_train,y_train)\n",
        "print(\"Best parameters for Random Forest:\", gr_reg.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhrX1SU-j22W",
        "outputId": "acb74999-2f20-47f0-d69e-6f0355da5a5f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Random Forest: {'min_samples_leaf': 2, 'n_estimators': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper parameter tuning on Balanced Random Forest Classifier\n",
        "\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "                 \n",
        "\n",
        "model = BalancedRandomForestClassifier(n_estimators = 500, random_state = 0,min_samples_leaf = 2)\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "y_pred_rf = model.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy: \", model.score(x_train, y_train))\n",
        "print('Testing Accuarcy: ', model.score(x_test, y_test))\n",
        "\n",
        "# making a classification report\n",
        "cr = classification_report(y_test,  y_pred_rf)\n",
        "print(cr)\n",
        "\n",
        "# making a confusion matrix\n",
        "plt.rcParams['figure.figsize'] = (5, 5)\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "oqYp2DOl9nzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf16418-286f-4bc7-fe50-06157c86fcec"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.91875\n",
            "Testing Accuarcy:  0.81\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.81      0.86       143\n",
            "           1       0.63      0.81      0.71        57\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.77      0.81      0.78       200\n",
            "weighted avg       0.83      0.81      0.82       200\n",
            "\n",
            "[[116  27]\n",
            " [ 11  46]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "param_grid = {\"n_estimators\": [10, 50, 100, 130], \"criterion\": ['gini', 'entropy'],\n",
        "                               \"max_depth\": range(2, 10, 1)}\n",
        "\n",
        "            #Creating an object of the Grid Search class\n",
        "grid = GridSearchCV(XGBClassifier(), param_grid=param_grid, cv=5,  verbose=3,n_jobs=-1)\n",
        "#finding the best parameters\n",
        "grid.fit(x_train, y_train)\n",
        "grid.best_estimator_"
      ],
      "metadata": {
        "id": "aTFAJ_Hu9n2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66a0992-2732-4003-8812-8799aec9d24e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(criterion='gini', max_depth=9, n_estimators=10)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid.best_estimator_.predict(x_test)\n",
        "print(\"Training Accuracy: \", model.score(x_train, y_train))\n",
        "print('Testing Accuarcy: ', model.score(x_test, y_test))\n",
        "\n",
        "# making a classification report\n",
        "cr = classification_report(y_test,  y_pred)\n",
        "print(cr)\n",
        "\n",
        "# making a confusion matrix\n",
        "plt.rcParams['figure.figsize'] = (5, 5)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "VzSW4DqF9n5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9844a41b-02a1-4861-e820-1fc163db5e2a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.91875\n",
            "Testing Accuarcy:  0.81\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88       143\n",
            "           1       0.73      0.58      0.65        57\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.79      0.75      0.76       200\n",
            "weighted avg       0.81      0.82      0.81       200\n",
            "\n",
            "[[131  12]\n",
            " [ 24  33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Best Model so far is Balanced Random forrest classifier , it is providing the best result for the both the classes"
      ],
      "metadata": {
        "id": "DVjA0AWtnakw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Trying Prinicipal componenet analysis since we had some features which are correlated\n",
        "\n",
        "pca_data = data.copy(deep=True)\n",
        "pca_data = pca_data.drop('fraud_reported',axis=1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(pca_data)\n",
        "new_df = pd.DataFrame(df_scaled)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "df1 = pd.DataFrame(pca.fit_transform(new_df))\n",
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "zwk7qg9joRyh",
        "outputId": "316f9f19-b6bc-4a54-91d6-a30af044da25"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8cbd6a50-5759-48c8-9635-3ba8b9e890a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.995377</td>\n",
              "      <td>1.339414</td>\n",
              "      <td>-1.055796</td>\n",
              "      <td>-0.144887</td>\n",
              "      <td>-1.249672</td>\n",
              "      <td>1.994864</td>\n",
              "      <td>-0.628849</td>\n",
              "      <td>-0.425304</td>\n",
              "      <td>0.378945</td>\n",
              "      <td>-1.090078</td>\n",
              "      <td>0.798539</td>\n",
              "      <td>-1.914355</td>\n",
              "      <td>-0.789831</td>\n",
              "      <td>0.479243</td>\n",
              "      <td>0.219697</td>\n",
              "      <td>-0.169748</td>\n",
              "      <td>-0.501692</td>\n",
              "      <td>1.109394</td>\n",
              "      <td>0.069580</td>\n",
              "      <td>0.460477</td>\n",
              "      <td>-0.241361</td>\n",
              "      <td>-0.158865</td>\n",
              "      <td>1.111135</td>\n",
              "      <td>-0.866524</td>\n",
              "      <td>0.571361</td>\n",
              "      <td>-0.047437</td>\n",
              "      <td>-0.115631</td>\n",
              "      <td>0.656237</td>\n",
              "      <td>0.869801</td>\n",
              "      <td>-0.264801</td>\n",
              "      <td>0.141449</td>\n",
              "      <td>-0.020845</td>\n",
              "      <td>-5.578766e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.033510</td>\n",
              "      <td>1.095610</td>\n",
              "      <td>1.663394</td>\n",
              "      <td>0.546933</td>\n",
              "      <td>0.575985</td>\n",
              "      <td>-0.558316</td>\n",
              "      <td>0.007426</td>\n",
              "      <td>-0.100597</td>\n",
              "      <td>-2.087883</td>\n",
              "      <td>-0.285665</td>\n",
              "      <td>-0.997097</td>\n",
              "      <td>-0.289285</td>\n",
              "      <td>1.222519</td>\n",
              "      <td>1.818967</td>\n",
              "      <td>-0.222308</td>\n",
              "      <td>-0.056479</td>\n",
              "      <td>1.935592</td>\n",
              "      <td>0.193363</td>\n",
              "      <td>-0.688119</td>\n",
              "      <td>-0.482562</td>\n",
              "      <td>-0.541100</td>\n",
              "      <td>0.343111</td>\n",
              "      <td>0.189662</td>\n",
              "      <td>-0.461920</td>\n",
              "      <td>-0.420878</td>\n",
              "      <td>0.866666</td>\n",
              "      <td>-0.184326</td>\n",
              "      <td>-0.463608</td>\n",
              "      <td>0.081402</td>\n",
              "      <td>0.574045</td>\n",
              "      <td>-0.497636</td>\n",
              "      <td>0.086775</td>\n",
              "      <td>7.987463e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.258635</td>\n",
              "      <td>-0.879681</td>\n",
              "      <td>-0.659968</td>\n",
              "      <td>-0.196020</td>\n",
              "      <td>1.658382</td>\n",
              "      <td>0.819624</td>\n",
              "      <td>0.297821</td>\n",
              "      <td>-0.633765</td>\n",
              "      <td>0.564521</td>\n",
              "      <td>0.902953</td>\n",
              "      <td>1.387621</td>\n",
              "      <td>-1.337111</td>\n",
              "      <td>0.217741</td>\n",
              "      <td>1.855113</td>\n",
              "      <td>-0.641253</td>\n",
              "      <td>0.760940</td>\n",
              "      <td>0.783369</td>\n",
              "      <td>1.610044</td>\n",
              "      <td>-0.393732</td>\n",
              "      <td>-0.062102</td>\n",
              "      <td>1.017271</td>\n",
              "      <td>0.824532</td>\n",
              "      <td>-0.981831</td>\n",
              "      <td>-0.017336</td>\n",
              "      <td>-0.916050</td>\n",
              "      <td>0.072060</td>\n",
              "      <td>0.814011</td>\n",
              "      <td>-0.250779</td>\n",
              "      <td>-0.893446</td>\n",
              "      <td>-0.325983</td>\n",
              "      <td>0.978365</td>\n",
              "      <td>-0.284919</td>\n",
              "      <td>1.022137e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.489647</td>\n",
              "      <td>0.714224</td>\n",
              "      <td>1.327470</td>\n",
              "      <td>-0.245542</td>\n",
              "      <td>2.810987</td>\n",
              "      <td>1.435644</td>\n",
              "      <td>0.740859</td>\n",
              "      <td>-0.915811</td>\n",
              "      <td>0.974507</td>\n",
              "      <td>1.430479</td>\n",
              "      <td>-0.541283</td>\n",
              "      <td>-1.357524</td>\n",
              "      <td>0.427608</td>\n",
              "      <td>1.872710</td>\n",
              "      <td>-0.818803</td>\n",
              "      <td>-0.605998</td>\n",
              "      <td>-0.968235</td>\n",
              "      <td>-0.820669</td>\n",
              "      <td>0.379826</td>\n",
              "      <td>2.966137</td>\n",
              "      <td>-1.226139</td>\n",
              "      <td>-1.204507</td>\n",
              "      <td>-0.338664</td>\n",
              "      <td>0.301686</td>\n",
              "      <td>1.700983</td>\n",
              "      <td>0.220489</td>\n",
              "      <td>-0.224433</td>\n",
              "      <td>0.752572</td>\n",
              "      <td>-0.108366</td>\n",
              "      <td>-0.938534</td>\n",
              "      <td>-0.024184</td>\n",
              "      <td>-0.177748</td>\n",
              "      <td>8.567092e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.546435</td>\n",
              "      <td>1.223472</td>\n",
              "      <td>-0.273618</td>\n",
              "      <td>0.311510</td>\n",
              "      <td>0.997173</td>\n",
              "      <td>0.305757</td>\n",
              "      <td>-0.615449</td>\n",
              "      <td>0.183225</td>\n",
              "      <td>1.012774</td>\n",
              "      <td>1.585660</td>\n",
              "      <td>-1.693293</td>\n",
              "      <td>0.605425</td>\n",
              "      <td>1.874185</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.585091</td>\n",
              "      <td>1.398069</td>\n",
              "      <td>-0.531955</td>\n",
              "      <td>-0.187025</td>\n",
              "      <td>-0.744917</td>\n",
              "      <td>1.743042</td>\n",
              "      <td>0.221281</td>\n",
              "      <td>0.570241</td>\n",
              "      <td>1.318550</td>\n",
              "      <td>-0.055234</td>\n",
              "      <td>0.784483</td>\n",
              "      <td>-2.343111</td>\n",
              "      <td>-0.235861</td>\n",
              "      <td>1.318971</td>\n",
              "      <td>-0.137988</td>\n",
              "      <td>0.094279</td>\n",
              "      <td>-0.162157</td>\n",
              "      <td>0.150005</td>\n",
              "      <td>2.833928e-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cbd6a50-5759-48c8-9635-3ba8b9e890a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cbd6a50-5759-48c8-9635-3ba8b9e890a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cbd6a50-5759-48c8-9635-3ba8b9e890a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0         1         2   ...        30        31            32\n",
              "0 -0.995377  1.339414 -1.055796  ...  0.141449 -0.020845 -5.578766e-16\n",
              "1  4.033510  1.095610  1.663394  ... -0.497636  0.086775  7.987463e-16\n",
              "2  1.258635 -0.879681 -0.659968  ...  0.978365 -0.284919  1.022137e-15\n",
              "3 -0.489647  0.714224  1.327470  ... -0.024184 -0.177748  8.567092e-16\n",
              "4  4.546435  1.223472 -0.273618  ... -0.162157  0.150005  2.833928e-15\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['fraud_reported']\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq575yaFqyn4",
        "outputId": "2515bc0e-2d6d-45c3-e08f-bd72ea29d98b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      0\n",
              "3      1\n",
              "4      0\n",
              "      ..\n",
              "995    0\n",
              "996    0\n",
              "997    0\n",
              "998    0\n",
              "999    0\n",
              "Name: fraud_reported, Length: 1000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "OesEd_eUrXX4",
        "outputId": "3dad6d4e-b5c2-4560-d81a-c2dfc81559f6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### After finding how many number of components to be used for training , pass the scaled data with n_components to PCA model\n",
        "\n",
        "pca = PCA(n_components=30,random_state=10)\n",
        "X = pca.fit_transform(new_df)\n",
        "x_df = pd.DataFrame(X)\n",
        "x_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "ztuN2Lu4rXa2",
        "outputId": "028ba0da-d448-4a19-daf1-57a84ca6eb61"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c991d33-9994-4230-8031-0ce614112ff6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.995377</td>\n",
              "      <td>1.339414</td>\n",
              "      <td>-1.055796</td>\n",
              "      <td>-0.144887</td>\n",
              "      <td>-1.249672</td>\n",
              "      <td>1.994864</td>\n",
              "      <td>-0.628849</td>\n",
              "      <td>-0.425304</td>\n",
              "      <td>0.378945</td>\n",
              "      <td>-1.090078</td>\n",
              "      <td>0.798539</td>\n",
              "      <td>-1.914355</td>\n",
              "      <td>-0.789831</td>\n",
              "      <td>0.479243</td>\n",
              "      <td>0.219697</td>\n",
              "      <td>-0.169748</td>\n",
              "      <td>-0.501692</td>\n",
              "      <td>1.109394</td>\n",
              "      <td>0.069580</td>\n",
              "      <td>0.460477</td>\n",
              "      <td>-0.241361</td>\n",
              "      <td>-0.158865</td>\n",
              "      <td>1.111135</td>\n",
              "      <td>-0.866524</td>\n",
              "      <td>0.571361</td>\n",
              "      <td>-0.047437</td>\n",
              "      <td>-0.115631</td>\n",
              "      <td>0.656237</td>\n",
              "      <td>0.869801</td>\n",
              "      <td>-0.264801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.033510</td>\n",
              "      <td>1.095610</td>\n",
              "      <td>1.663394</td>\n",
              "      <td>0.546933</td>\n",
              "      <td>0.575985</td>\n",
              "      <td>-0.558316</td>\n",
              "      <td>0.007426</td>\n",
              "      <td>-0.100597</td>\n",
              "      <td>-2.087883</td>\n",
              "      <td>-0.285665</td>\n",
              "      <td>-0.997097</td>\n",
              "      <td>-0.289285</td>\n",
              "      <td>1.222519</td>\n",
              "      <td>1.818967</td>\n",
              "      <td>-0.222308</td>\n",
              "      <td>-0.056479</td>\n",
              "      <td>1.935592</td>\n",
              "      <td>0.193363</td>\n",
              "      <td>-0.688119</td>\n",
              "      <td>-0.482562</td>\n",
              "      <td>-0.541100</td>\n",
              "      <td>0.343111</td>\n",
              "      <td>0.189662</td>\n",
              "      <td>-0.461920</td>\n",
              "      <td>-0.420878</td>\n",
              "      <td>0.866666</td>\n",
              "      <td>-0.184326</td>\n",
              "      <td>-0.463608</td>\n",
              "      <td>0.081402</td>\n",
              "      <td>0.574045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.258635</td>\n",
              "      <td>-0.879681</td>\n",
              "      <td>-0.659968</td>\n",
              "      <td>-0.196020</td>\n",
              "      <td>1.658382</td>\n",
              "      <td>0.819624</td>\n",
              "      <td>0.297821</td>\n",
              "      <td>-0.633765</td>\n",
              "      <td>0.564521</td>\n",
              "      <td>0.902953</td>\n",
              "      <td>1.387621</td>\n",
              "      <td>-1.337111</td>\n",
              "      <td>0.217741</td>\n",
              "      <td>1.855113</td>\n",
              "      <td>-0.641253</td>\n",
              "      <td>0.760940</td>\n",
              "      <td>0.783369</td>\n",
              "      <td>1.610044</td>\n",
              "      <td>-0.393732</td>\n",
              "      <td>-0.062102</td>\n",
              "      <td>1.017271</td>\n",
              "      <td>0.824532</td>\n",
              "      <td>-0.981831</td>\n",
              "      <td>-0.017336</td>\n",
              "      <td>-0.916050</td>\n",
              "      <td>0.072060</td>\n",
              "      <td>0.814011</td>\n",
              "      <td>-0.250779</td>\n",
              "      <td>-0.893446</td>\n",
              "      <td>-0.325983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.489647</td>\n",
              "      <td>0.714224</td>\n",
              "      <td>1.327470</td>\n",
              "      <td>-0.245542</td>\n",
              "      <td>2.810987</td>\n",
              "      <td>1.435644</td>\n",
              "      <td>0.740859</td>\n",
              "      <td>-0.915811</td>\n",
              "      <td>0.974507</td>\n",
              "      <td>1.430479</td>\n",
              "      <td>-0.541283</td>\n",
              "      <td>-1.357524</td>\n",
              "      <td>0.427608</td>\n",
              "      <td>1.872710</td>\n",
              "      <td>-0.818803</td>\n",
              "      <td>-0.605998</td>\n",
              "      <td>-0.968235</td>\n",
              "      <td>-0.820669</td>\n",
              "      <td>0.379826</td>\n",
              "      <td>2.966137</td>\n",
              "      <td>-1.226139</td>\n",
              "      <td>-1.204507</td>\n",
              "      <td>-0.338664</td>\n",
              "      <td>0.301686</td>\n",
              "      <td>1.700983</td>\n",
              "      <td>0.220489</td>\n",
              "      <td>-0.224433</td>\n",
              "      <td>0.752572</td>\n",
              "      <td>-0.108366</td>\n",
              "      <td>-0.938534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.546435</td>\n",
              "      <td>1.223472</td>\n",
              "      <td>-0.273618</td>\n",
              "      <td>0.311510</td>\n",
              "      <td>0.997173</td>\n",
              "      <td>0.305757</td>\n",
              "      <td>-0.615449</td>\n",
              "      <td>0.183225</td>\n",
              "      <td>1.012774</td>\n",
              "      <td>1.585660</td>\n",
              "      <td>-1.693293</td>\n",
              "      <td>0.605425</td>\n",
              "      <td>1.874185</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.585091</td>\n",
              "      <td>1.398069</td>\n",
              "      <td>-0.531955</td>\n",
              "      <td>-0.187025</td>\n",
              "      <td>-0.744917</td>\n",
              "      <td>1.743042</td>\n",
              "      <td>0.221281</td>\n",
              "      <td>0.570241</td>\n",
              "      <td>1.318550</td>\n",
              "      <td>-0.055234</td>\n",
              "      <td>0.784483</td>\n",
              "      <td>-2.343111</td>\n",
              "      <td>-0.235861</td>\n",
              "      <td>1.318971</td>\n",
              "      <td>-0.137988</td>\n",
              "      <td>0.094279</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c991d33-9994-4230-8031-0ce614112ff6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c991d33-9994-4230-8031-0ce614112ff6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c991d33-9994-4230-8031-0ce614112ff6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0         1         2   ...        27        28        29\n",
              "0 -0.995377  1.339414 -1.055796  ...  0.656237  0.869801 -0.264801\n",
              "1  4.033510  1.095610  1.663394  ... -0.463608  0.081402  0.574045\n",
              "2  1.258635 -0.879681 -0.659968  ... -0.250779 -0.893446 -0.325983\n",
              "3 -0.489647  0.714224  1.327470  ...  0.752572 -0.108366 -0.938534\n",
              "4  4.546435  1.223472 -0.273618  ...  1.318971 -0.137988  0.094279\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### pca1_train = x_train , pca2_train = y_train\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "pca1_train, pca1_test,pca2_train,pca2_test = train_test_split(X,y,test_size=0.2,random_state=10)\n",
        "print(pca1_train.shape)\n",
        "print(pca2_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0a12m4rXd1",
        "outputId": "fd7b61fa-9f4f-4732-9261-d3df3836b396"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 30)\n",
            "(800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca1_test.shape)\n",
        "print(pca2_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcaVQvNgzDB7",
        "outputId": "6f9bff54-bb9f-4a86-d742-dd168c917fba"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 30)\n",
            "(200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_RFC={'n_estimators':[100,200, 350, 500,1000], 'min_samples_leaf':[2, 10, 30],'max_features':[5,7,9],'min_samples_split':[4,6,8]}\n",
        "gr_reg =GridSearchCV(BalancedRandomForestClassifier(),param_grid=param_RFC,cv=5)\n",
        "gr_reg.fit(pca1_train,pca2_train)\n",
        "print(\"Best parameters for Random Forest:\", gr_reg.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZADM_XntFGv",
        "outputId": "92b232c6-85d4-4d37-e6a6-fa17840e71c1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Random Forest: {'max_features': 5, 'min_samples_leaf': 10, 'min_samples_split': 8, 'n_estimators': 1000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = gr_reg.best_estimator_.predict(pca1_test)\n",
        "print(\"Training Accuracy: \", model.score(pca1_train, pca2_train))\n",
        "print('Testing Accuarcy: ', model.score(pca1_test, pca2_test))\n",
        "\n",
        "# making a classification report\n",
        "cr = classification_report(pca2_test,  y_pred)\n",
        "print(cr)\n",
        "\n",
        "# making a confusion matrix\n",
        "plt.rcParams['figure.figsize'] = (5, 5)\n",
        "cm = confusion_matrix(pca2_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpV2evlItlfH",
        "outputId": "fa18e86e-6abe-40b4-def5-a6d3af064c1b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9125\n",
            "Testing Accuarcy:  0.665\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.75      0.79       151\n",
            "           1       0.42      0.55      0.47        49\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.63      0.65      0.63       200\n",
            "weighted avg       0.73      0.70      0.71       200\n",
            "\n",
            "[[113  38]\n",
            " [ 22  27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks Like the Best Model is LIGHTGBM for this dataset with the accuracy of 83% and we have not removed any outliers for this dataset since this is a fraud detection model , so each and every point is necessary for us."
      ],
      "metadata": {
        "id": "E4ejyUeIzorC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AH-V5qhts1dG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}